{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"calcipy \u2693\ufe0e calcipy is a Python package that implements best practices such as code style (linting, auto-fixes), documentation, CI/CD, and logging. Like the calcium carbonate in hard coral, packages can be built on the calcipy foundation. calcipy has some configurability, but is still very opinionated for my particular use cases. There are a number of alternatives to consider: tidypy offers similar functionality of bundling and running static checkers, but makes far fewer assumptions about the project itself (and has a really nice progress indicator!) black is an opinionated, but really popular formatter And many more such as prospector , wemake-python-styleguide / cjolowicz/cookiecutter-hypermodern-python , etc. Installation \u2693\ufe0e Create a new project with kyleking/calcipy_template # See above link for latest documentation, but this snippet should work pipx install copier copier copy gh:KyleKing/calcipy_template new_project cd new_project # Static files can then be kept in sync with \"copier update\"! Tip Note: If needed, the latest version of calcipy can be installed from git by modifying the pyproject.toml : [tool.poetry.dependencies.calcipy] git = \"https://github.com/kyleking/calcipy.git\" branch = \"dev/development\" rev = \"56802cf\" # Always pin to a commit develop = true # Optional: will reinstall each time [tool.poetry.dev-dependencies.calcipy] git = \"https://github.com/kyleking/calcipy.git\" branch = \"dev/development\" extras = [ \"dev\", \"lint\", \"test\",] Usage \u2693\ufe0e Run poetry install Check that poetry run doit works Run poetry run doit list to see available tasks If you have any questions, please start a Discussion on Github For more examples, see other projects that use calcipy : KyleKing/cz_legacy - Published KyleKing/dash_charts - WIP KyleKing/PiAlarm - On Hold KyleKing/Goodreads_Library_Availability - On Hold See other projects tagged with the topic \u201ccalcipy\u201d Also see: Scripts or Tests Upgrades \u2693\ufe0e Review the ./docs/CHANGELOG.md before updating. Calcipy uses semantic versioning so once ^1.0.0 , breaking changes will only occur during major releases; however, while an alpha-release ( 0.#.# ), the project may have breaking changes on minor increments until stable. # Update dependencies poetry update # Update files copier update Roadmap \u2693\ufe0e See the Open Issues and Milestones for current status and ./docs/CODE_TAG_SUMMARY.md for annotations in the source code. For release history, see the ./docs/CHANGELOG.md Contributing \u2693\ufe0e See the Developer Guide, Contribution Guidelines, etc ./docs/DEVELOPER_GUIDE.md ./docs/STYLE_GUIDE.md ./docs/CONTRIBUTING.md ./docs/CODE_OF_CONDUCT.md ./docs/SECURITY.md License \u2693\ufe0e LICENSE","title":"calcipy"},{"location":"#calcipy","text":"calcipy is a Python package that implements best practices such as code style (linting, auto-fixes), documentation, CI/CD, and logging. Like the calcium carbonate in hard coral, packages can be built on the calcipy foundation. calcipy has some configurability, but is still very opinionated for my particular use cases. There are a number of alternatives to consider: tidypy offers similar functionality of bundling and running static checkers, but makes far fewer assumptions about the project itself (and has a really nice progress indicator!) black is an opinionated, but really popular formatter And many more such as prospector , wemake-python-styleguide / cjolowicz/cookiecutter-hypermodern-python , etc.","title":"calcipy"},{"location":"#installation","text":"Create a new project with kyleking/calcipy_template # See above link for latest documentation, but this snippet should work pipx install copier copier copy gh:KyleKing/calcipy_template new_project cd new_project # Static files can then be kept in sync with \"copier update\"! Tip Note: If needed, the latest version of calcipy can be installed from git by modifying the pyproject.toml : [tool.poetry.dependencies.calcipy] git = \"https://github.com/kyleking/calcipy.git\" branch = \"dev/development\" rev = \"56802cf\" # Always pin to a commit develop = true # Optional: will reinstall each time [tool.poetry.dev-dependencies.calcipy] git = \"https://github.com/kyleking/calcipy.git\" branch = \"dev/development\" extras = [ \"dev\", \"lint\", \"test\",]","title":"Installation"},{"location":"#usage","text":"Run poetry install Check that poetry run doit works Run poetry run doit list to see available tasks If you have any questions, please start a Discussion on Github For more examples, see other projects that use calcipy : KyleKing/cz_legacy - Published KyleKing/dash_charts - WIP KyleKing/PiAlarm - On Hold KyleKing/Goodreads_Library_Availability - On Hold See other projects tagged with the topic \u201ccalcipy\u201d Also see: Scripts or Tests","title":"Usage"},{"location":"#upgrades","text":"Review the ./docs/CHANGELOG.md before updating. Calcipy uses semantic versioning so once ^1.0.0 , breaking changes will only occur during major releases; however, while an alpha-release ( 0.#.# ), the project may have breaking changes on minor increments until stable. # Update dependencies poetry update # Update files copier update","title":"Upgrades"},{"location":"#roadmap","text":"See the Open Issues and Milestones for current status and ./docs/CODE_TAG_SUMMARY.md for annotations in the source code. For release history, see the ./docs/CHANGELOG.md","title":"Roadmap"},{"location":"#contributing","text":"See the Developer Guide, Contribution Guidelines, etc ./docs/DEVELOPER_GUIDE.md ./docs/STYLE_GUIDE.md ./docs/CONTRIBUTING.md ./docs/CODE_OF_CONDUCT.md ./docs/SECURITY.md","title":"Contributing"},{"location":"#license","text":"LICENSE","title":"License"},{"location":"docs/CHANGELOG/","text":"Unreleased \u2693\ufe0e Refactor \u2693\ufe0e apply 0.0.10 template 2021.0.2.0 (2021-06-05) \u2693\ufe0e Feat \u2693\ufe0e #58 : implement doc task and merge serve_docs make loading YAML files more generic create doit summary report add task to check license compliance move lock into doit tasks with file-dependency #38 : re-implement coverage and write source drop subprocess-tee #36 : WIP implementation of doc formatting implement publish tasks add pip outdated to stale check implement check for stale packages begin implementing stale package check smart default tasks for CI vs. local make nox imports optional try doit rather than CWD for initial path move noxfile into calcipy integrate nox to doit tasks WIP check for stale dep & placeholder publish add additional configuration options add nox tasks add detect-secrets as pre-commit lint non-Python files read doc_dir from copier file make most settings configurable added dotted-dict wrapper of Box delete old files rather than full directory filter with glob-like ignore_patterns (2/2) add security check task add skip_phrase for code tag skipping beartype - roar! optionally clear log directory. Move file_helpers from base new tail-like reverse read_lines rename DIG to DG because doit is one word retrieve doc_dir from copier add log-setup fun for doit make (source) doc_dir configurable add sanitizer add pytype #36 : start WIP ReadMeMachine #36 : merge logic of markdown auto-formatters make code tag partially configurable move check_types into calcipy import templates from pdocs Fix \u2693\ufe0e resolve doc_dir and style errors #58 : remove None from pdocs output deconflict doit/nox repair failing test packaging needed keyword argument import and nox syntax errors run push pre-commit hooks with doit show log warning instead of error for stale dep improve output from check_stale errors caught in testing suppress beartype warnings for now drop logger middleware catch most calcipy section typos in toml remove check-secrets but keep snippets errors in ignore patterns import doit and expand nox test file skip tags must be at bottom reset Lint paths instead of extend use find_files for code tag summary don\u2019t manually add the package source dir lint typing and improve tests create separate file_search file to fix imports #51 : replace glob with git-based file identification #53 : Use Interact instead of LongRunning undo PEP585 for runtime beartype resolve file explosion from _find_files import the loguru Logger class safely additional problems found with mypy fix Doit Types and start beartype add no-verify to cl_bump correct isort configuration restore ReadMeMachine repair small bugs found in tests make transitions optional Refactor \u2693\ufe0e move markdown to subdirectory for mkdocs move isort back to toml fix edge case in diff-cov failing and lint errors relicense with MIT for better compliance create generic doit-runner for noxfile fix some type issues minor fixes from AppVeyor testing #38 : reduce complexity minor cleanup to docs apply pre-commit autoformat auto-drop skipcq comment format with VSCode fix lint errors in YAML files move find file paths to DG.meta move if_found_unlink to file_helpers fix formatting with pre-commit fix attribute names for path types (1/2) use calcipy:skip-tags fix minor code tags move __temp_chdir and improve fix_dg narrow type ignore use use path_file of file_path apply auto-fixes from pre-commit replace all glob-search with find_files remove find_files from code_tag script update isort for trailing-comma move excluded lint rules to DG apply PEP585 and add pre-commit hook fix capitalization for doit (one word, all lowercase) improve activate_debug_logging try to replace Any with BaseAction apply 0.0.2 minor fixes apply 0.0.1 version of calcipy_template minor renaming for _MarkdownMachine fix lock file and line length run more pre-commit checks on commit standardize on code tags and cleanup Perf \u2693\ufe0e combine autopep8 paths into single command combine files for linting in one command 2021.0.2.0a0 (2021-02-11) \u2693\ufe0e Feat \u2693\ufe0e push tags with no pre-commit hooks on pre use Interactive instead of \u2014yes for cl_bump* remove tag create/remove tasks new task cl_bump_pre replace MIT license with Unlicense use cz_legacy to generate changelogs remove task in anticipation of copier #26 improve git pre-commit hooks new add-trailing-comma and pyupgrade hooks new mkdocs tasks and improvements new optional preconvert to serialize logs move logger configuration to log_helpers new cl_bump task. Closes #21 Fix \u2693\ufe0e do not pass filenames to pre-commit #43 : add year to version for pseudo-calver prevent legacy types for new commits prevent circular import in doit_tasks extras need to be defined as optional rollback hook changes as they are not working install hooks for push LongRunning passed tasks that should fail yesqa removed necessary noqa (H303, etc) incorrect output paths reduce false tags found (WIP). Fix #24 regression in lint_project tasks unincremented version in toml Refactor \u2693\ufe0e #22 : restore MIT license copy+paste unmodified labels workflow update local TODO notes make toml an optional import rename path_source to path_project rename DIG_CWD as PATH_TEST_PROJECT rename test file doit is lowercase (CC looks like Dolt) replace sh with subprocess-tee reduce excess logging move DOIT_CONFIG to import move dig test to dig test file 0.1.0 (2020-12-19) \u2693\ufe0e Feat \u2693\ufe0e new write_cl task utilizing comittizen new task, pre_commit_hooks Refactor \u2693\ufe0e show STDOUT formatting in DoIt task remove archived code New (Old) \u2693\ufe0e initialize new DIG for #7 (@WIP) last version with dash_dev package name (#22) Change (Old) \u2693\ufe0e try skipcq above the line suppress LGTM warnings skip all DeepSource checks of wildcard import make dev-dep an \u201cExtra\u201d Fix #19 test wildcard imports remove temp files used to test DeepSource rename doit_helpers folder to doit_tasks register tasks in init with all WIP remove old DIG restore documentation tasks from archive remove pdoc3 documentation tasks final changes to intialize calcipy. Fixes #22 move notes on typeguard to #28 rename folder to calcipy #22 rename source to calcipy for #22 remove pdoc3 & archive documentation tasks Fix (Old) \u2693\ufe0e remaining DS wilcard issue try one more time to fix DeepSource * issues attempt to resolve deepsource issues circular import for tag_collector breaking changes from DIG changes (#7) refactor the missing keyword argument logic bury attr exceptions for coverage table 0.0.3 (2020-12-10) \u2693\ufe0e New (Old) \u2693\ufe0e use the climate strike license (#22) ADR template and notes Change (Old) \u2693\ufe0e remove sh for Windows support @WIP try long running for pytest Fix (Old) \u2693\ufe0e make creating the log directory optional 0.0.2 (2020-11-14) \u2693\ufe0e New (Old) \u2693\ufe0e separate task_git_add_docs archive watchcode task move DIG to separate file move tasks to use a wildcard import Change (Old) \u2693\ufe0e add skipcq & update version update documentation improve how tags are located update documentation @WIP minor type annotation fixes 0.0.1 (2020-11-14) \u2693\ufe0e New (Old) \u2693\ufe0e add logging. Fixes #5 intialized tag-finding logic @WIP use a new DoItTask type for annotations add type annotations Loguru configuration for init @WIP activate DeepSource allow user-content in init . Fixes #1 indicate private functions. Fixes #4 add loguru! add watchcode task for arbitrary files flake8-ann & drop pur show README contents in init dump isort & flake8 settings in source path improve linting & test tasks vastly expanded test coverage add ptw as a DoIt LongRunning task initialize index.html as redirect implement source code from dash_charts initialize poetry project Change (Old) \u2693\ufe0e improve logging. Addresses #5 improve logger context manager add task to summarize tags. Fixes #2 move watchcode to separate file mark additional globals as private sync local changes for branch and TODOs loosen dependencies requirements add WIP type checker configs drop dash dependency remove unused packages drop interrogate try to improve interrogate table add interrogate to README implement linting tasks in package push local changes for linting add DIG.test_path incremental changes from local apply and cleanup local changes create the index.html with redirect add the HTML documentation to git control move gitchangelog to package sync local improvements to coverage & linting update dependencies and documentation further improved commit_docs task call out issues with task_commit_docs @wip set Dash version & update whitelist Fix (Old) \u2693\ufe0e replace subprocess with sh problems found by DeepSource path to the .flake8 should be in source_path remove DIG.gh_pages_dir & task_commit_docs changelog creation commit_docs task add missing pystache dep for gitchangelog document dash extras in README","title":"CHANGELOG"},{"location":"docs/CHANGELOG/#unreleased","text":"","title":"Unreleased"},{"location":"docs/CHANGELOG/#refactor","text":"apply 0.0.10 template","title":"Refactor"},{"location":"docs/CHANGELOG/#2021020-2021-06-05","text":"","title":"2021.0.2.0 (2021-06-05)"},{"location":"docs/CHANGELOG/#feat","text":"#58 : implement doc task and merge serve_docs make loading YAML files more generic create doit summary report add task to check license compliance move lock into doit tasks with file-dependency #38 : re-implement coverage and write source drop subprocess-tee #36 : WIP implementation of doc formatting implement publish tasks add pip outdated to stale check implement check for stale packages begin implementing stale package check smart default tasks for CI vs. local make nox imports optional try doit rather than CWD for initial path move noxfile into calcipy integrate nox to doit tasks WIP check for stale dep & placeholder publish add additional configuration options add nox tasks add detect-secrets as pre-commit lint non-Python files read doc_dir from copier file make most settings configurable added dotted-dict wrapper of Box delete old files rather than full directory filter with glob-like ignore_patterns (2/2) add security check task add skip_phrase for code tag skipping beartype - roar! optionally clear log directory. Move file_helpers from base new tail-like reverse read_lines rename DIG to DG because doit is one word retrieve doc_dir from copier add log-setup fun for doit make (source) doc_dir configurable add sanitizer add pytype #36 : start WIP ReadMeMachine #36 : merge logic of markdown auto-formatters make code tag partially configurable move check_types into calcipy import templates from pdocs","title":"Feat"},{"location":"docs/CHANGELOG/#fix","text":"resolve doc_dir and style errors #58 : remove None from pdocs output deconflict doit/nox repair failing test packaging needed keyword argument import and nox syntax errors run push pre-commit hooks with doit show log warning instead of error for stale dep improve output from check_stale errors caught in testing suppress beartype warnings for now drop logger middleware catch most calcipy section typos in toml remove check-secrets but keep snippets errors in ignore patterns import doit and expand nox test file skip tags must be at bottom reset Lint paths instead of extend use find_files for code tag summary don\u2019t manually add the package source dir lint typing and improve tests create separate file_search file to fix imports #51 : replace glob with git-based file identification #53 : Use Interact instead of LongRunning undo PEP585 for runtime beartype resolve file explosion from _find_files import the loguru Logger class safely additional problems found with mypy fix Doit Types and start beartype add no-verify to cl_bump correct isort configuration restore ReadMeMachine repair small bugs found in tests make transitions optional","title":"Fix"},{"location":"docs/CHANGELOG/#refactor_1","text":"move markdown to subdirectory for mkdocs move isort back to toml fix edge case in diff-cov failing and lint errors relicense with MIT for better compliance create generic doit-runner for noxfile fix some type issues minor fixes from AppVeyor testing #38 : reduce complexity minor cleanup to docs apply pre-commit autoformat auto-drop skipcq comment format with VSCode fix lint errors in YAML files move find file paths to DG.meta move if_found_unlink to file_helpers fix formatting with pre-commit fix attribute names for path types (1/2) use calcipy:skip-tags fix minor code tags move __temp_chdir and improve fix_dg narrow type ignore use use path_file of file_path apply auto-fixes from pre-commit replace all glob-search with find_files remove find_files from code_tag script update isort for trailing-comma move excluded lint rules to DG apply PEP585 and add pre-commit hook fix capitalization for doit (one word, all lowercase) improve activate_debug_logging try to replace Any with BaseAction apply 0.0.2 minor fixes apply 0.0.1 version of calcipy_template minor renaming for _MarkdownMachine fix lock file and line length run more pre-commit checks on commit standardize on code tags and cleanup","title":"Refactor"},{"location":"docs/CHANGELOG/#perf","text":"combine autopep8 paths into single command combine files for linting in one command","title":"Perf"},{"location":"docs/CHANGELOG/#2021020a0-2021-02-11","text":"","title":"2021.0.2.0a0 (2021-02-11)"},{"location":"docs/CHANGELOG/#feat_1","text":"push tags with no pre-commit hooks on pre use Interactive instead of \u2014yes for cl_bump* remove tag create/remove tasks new task cl_bump_pre replace MIT license with Unlicense use cz_legacy to generate changelogs remove task in anticipation of copier #26 improve git pre-commit hooks new add-trailing-comma and pyupgrade hooks new mkdocs tasks and improvements new optional preconvert to serialize logs move logger configuration to log_helpers new cl_bump task. Closes #21","title":"Feat"},{"location":"docs/CHANGELOG/#fix_1","text":"do not pass filenames to pre-commit #43 : add year to version for pseudo-calver prevent legacy types for new commits prevent circular import in doit_tasks extras need to be defined as optional rollback hook changes as they are not working install hooks for push LongRunning passed tasks that should fail yesqa removed necessary noqa (H303, etc) incorrect output paths reduce false tags found (WIP). Fix #24 regression in lint_project tasks unincremented version in toml","title":"Fix"},{"location":"docs/CHANGELOG/#refactor_2","text":"#22 : restore MIT license copy+paste unmodified labels workflow update local TODO notes make toml an optional import rename path_source to path_project rename DIG_CWD as PATH_TEST_PROJECT rename test file doit is lowercase (CC looks like Dolt) replace sh with subprocess-tee reduce excess logging move DOIT_CONFIG to import move dig test to dig test file","title":"Refactor"},{"location":"docs/CHANGELOG/#010-2020-12-19","text":"","title":"0.1.0 (2020-12-19)"},{"location":"docs/CHANGELOG/#feat_2","text":"new write_cl task utilizing comittizen new task, pre_commit_hooks","title":"Feat"},{"location":"docs/CHANGELOG/#refactor_3","text":"show STDOUT formatting in DoIt task remove archived code","title":"Refactor"},{"location":"docs/CHANGELOG/#new-old","text":"initialize new DIG for #7 (@WIP) last version with dash_dev package name (#22)","title":"New (Old)"},{"location":"docs/CHANGELOG/#change-old","text":"try skipcq above the line suppress LGTM warnings skip all DeepSource checks of wildcard import make dev-dep an \u201cExtra\u201d Fix #19 test wildcard imports remove temp files used to test DeepSource rename doit_helpers folder to doit_tasks register tasks in init with all WIP remove old DIG restore documentation tasks from archive remove pdoc3 documentation tasks final changes to intialize calcipy. Fixes #22 move notes on typeguard to #28 rename folder to calcipy #22 rename source to calcipy for #22 remove pdoc3 & archive documentation tasks","title":"Change (Old)"},{"location":"docs/CHANGELOG/#fix-old","text":"remaining DS wilcard issue try one more time to fix DeepSource * issues attempt to resolve deepsource issues circular import for tag_collector breaking changes from DIG changes (#7) refactor the missing keyword argument logic bury attr exceptions for coverage table","title":"Fix (Old)"},{"location":"docs/CHANGELOG/#003-2020-12-10","text":"","title":"0.0.3 (2020-12-10)"},{"location":"docs/CHANGELOG/#new-old_1","text":"use the climate strike license (#22) ADR template and notes","title":"New (Old)"},{"location":"docs/CHANGELOG/#change-old_1","text":"remove sh for Windows support @WIP try long running for pytest","title":"Change (Old)"},{"location":"docs/CHANGELOG/#fix-old_1","text":"make creating the log directory optional","title":"Fix (Old)"},{"location":"docs/CHANGELOG/#002-2020-11-14","text":"","title":"0.0.2 (2020-11-14)"},{"location":"docs/CHANGELOG/#new-old_2","text":"separate task_git_add_docs archive watchcode task move DIG to separate file move tasks to use a wildcard import","title":"New (Old)"},{"location":"docs/CHANGELOG/#change-old_2","text":"add skipcq & update version update documentation improve how tags are located update documentation @WIP minor type annotation fixes","title":"Change (Old)"},{"location":"docs/CHANGELOG/#001-2020-11-14","text":"","title":"0.0.1 (2020-11-14)"},{"location":"docs/CHANGELOG/#new-old_3","text":"add logging. Fixes #5 intialized tag-finding logic @WIP use a new DoItTask type for annotations add type annotations Loguru configuration for init @WIP activate DeepSource allow user-content in init . Fixes #1 indicate private functions. Fixes #4 add loguru! add watchcode task for arbitrary files flake8-ann & drop pur show README contents in init dump isort & flake8 settings in source path improve linting & test tasks vastly expanded test coverage add ptw as a DoIt LongRunning task initialize index.html as redirect implement source code from dash_charts initialize poetry project","title":"New (Old)"},{"location":"docs/CHANGELOG/#change-old_3","text":"improve logging. Addresses #5 improve logger context manager add task to summarize tags. Fixes #2 move watchcode to separate file mark additional globals as private sync local changes for branch and TODOs loosen dependencies requirements add WIP type checker configs drop dash dependency remove unused packages drop interrogate try to improve interrogate table add interrogate to README implement linting tasks in package push local changes for linting add DIG.test_path incremental changes from local apply and cleanup local changes create the index.html with redirect add the HTML documentation to git control move gitchangelog to package sync local improvements to coverage & linting update dependencies and documentation further improved commit_docs task call out issues with task_commit_docs @wip set Dash version & update whitelist","title":"Change (Old)"},{"location":"docs/CHANGELOG/#fix-old_2","text":"replace subprocess with sh problems found by DeepSource path to the .flake8 should be in source_path remove DIG.gh_pages_dir & task_commit_docs changelog creation commit_docs task add missing pystache dep for gitchangelog document dash extras in README","title":"Fix (Old)"},{"location":"docs/CODE_OF_CONDUCT/","text":"Contributor Covenant Code of Conduct \u2693\ufe0e Our Pledge \u2693\ufe0e We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community. Our Standards \u2693\ufe0e Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others\u2019 private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Enforcement Responsibilities \u2693\ufe0e Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate. Scope \u2693\ufe0e This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Enforcement \u2693\ufe0e Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at dev.act.kyle@gmail.com. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident. Enforcement Guidelines \u2693\ufe0e Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct: 1. Correction \u2693\ufe0e Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. 2. Warning \u2693\ufe0e Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban. 3. Temporary Ban \u2693\ufe0e Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban. 4. Permanent Ban \u2693\ufe0e Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community. Attribution \u2693\ufe0e This Code of Conduct is adapted from the Contributor Covenant , version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html. Community Impact Guidelines were inspired by Mozilla\u2019s code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.","title":"Contributor Covenant Code of Conduct"},{"location":"docs/CODE_OF_CONDUCT/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"docs/CODE_OF_CONDUCT/#our-pledge","text":"We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.","title":"Our Pledge"},{"location":"docs/CODE_OF_CONDUCT/#our-standards","text":"Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others\u2019 private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"docs/CODE_OF_CONDUCT/#enforcement-responsibilities","text":"Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.","title":"Enforcement Responsibilities"},{"location":"docs/CODE_OF_CONDUCT/#scope","text":"This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.","title":"Scope"},{"location":"docs/CODE_OF_CONDUCT/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at dev.act.kyle@gmail.com. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident.","title":"Enforcement"},{"location":"docs/CODE_OF_CONDUCT/#enforcement-guidelines","text":"Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:","title":"Enforcement Guidelines"},{"location":"docs/CODE_OF_CONDUCT/#1-correction","text":"Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.","title":"1. Correction"},{"location":"docs/CODE_OF_CONDUCT/#2-warning","text":"Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.","title":"2. Warning"},{"location":"docs/CODE_OF_CONDUCT/#3-temporary-ban","text":"Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.","title":"3. Temporary Ban"},{"location":"docs/CODE_OF_CONDUCT/#4-permanent-ban","text":"Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community.","title":"4. Permanent Ban"},{"location":"docs/CODE_OF_CONDUCT/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html. Community Impact Guidelines were inspired by Mozilla\u2019s code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.","title":"Attribution"},{"location":"docs/CODE_TAG_SUMMARY/","text":"Task Summary \u2693\ufe0e Auto-Generated by calcipy .pre-commit-config.yaml line 72 PLANNED: Run when dropping Python 3.8 (& remove BeartypeDecorHint\u2026 ignore) appveyor.yml line 87 PLANNED: Specify single files, like wheels, but zip the docs/reports calcipy/dev/noxfile.py line 158 PLANNED: Troubleshoot why pyroma score is so low (6/10) calcipy/doit_tasks/doc.py line 250 TODO: Convert to Pandas for \u201c.to_markdown\u201d line 252 TODO: Add summary line for total coverage statistics calcipy/doit_tasks/lint.py line 60 FIXME: Docstrings should be reporting an error here for mismatch in types calcipy/doit_tasks/packaging.py line 147 PLANNED: Check that this prevent excess requests to PyPi and refactor line 272 TBD: Handle non-pypi domains and format the URL accordingly (i.e. TestPyPi, etc.) calcipy/doit_tasks/templates/text.mako line 80 PLANNED: handle multiline descriptions line 90 PLANNED: handle multiline descriptions line 215 PLANNED: add meta (example and notes) pyproject.toml line 74 TODO: Implement fully optional imports with: https://github.com/KyleKing/calcipy/issues/19#issuecomment-807886404 line 250 PLANNED: One of these might be causing long flake8 warning messages\u2026 tests/configuration.py line 24 TODO: Replace magic numbers in tests with meta-data about the test project tests/test_doit_tasks/test_packaging.py line 20 FIXME: Replace MockLogger with a more generic alternative. See: Found code tags for FIXME (2), TODO (4), PLANNED (8), TBD (1)","title":"Task Summary"},{"location":"docs/CODE_TAG_SUMMARY/#task-summary","text":"Auto-Generated by calcipy .pre-commit-config.yaml line 72 PLANNED: Run when dropping Python 3.8 (& remove BeartypeDecorHint\u2026 ignore) appveyor.yml line 87 PLANNED: Specify single files, like wheels, but zip the docs/reports calcipy/dev/noxfile.py line 158 PLANNED: Troubleshoot why pyroma score is so low (6/10) calcipy/doit_tasks/doc.py line 250 TODO: Convert to Pandas for \u201c.to_markdown\u201d line 252 TODO: Add summary line for total coverage statistics calcipy/doit_tasks/lint.py line 60 FIXME: Docstrings should be reporting an error here for mismatch in types calcipy/doit_tasks/packaging.py line 147 PLANNED: Check that this prevent excess requests to PyPi and refactor line 272 TBD: Handle non-pypi domains and format the URL accordingly (i.e. TestPyPi, etc.) calcipy/doit_tasks/templates/text.mako line 80 PLANNED: handle multiline descriptions line 90 PLANNED: handle multiline descriptions line 215 PLANNED: add meta (example and notes) pyproject.toml line 74 TODO: Implement fully optional imports with: https://github.com/KyleKing/calcipy/issues/19#issuecomment-807886404 line 250 PLANNED: One of these might be causing long flake8 warning messages\u2026 tests/configuration.py line 24 TODO: Replace magic numbers in tests with meta-data about the test project tests/test_doit_tasks/test_packaging.py line 20 FIXME: Replace MockLogger with a more generic alternative. See: Found code tags for FIXME (2), TODO (4), PLANNED (8), TBD (1)","title":"Task Summary"},{"location":"docs/CONTRIBUTING/","text":"Contributing \u2693\ufe0e Thanks for taking a look! This is primarily a personal project, but Pull Requests and Issues (questions, feature requests, etc.) are welcome. If you would like to submit a Pull Request, please open an issue first to discuss what you would like to change Pull Requests (PR) \u2693\ufe0e Code Development \u2693\ufe0e See ./DEVELOPER_GUIDE.md PR Process \u2693\ufe0e Fork the Project and Clone Create a new branch ( git checkout -b feat/feature-name ) Edit code; update documentation and tests; commit and push Before submitting the review and pushing, make sure to run poetry run doit Open a new Pull Request See the style guide for commit message format ( ./STYLE_GUIDE ) If you run into any issues, please check to see if there is an open issues or open a new one Other PR Tips \u2693\ufe0e Link the issue with Fixes #N in the Pull Request body Please add a short summary of why the change was made, what changed , and any relevant information or screenshots # SHA is the SHA of the commit you want to fix git commit --fixup = SHA # Once all the changes are approved, you can squash your commits: git rebase --interactive --autosquash main # Force Push git push --force","title":"Contributing"},{"location":"docs/CONTRIBUTING/#contributing","text":"Thanks for taking a look! This is primarily a personal project, but Pull Requests and Issues (questions, feature requests, etc.) are welcome. If you would like to submit a Pull Request, please open an issue first to discuss what you would like to change","title":"Contributing"},{"location":"docs/CONTRIBUTING/#pull-requests-pr","text":"","title":"Pull Requests (PR)"},{"location":"docs/CONTRIBUTING/#code-development","text":"See ./DEVELOPER_GUIDE.md","title":"Code Development"},{"location":"docs/CONTRIBUTING/#pr-process","text":"Fork the Project and Clone Create a new branch ( git checkout -b feat/feature-name ) Edit code; update documentation and tests; commit and push Before submitting the review and pushing, make sure to run poetry run doit Open a new Pull Request See the style guide for commit message format ( ./STYLE_GUIDE ) If you run into any issues, please check to see if there is an open issues or open a new one","title":"PR Process"},{"location":"docs/CONTRIBUTING/#other-pr-tips","text":"Link the issue with Fixes #N in the Pull Request body Please add a short summary of why the change was made, what changed , and any relevant information or screenshots # SHA is the SHA of the commit you want to fix git commit --fixup = SHA # Once all the changes are approved, you can squash your commits: git rebase --interactive --autosquash main # Force Push git push --force","title":"Other PR Tips"},{"location":"docs/DEVELOPER_GUIDE/","text":"Developer Notes \u2693\ufe0e Local Development \u2693\ufe0e git clone https://github.com/kyleking/calcipy.git cd calcipy poetry install -E dev -E lint -E test -E commitizen_legacy # See the available tasks poetry run doit list # Run the default task list (lint, auto-format, test coverage, etc.) poetry run doit --continue # Make code changes and run specific tasks as needed: poetry run doit run test Publishing \u2693\ufe0e For testing, create an account on TestPyPi poetry config repositories.testpypi https://test.pypi.org/legacy/ poetry config pypi-token.testpypi ... poetry run doit run publish_test_pypi # If you didn't configure a token, you will need to provide your username and password to publish To publish to the real PyPi poetry config pypi-token.pypi ... poetry run doit run publish # For a full release, increment the version, the documentation, and publish poetry run doit run --continue poetry run doit run cl_bump document deploy_docs publish # Note: cl_bump_pre is helpful for pre-releases rather than full increments Replace \u201c\u2026\u201d with the API token generated on TestPyPi/PyPi respectively Checklist \u2693\ufe0e Run doit tasks (test) poetry run doit Commit and push all local changes Increment version: poetry run doit run cl_bump Check that the README and other Markdown files are up-to-date Publish (see above)","title":"Developer Notes"},{"location":"docs/DEVELOPER_GUIDE/#developer-notes","text":"","title":"Developer Notes"},{"location":"docs/DEVELOPER_GUIDE/#local-development","text":"git clone https://github.com/kyleking/calcipy.git cd calcipy poetry install -E dev -E lint -E test -E commitizen_legacy # See the available tasks poetry run doit list # Run the default task list (lint, auto-format, test coverage, etc.) poetry run doit --continue # Make code changes and run specific tasks as needed: poetry run doit run test","title":"Local Development"},{"location":"docs/DEVELOPER_GUIDE/#publishing","text":"For testing, create an account on TestPyPi poetry config repositories.testpypi https://test.pypi.org/legacy/ poetry config pypi-token.testpypi ... poetry run doit run publish_test_pypi # If you didn't configure a token, you will need to provide your username and password to publish To publish to the real PyPi poetry config pypi-token.pypi ... poetry run doit run publish # For a full release, increment the version, the documentation, and publish poetry run doit run --continue poetry run doit run cl_bump document deploy_docs publish # Note: cl_bump_pre is helpful for pre-releases rather than full increments Replace \u201c\u2026\u201d with the API token generated on TestPyPi/PyPi respectively","title":"Publishing"},{"location":"docs/DEVELOPER_GUIDE/#checklist","text":"Run doit tasks (test) poetry run doit Commit and push all local changes Increment version: poetry run doit run cl_bump Check that the README and other Markdown files are up-to-date Publish (see above)","title":"Checklist"},{"location":"docs/SECURITY/","text":"Security \u2693\ufe0e Reporting Security Issues \u2693\ufe0e Do not open issues that might have security implications! It is critical that security related issues are reported privately so we have time to address them before they become public knowledge. Vulnerabilities can be reported by emailing core members: Kyle King ( dev.act.kyle@gmail.com ) Please include the requested information listed below (as much as you can provide) to help us better understand the nature and scope of the possible issue: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Environment (e.g. Linux / Windows / macOS) Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly. Preferred Languages \u2693\ufe0e We prefer all communications to be in English. Attribution \u2693\ufe0e This file was based on the template from TezRomacH/python-package-template/SECURITY.md","title":"Security"},{"location":"docs/SECURITY/#security","text":"","title":"Security"},{"location":"docs/SECURITY/#reporting-security-issues","text":"Do not open issues that might have security implications! It is critical that security related issues are reported privately so we have time to address them before they become public knowledge. Vulnerabilities can be reported by emailing core members: Kyle King ( dev.act.kyle@gmail.com ) Please include the requested information listed below (as much as you can provide) to help us better understand the nature and scope of the possible issue: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Environment (e.g. Linux / Windows / macOS) Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly.","title":"Reporting Security Issues"},{"location":"docs/SECURITY/#preferred-languages","text":"We prefer all communications to be in English.","title":"Preferred Languages"},{"location":"docs/SECURITY/#attribution","text":"This file was based on the template from TezRomacH/python-package-template/SECURITY.md","title":"Attribution"},{"location":"docs/STYLE_GUIDE/","text":"Personal Style Guides \u2693\ufe0e Git \u2693\ufe0e Use Conventional Commits and Commitizen The Changelog is an important part of a project (built with commitizen ). Use semver Conventional Commits \u2693\ufe0e type(scope): description / body The type feat MUST be used when a commit adds a new feature to your application or library. The type fix MUST be used when a commit represents a bug fix for your application. A scope MUST consist of a noun describing a section of the codebase surrounded by parenthesis, e.g., fix(parser): or issue number fix(#32): A ! can be used to indicate a breaking change, e.g. refactor!: drop support for Node 6 What if a commit fits multiple types? Go back and make multiple commits whenever possible. Part of the benefit of Conventional Commits is its ability to drive us to make more organized commits and PRs. It discourages moving fast in a disorganized way. It helps you be able to move fast long term across multiple projects with varied contributors. semver : fix : PATCH / feat : MINOR / BREAKING CHANGE : MAJOR Use git rebase -i to fix commit names prior to merging if incorrect types/scopes are used Commitizen Types and Scopes \u2693\ufe0e Types fix: A bug fix feat: A new feature docs: Documentation-only changes (code comments, separate docs) style: Changes that do not affect the meaning of the code (white-space, formatting, missing semi-colons) perf: A code change that improves performance refactor: A change to production code that is not fix, feat, or perf test: Adding missing or correcting existing tests build: Changes that affect the build system or external dependencies (example scopes: pip, docker, npm) ci: Changes to our CI configuration files and scripts (example scopes: GitLabCI) Scopes Class, File name, Issue Number, other approved noun Git Message Guidelines \u2693\ufe0e Commit message guidelines Full sentence with verb ( lowercase ) and concise description. Below are modified examples for Conventional Commits fix(roles): bug in admin role permissions feat(ui): implement new button design build(pip): upgrade package to remove vulnerabilities refactor: file structure to improve code readability perf(cli): rewrite methods feat(api): endpoints to implement new customer dashboard How to write a good commit message A diff will tell you what changed, but only the commit message can properly tell you why. Keep in mind: This has all been said before . The seven rules of a great Git commit message Try for 50 characters, but consider 72 the hard limit Use the body to explain what and why vs. how Issue Labels and Milestones \u2693\ufe0e Personal Guide Labels Needs Discussion : (#ff5722) Ticket needs discussion and prioritization Type: Bug : (#d73a4a) Something isn\u2019t working Type: Documentation : (#69cde9) Documentation changes Type: Maintenance : (#c5def5) Chore including build/dep, CI, refactor, or perf Type: Idea : (#fbca04) General idea or concept that could become a feature request Type: Feature : (#0075ca) Clearly defined new feature request Milestones Current Tasks (Main Milestone) - name could change based on a specific project, sprint, or month Next Tasks Blue Sky Search is:open is:issue assignee:KyleKing archived:false milestone:\"blue sky\" or no:milestone etc. Research [Sane Github Labels](https://medium.com/@dave_lunny/sane-github-labels-c5d2e6004b63) and see [sensible-github-labels](https://github.com/Relequestual/sensible-github-labels) for full descriptions of each \u201cit is much more helpful to see the status and type of all issues at a glance.\u201d One of each: Status: \u2026 Abandoned, Accepted, Available, Blocked, Completed, In Progress, On Hold, Pending, Review Needed, Revision Needed Type: \u2026 Bug, Maintenance, Question, Enhancement Priority: \u2026 Critical, High, Medium, Low [Britecharts](https://britecharts.github.io/britecharts/github-labels.html) Status: \u2026 On Review \u2013 Request that we are pondering if including or not Needs Reproducing \u2013 For bugs that need to be reproduced in order to get fixed Needs Design \u2013 Feature that needs a design Ready to Go \u2013 Issue that has been defined and is ready to get started with In Progress \u2013 Issue that is being worked on right now. Completed \u2013 Finished feature or fix Type: \u2026 Bug \u2013 An unexpected problem or unintended behavior Feature \u2013 A new feature request Maintenance \u2013 A regular maintenance chore or task, including refactors, build system, CI, performance improvements Documentation \u2013 A documentation improvement task Question \u2013 An issue or PR that needs more information or a user question Not Included Priority: They would add complexity and overhead due to the discussions, but could help with the roadmap Technology Labels: It can create too much overhead, as properly tag with technologies all the issues could be time consuming [Ian Bicking Blog](https://www.ianbicking.org/blog/2014/03/use-github-issues-to-organize-a-project.html) Milestone Overview What are we doing right now? What aren\u2019t we doing right now? 2a. Stuff we\u2019ll probably do soon 2b. Stuff we probably won\u2019t do soon What aren\u2019t we sure about? Milestone Descriptions Stuff we are doing right now: this is the \u201cmain\u201d milestone. We give it a name (like Alpha 2 or Strawberry Rhubarb Pie) and we write down what we are trying to accomplish with the milestone. We create a new milestone when we are ready for the next iteration. Stuff we\u2019ll probably do soon: this is a standing \u201c**Next Tasks**\u201d milestone. We never change or rename this milestone. We use a permanent \u201cNext Tasks\u201d milestone (as opposed to renaming it to \u201cAlpha 3\u201d or actual-next-iteration milestone) because we don\u2019t want to presume or default to including something in the real next iteration. When we\u2019re ready to start planning the next iteration we\u2019ll create a new milestone, and only deliberately move things into that milestone. Stuff we probably won\u2019t do soon: this is a standing \u201c**Blue Sky**\u201d milestone. We refer to these tickets and sometimes look through them, but they are easy to ignore, somewhat intentionally ignored. What aren\u2019t we sure about?: issues with no milestone. Label: \u201cNeeds Discussion\u201d - (addressed in a triage meeting) - use liberally for either big or small tickets \u201cIt\u2019s better to give people more power: it\u2019s actually helpful if people can overreach because it is an opportunity to establish where the limits really are and what purpose those limits have\u201d External Links \u2693\ufe0e TODO: Revisit Git: The Simple Guide Commit Messages and why use the present tense Github\u2019s Advice on Github Most Comprehensive Guide Git Pro Book (free) Bash Tab-Completion Snippet Python \u2693\ufe0e TODO: Revisit Python Style Guides https://gist.github.com/sloria/7001839 http://www.nilunder.com/blog/2013/08/03/pythonic-sensibilities/ https://innoq.github.io/cards42org_en/ https://docs.openstack.org/hacking/latest/user/hacking.html#styleguide https://www.python.org/doc/humor/ https://docs.python-guide.org/writing/reading/ https://realpython.com/python-refactoring/ ADRs \u2693\ufe0e TODO: Revisit Examples https://github.com/pawamoy/mkdocstrings/issues/28","title":"Personal Style Guides"},{"location":"docs/STYLE_GUIDE/#personal-style-guides","text":"","title":"Personal Style Guides"},{"location":"docs/STYLE_GUIDE/#git","text":"Use Conventional Commits and Commitizen The Changelog is an important part of a project (built with commitizen ). Use semver","title":"Git"},{"location":"docs/STYLE_GUIDE/#conventional-commits","text":"type(scope): description / body The type feat MUST be used when a commit adds a new feature to your application or library. The type fix MUST be used when a commit represents a bug fix for your application. A scope MUST consist of a noun describing a section of the codebase surrounded by parenthesis, e.g., fix(parser): or issue number fix(#32): A ! can be used to indicate a breaking change, e.g. refactor!: drop support for Node 6 What if a commit fits multiple types? Go back and make multiple commits whenever possible. Part of the benefit of Conventional Commits is its ability to drive us to make more organized commits and PRs. It discourages moving fast in a disorganized way. It helps you be able to move fast long term across multiple projects with varied contributors. semver : fix : PATCH / feat : MINOR / BREAKING CHANGE : MAJOR Use git rebase -i to fix commit names prior to merging if incorrect types/scopes are used","title":"Conventional Commits"},{"location":"docs/STYLE_GUIDE/#commitizen-types-and-scopes","text":"Types fix: A bug fix feat: A new feature docs: Documentation-only changes (code comments, separate docs) style: Changes that do not affect the meaning of the code (white-space, formatting, missing semi-colons) perf: A code change that improves performance refactor: A change to production code that is not fix, feat, or perf test: Adding missing or correcting existing tests build: Changes that affect the build system or external dependencies (example scopes: pip, docker, npm) ci: Changes to our CI configuration files and scripts (example scopes: GitLabCI) Scopes Class, File name, Issue Number, other approved noun","title":"Commitizen Types and Scopes"},{"location":"docs/STYLE_GUIDE/#git-message-guidelines","text":"Commit message guidelines Full sentence with verb ( lowercase ) and concise description. Below are modified examples for Conventional Commits fix(roles): bug in admin role permissions feat(ui): implement new button design build(pip): upgrade package to remove vulnerabilities refactor: file structure to improve code readability perf(cli): rewrite methods feat(api): endpoints to implement new customer dashboard How to write a good commit message A diff will tell you what changed, but only the commit message can properly tell you why. Keep in mind: This has all been said before . The seven rules of a great Git commit message Try for 50 characters, but consider 72 the hard limit Use the body to explain what and why vs. how","title":"Git Message Guidelines"},{"location":"docs/STYLE_GUIDE/#issue-labels-and-milestones","text":"Personal Guide Labels Needs Discussion : (#ff5722) Ticket needs discussion and prioritization Type: Bug : (#d73a4a) Something isn\u2019t working Type: Documentation : (#69cde9) Documentation changes Type: Maintenance : (#c5def5) Chore including build/dep, CI, refactor, or perf Type: Idea : (#fbca04) General idea or concept that could become a feature request Type: Feature : (#0075ca) Clearly defined new feature request Milestones Current Tasks (Main Milestone) - name could change based on a specific project, sprint, or month Next Tasks Blue Sky Search is:open is:issue assignee:KyleKing archived:false milestone:\"blue sky\" or no:milestone etc. Research [Sane Github Labels](https://medium.com/@dave_lunny/sane-github-labels-c5d2e6004b63) and see [sensible-github-labels](https://github.com/Relequestual/sensible-github-labels) for full descriptions of each \u201cit is much more helpful to see the status and type of all issues at a glance.\u201d One of each: Status: \u2026 Abandoned, Accepted, Available, Blocked, Completed, In Progress, On Hold, Pending, Review Needed, Revision Needed Type: \u2026 Bug, Maintenance, Question, Enhancement Priority: \u2026 Critical, High, Medium, Low [Britecharts](https://britecharts.github.io/britecharts/github-labels.html) Status: \u2026 On Review \u2013 Request that we are pondering if including or not Needs Reproducing \u2013 For bugs that need to be reproduced in order to get fixed Needs Design \u2013 Feature that needs a design Ready to Go \u2013 Issue that has been defined and is ready to get started with In Progress \u2013 Issue that is being worked on right now. Completed \u2013 Finished feature or fix Type: \u2026 Bug \u2013 An unexpected problem or unintended behavior Feature \u2013 A new feature request Maintenance \u2013 A regular maintenance chore or task, including refactors, build system, CI, performance improvements Documentation \u2013 A documentation improvement task Question \u2013 An issue or PR that needs more information or a user question Not Included Priority: They would add complexity and overhead due to the discussions, but could help with the roadmap Technology Labels: It can create too much overhead, as properly tag with technologies all the issues could be time consuming [Ian Bicking Blog](https://www.ianbicking.org/blog/2014/03/use-github-issues-to-organize-a-project.html) Milestone Overview What are we doing right now? What aren\u2019t we doing right now? 2a. Stuff we\u2019ll probably do soon 2b. Stuff we probably won\u2019t do soon What aren\u2019t we sure about? Milestone Descriptions Stuff we are doing right now: this is the \u201cmain\u201d milestone. We give it a name (like Alpha 2 or Strawberry Rhubarb Pie) and we write down what we are trying to accomplish with the milestone. We create a new milestone when we are ready for the next iteration. Stuff we\u2019ll probably do soon: this is a standing \u201c**Next Tasks**\u201d milestone. We never change or rename this milestone. We use a permanent \u201cNext Tasks\u201d milestone (as opposed to renaming it to \u201cAlpha 3\u201d or actual-next-iteration milestone) because we don\u2019t want to presume or default to including something in the real next iteration. When we\u2019re ready to start planning the next iteration we\u2019ll create a new milestone, and only deliberately move things into that milestone. Stuff we probably won\u2019t do soon: this is a standing \u201c**Blue Sky**\u201d milestone. We refer to these tickets and sometimes look through them, but they are easy to ignore, somewhat intentionally ignored. What aren\u2019t we sure about?: issues with no milestone. Label: \u201cNeeds Discussion\u201d - (addressed in a triage meeting) - use liberally for either big or small tickets \u201cIt\u2019s better to give people more power: it\u2019s actually helpful if people can overreach because it is an opportunity to establish where the limits really are and what purpose those limits have\u201d","title":"Issue Labels and Milestones"},{"location":"docs/STYLE_GUIDE/#external-links","text":"TODO: Revisit Git: The Simple Guide Commit Messages and why use the present tense Github\u2019s Advice on Github Most Comprehensive Guide Git Pro Book (free) Bash Tab-Completion Snippet","title":"External Links"},{"location":"docs/STYLE_GUIDE/#python","text":"TODO: Revisit Python Style Guides https://gist.github.com/sloria/7001839 http://www.nilunder.com/blog/2013/08/03/pythonic-sensibilities/ https://innoq.github.io/cards42org_en/ https://docs.openstack.org/hacking/latest/user/hacking.html#styleguide https://www.python.org/doc/humor/ https://docs.python-guide.org/writing/reading/ https://realpython.com/python-refactoring/","title":"Python"},{"location":"docs/STYLE_GUIDE/#adrs","text":"TODO: Revisit Examples https://github.com/pawamoy/mkdocstrings/issues/28","title":"ADRs"},{"location":"docs/modules/calcipy/","text":"calcipy \u2693\ufe0e calcipy. View Source \"\"\"calcipy.\"\"\" import warnings from beartype.roar import BeartypeDecorHintPepDeprecatedWarning from loguru import logger __version__ = '0.2.0' __pkg_name__ = 'calcipy' logger . disable ( __pkg_name__ ) # Suppress Beartype warnings for now while 3.8.8 and below need to be supported # See: https://github.com/beartype/beartype/issues/30#issuecomment-792176571 warnings . simplefilter ( action = 'ignore' , category = BeartypeDecorHintPepDeprecatedWarning ) # ====== Above is the recommended code from calcipy_template and may be updated on new releases ====== Sub-modules \u2693\ufe0e calcipy.dev calcipy.doit_tasks calcipy.file_helpers calcipy.log_helpers calcipy.wrappers","title":"calcipy"},{"location":"docs/modules/calcipy/#calcipy","text":"calcipy. View Source \"\"\"calcipy.\"\"\" import warnings from beartype.roar import BeartypeDecorHintPepDeprecatedWarning from loguru import logger __version__ = '0.2.0' __pkg_name__ = 'calcipy' logger . disable ( __pkg_name__ ) # Suppress Beartype warnings for now while 3.8.8 and below need to be supported # See: https://github.com/beartype/beartype/issues/30#issuecomment-792176571 warnings . simplefilter ( action = 'ignore' , category = BeartypeDecorHintPepDeprecatedWarning ) # ====== Above is the recommended code from calcipy_template and may be updated on new releases ======","title":"calcipy"},{"location":"docs/modules/calcipy/#sub-modules","text":"calcipy.dev calcipy.doit_tasks calcipy.file_helpers calcipy.log_helpers calcipy.wrappers","title":"Sub-modules"},{"location":"docs/modules/calcipy/file_helpers/","text":"calcipy.file_helpers \u2693\ufe0e File Helpers. View Source \"\"\"File Helpers.\"\"\" import os import shutil import string import time from pathlib import Path from typing import Any , List import yaml from beartype import beartype from loguru import logger # ---------------------------------------------------------------------------------------------------------------------- # General ALLOWED_CHARS = string . ascii_lowercase + string . ascii_uppercase + string . digits + '-_.' \"\"\"Default string of acceptable characters in a filename.\"\"\" @beartype def sanitize_filename ( filename : str , repl_char : str = '_' , allowed_chars : str = ALLOWED_CHARS ) -> str : \"\"\"Replace all characters not in the `allow_chars` with `repl_char`. Args: filename: string filename (stem and suffix only) repl_char: replacement character. Default is `_` allowed_chars: all allowed characters. Default is `ALLOWED_CHARS` Returns: str: sanitized filename \"\"\" return '' . join (( char if char in allowed_chars else repl_char ) for char in filename ) _COPIER_ANSWERS_NAME = '.copier-answers.yml' \"\"\"Copier Answer file name.\"\"\" _MKDOCS_CONFIG_NAME = 'mkdocs.yml' \"\"\"Copier Answer file name.\"\"\" @beartype def _read_yaml_file ( path_yaml : Path ) -> Any : \"\"\"Attempt to read the specified yaml file. Returns an empty dictionary if not found or a parser error occurs. > Note: suppresses all tags in the YAML file Args: path_yaml: path to the yaml file Returns: dictionary representation of the source file \"\"\" # Based on: https://github.com/yaml/pyyaml/issues/86#issuecomment-380252434 yaml . add_multi_constructor ( '' , lambda loader , suffix , node : None ) try : return yaml . unsafe_load ( path_yaml . read_text ()) except ( FileNotFoundError , KeyError ) as err : # pragma: no cover logger . warning ( f 'Unexpected error reading the { path_yaml . name } file ( { path_yaml } ): { err } ' ) return {} @beartype def get_doc_dir ( path_project : Path ) -> Path : \"\"\"Retrieve the documentation directory from teh copier answer file. > Default directory is \"docs\" if not found Args: path_project: Path to the project directory with contains `.copier-answers.yml` Returns: Path: to the source documentation directory \"\"\" path_copier = path_project / _COPIER_ANSWERS_NAME return path_project / _read_yaml_file ( path_copier ) . get ( 'doc_dir' , 'docs' ) # ---------------------------------------------------------------------------------------------------------------------- # Read Files @beartype def read_lines ( path_file : Path ) -> List [ str ]: \"\"\"Read a file and split on newlines for later parsing. Args: path_file: path to the file Returns: List[str]: lines of text as list \"\"\" if path_file . is_file (): return path_file . read_text () . split ( ' \\n ' ) return [] @beartype def tail_lines ( path_file : Path , * , count : int ) -> List [ str ]: \"\"\"Tail a file for up to the last count (or full file) lines. Based on: https://stackoverflow.com/a/54278929 > Tip: `file_size = fh.tell()` -or- `os.fstat(fh.fileno()).st_size` -or- return from `fh.seek(0, os.SEEK_END)` Args: path_file: path to the file count: maximum number of lines to return Returns: List[str]: lines of text as list \"\"\" with open ( path_file , 'rb' ) as fh : rem_bytes = fh . seek ( 0 , os . SEEK_END ) step_size = 1 # Initially set to 1 so that the last byte is read found_lines = 0 while found_lines < count and rem_bytes >= step_size : rem_bytes = fh . seek ( - 1 * step_size , os . SEEK_CUR ) if fh . read ( 1 ) == b ' \\n ' : found_lines += 1 step_size = 2 # Increase so that repeats(read 1 / back 2) if rem_bytes < step_size : fh . seek ( 0 , os . SEEK_SET ) return [ line . rstrip ( ' \\r ' ) for line in fh . read () . decode () . split ( ' \\n ' )] # ---------------------------------------------------------------------------------------------------------------------- # Manage Files and Directories @beartype def if_found_unlink ( path_file : Path ) -> None : \"\"\"Remove file if it exists. Function is intended to a doit action. Args: path_file: Path to file to remove \"\"\" if path_file . is_file (): logger . info ( f 'Deleting ` { path_file } `' , path_file = path_file ) path_file . unlink () @beartype def delete_old_files ( dir_path : Path , * , ttl_seconds : int ) -> None : \"\"\"Delete old files within the specified directory. Args: dir_path: Path to directory to delete ttl_seconds: if last modified within this number of seconds, will not be deleted \"\"\" for pth in dir_path . rglob ( '*' ): if pth . is_file () and ( time . time () - pth . stat () . st_mtime ) > ttl_seconds : pth . unlink () @beartype def delete_dir ( dir_path : Path ) -> None : \"\"\"Delete the specified directory from a doit task. Args: dir_path: Path to directory to delete \"\"\" if dir_path . is_dir (): logger . info ( f 'Deleting ` { dir_path } `' , dir_path = dir_path ) shutil . rmtree ( dir_path ) @beartype def ensure_dir ( dir_path : Path ) -> None : \"\"\"Make sure that the specified dir_path exists and create any missing folders from a doit task. Args: dir_path: Path to directory that needs to exists \"\"\" logger . info ( f 'Creating ` { dir_path } `' , dir_path = dir_path ) dir_path . mkdir ( parents = True , exist_ok = True ) Variables \u2693\ufe0e ALLOWED_CHARS Default string of acceptable characters in a filename. Functions \u2693\ufe0e delete_dir \u2693\ufe0e def delete_dir ( dir_path : pathlib . Path ) -> None Delete the specified directory from a doit task. Parameters: Name Type Description Default dir_path None Path to directory to delete None View Source @beartype def delete_dir ( dir_path : Path ) -> None : \"\"\"Delete the specified directory from a doit task. Args: dir_path: Path to directory to delete \"\"\" if dir_path . is_dir (): logger . info ( f 'Deleting ` { dir_path } `' , dir_path = dir_path ) shutil . rmtree ( dir_path ) delete_old_files \u2693\ufe0e def delete_old_files ( dir_path : pathlib . Path , * , ttl_seconds : int ) -> None Delete old files within the specified directory. Parameters: Name Type Description Default dir_path None Path to directory to delete None ttl_seconds None if last modified within this number of seconds, will not be deleted None View Source @beartype def delete_old_files ( dir_path : Path , * , ttl_seconds : int ) -> None : \"\"\"Delete old files within the specified directory. Args: dir_path: Path to directory to delete ttl_seconds: if last modified within this number of seconds, will not be deleted \"\"\" for pth in dir_path . rglob ( '*' ): if pth . is_file () and ( time . time () - pth . stat () . st_mtime ) > ttl_seconds : pth . unlink () ensure_dir \u2693\ufe0e def ensure_dir ( dir_path : pathlib . Path ) -> None Make sure that the specified dir_path exists and create any missing folders from a doit task. Parameters: Name Type Description Default dir_path None Path to directory that needs to exists None View Source @beartype def ensure_dir ( dir_path : Path ) -> None : \"\"\"Make sure that the specified dir_path exists and create any missing folders from a doit task. Args: dir_path: Path to directory that needs to exists \"\"\" logger . info ( f 'Creating ` { dir_path } `' , dir_path = dir_path ) dir_path . mkdir ( parents = True , exist_ok = True ) get_doc_dir \u2693\ufe0e def get_doc_dir ( path_project : pathlib . Path ) -> pathlib . Path Retrieve the documentation directory from teh copier answer file. Default directory is \u201cdocs\u201d if not found Parameters: Name Type Description Default path_project None Path to the project directory with contains .copier-answers.yml None Returns: Type Description Path to the source documentation directory View Source @beartype def get_doc_dir ( path_project : Path ) -> Path : \"\"\"Retrieve the documentation directory from teh copier answer file. > Default directory is \"docs\" if not found Args: path_project: Path to the project directory with contains `.copier-answers.yml` Returns: Path: to the source documentation directory \"\"\" path_copier = path_project / _COPIER_ANSWERS_NAME return path_project / _read_yaml_file ( path_copier ) . get ( 'doc_dir' , 'docs' ) if_found_unlink \u2693\ufe0e def if_found_unlink ( path_file : pathlib . Path ) -> None Remove file if it exists. Function is intended to a doit action. Parameters: Name Type Description Default path_file None Path to file to remove None View Source @beartype def if_found_unlink ( path_file : Path ) -> None : \"\"\"Remove file if it exists. Function is intended to a doit action. Args: path_file: Path to file to remove \"\"\" if path_file . is_file (): logger . info ( f 'Deleting ` { path_file } `' , path_file = path_file ) path_file . unlink () read_lines \u2693\ufe0e def read_lines ( path_file : pathlib . Path ) -> List [ str ] Read a file and split on newlines for later parsing. Parameters: Name Type Description Default path_file None path to the file None Returns: Type Description List[str] lines of text as list View Source @beartype def read_lines ( path_file : Path ) -> List [ str ]: \"\"\"Read a file and split on newlines for later parsing. Args: path_file: path to the file Returns: List[str]: lines of text as list \"\"\" if path_file . is_file (): return path_file . read_text () . split ( ' \\n ' ) return [] sanitize_filename \u2693\ufe0e def sanitize_filename ( filename : str , repl_char : str = '_' , allowed_chars : str = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-_.' ) -> str Replace all characters not in the allow_chars with repl_char . Parameters: Name Type Description Default filename None string filename (stem and suffix only) None repl_char None replacement character. Default is _ None allowed_chars None all allowed characters. Default is ALLOWED_CHARS None Returns: Type Description str sanitized filename View Source @beartype def sanitize_filename ( filename : str , repl_char : str = '_' , allowed_chars : str = ALLOWED_CHARS ) -> str : \"\"\"Replace all characters not in the `allow_chars` with `repl_char`. Args: filename: string filename (stem and suffix only) repl_char: replacement character. Default is `_` allowed_chars: all allowed characters. Default is `ALLOWED_CHARS` Returns: str: sanitized filename \"\"\" return '' . join (( char if char in allowed_chars else repl_char ) for char in filename ) tail_lines \u2693\ufe0e def tail_lines ( path_file : pathlib . Path , * , count : int ) -> List [ str ] Tail a file for up to the last count (or full file) lines. Based on: https://stackoverflow.com/a/54278929 Tip: file_size = fh.tell() -or- os.fstat(fh.fileno()).st_size -or- return from fh.seek(0, os.SEEK_END) Parameters: Name Type Description Default path_file None path to the file None count None maximum number of lines to return None Returns: Type Description List[str] lines of text as list View Source @beartype def tail_lines ( path_file : Path , * , count : int ) -> List [ str ]: \"\"\"Tail a file for up to the last count (or full file) lines. Based on: https://stackoverflow.com/a/54278929 > Tip: `file_size = fh.tell()` -or- `os.fstat(fh.fileno()).st_size` -or- return from `fh.seek(0, os.SEEK_END)` Args: path_file: path to the file count: maximum number of lines to return Returns: List[str]: lines of text as list \"\"\" with open ( path_file , 'rb' ) as fh : rem_bytes = fh . seek ( 0 , os . SEEK_END ) step_size = 1 # Initially set to 1 so that the last byte is read found_lines = 0 while found_lines < count and rem_bytes >= step_size : rem_bytes = fh . seek ( - 1 * step_size , os . SEEK_CUR ) if fh . read ( 1 ) == b ' \\n ' : found_lines += 1 step_size = 2 # Increase so that repeats(read 1 / back 2) if rem_bytes < step_size : fh . seek ( 0 , os . SEEK_SET ) return [ line . rstrip ( ' \\r ' ) for line in fh . read () . decode () . split ( ' \\n ' )]","title":"calcipy.file_helpers"},{"location":"docs/modules/calcipy/file_helpers/#calcipyfile_helpers","text":"File Helpers. View Source \"\"\"File Helpers.\"\"\" import os import shutil import string import time from pathlib import Path from typing import Any , List import yaml from beartype import beartype from loguru import logger # ---------------------------------------------------------------------------------------------------------------------- # General ALLOWED_CHARS = string . ascii_lowercase + string . ascii_uppercase + string . digits + '-_.' \"\"\"Default string of acceptable characters in a filename.\"\"\" @beartype def sanitize_filename ( filename : str , repl_char : str = '_' , allowed_chars : str = ALLOWED_CHARS ) -> str : \"\"\"Replace all characters not in the `allow_chars` with `repl_char`. Args: filename: string filename (stem and suffix only) repl_char: replacement character. Default is `_` allowed_chars: all allowed characters. Default is `ALLOWED_CHARS` Returns: str: sanitized filename \"\"\" return '' . join (( char if char in allowed_chars else repl_char ) for char in filename ) _COPIER_ANSWERS_NAME = '.copier-answers.yml' \"\"\"Copier Answer file name.\"\"\" _MKDOCS_CONFIG_NAME = 'mkdocs.yml' \"\"\"Copier Answer file name.\"\"\" @beartype def _read_yaml_file ( path_yaml : Path ) -> Any : \"\"\"Attempt to read the specified yaml file. Returns an empty dictionary if not found or a parser error occurs. > Note: suppresses all tags in the YAML file Args: path_yaml: path to the yaml file Returns: dictionary representation of the source file \"\"\" # Based on: https://github.com/yaml/pyyaml/issues/86#issuecomment-380252434 yaml . add_multi_constructor ( '' , lambda loader , suffix , node : None ) try : return yaml . unsafe_load ( path_yaml . read_text ()) except ( FileNotFoundError , KeyError ) as err : # pragma: no cover logger . warning ( f 'Unexpected error reading the { path_yaml . name } file ( { path_yaml } ): { err } ' ) return {} @beartype def get_doc_dir ( path_project : Path ) -> Path : \"\"\"Retrieve the documentation directory from teh copier answer file. > Default directory is \"docs\" if not found Args: path_project: Path to the project directory with contains `.copier-answers.yml` Returns: Path: to the source documentation directory \"\"\" path_copier = path_project / _COPIER_ANSWERS_NAME return path_project / _read_yaml_file ( path_copier ) . get ( 'doc_dir' , 'docs' ) # ---------------------------------------------------------------------------------------------------------------------- # Read Files @beartype def read_lines ( path_file : Path ) -> List [ str ]: \"\"\"Read a file and split on newlines for later parsing. Args: path_file: path to the file Returns: List[str]: lines of text as list \"\"\" if path_file . is_file (): return path_file . read_text () . split ( ' \\n ' ) return [] @beartype def tail_lines ( path_file : Path , * , count : int ) -> List [ str ]: \"\"\"Tail a file for up to the last count (or full file) lines. Based on: https://stackoverflow.com/a/54278929 > Tip: `file_size = fh.tell()` -or- `os.fstat(fh.fileno()).st_size` -or- return from `fh.seek(0, os.SEEK_END)` Args: path_file: path to the file count: maximum number of lines to return Returns: List[str]: lines of text as list \"\"\" with open ( path_file , 'rb' ) as fh : rem_bytes = fh . seek ( 0 , os . SEEK_END ) step_size = 1 # Initially set to 1 so that the last byte is read found_lines = 0 while found_lines < count and rem_bytes >= step_size : rem_bytes = fh . seek ( - 1 * step_size , os . SEEK_CUR ) if fh . read ( 1 ) == b ' \\n ' : found_lines += 1 step_size = 2 # Increase so that repeats(read 1 / back 2) if rem_bytes < step_size : fh . seek ( 0 , os . SEEK_SET ) return [ line . rstrip ( ' \\r ' ) for line in fh . read () . decode () . split ( ' \\n ' )] # ---------------------------------------------------------------------------------------------------------------------- # Manage Files and Directories @beartype def if_found_unlink ( path_file : Path ) -> None : \"\"\"Remove file if it exists. Function is intended to a doit action. Args: path_file: Path to file to remove \"\"\" if path_file . is_file (): logger . info ( f 'Deleting ` { path_file } `' , path_file = path_file ) path_file . unlink () @beartype def delete_old_files ( dir_path : Path , * , ttl_seconds : int ) -> None : \"\"\"Delete old files within the specified directory. Args: dir_path: Path to directory to delete ttl_seconds: if last modified within this number of seconds, will not be deleted \"\"\" for pth in dir_path . rglob ( '*' ): if pth . is_file () and ( time . time () - pth . stat () . st_mtime ) > ttl_seconds : pth . unlink () @beartype def delete_dir ( dir_path : Path ) -> None : \"\"\"Delete the specified directory from a doit task. Args: dir_path: Path to directory to delete \"\"\" if dir_path . is_dir (): logger . info ( f 'Deleting ` { dir_path } `' , dir_path = dir_path ) shutil . rmtree ( dir_path ) @beartype def ensure_dir ( dir_path : Path ) -> None : \"\"\"Make sure that the specified dir_path exists and create any missing folders from a doit task. Args: dir_path: Path to directory that needs to exists \"\"\" logger . info ( f 'Creating ` { dir_path } `' , dir_path = dir_path ) dir_path . mkdir ( parents = True , exist_ok = True )","title":"calcipy.file_helpers"},{"location":"docs/modules/calcipy/file_helpers/#variables","text":"ALLOWED_CHARS Default string of acceptable characters in a filename.","title":"Variables"},{"location":"docs/modules/calcipy/file_helpers/#functions","text":"","title":"Functions"},{"location":"docs/modules/calcipy/file_helpers/#delete_dir","text":"def delete_dir ( dir_path : pathlib . Path ) -> None Delete the specified directory from a doit task. Parameters: Name Type Description Default dir_path None Path to directory to delete None View Source @beartype def delete_dir ( dir_path : Path ) -> None : \"\"\"Delete the specified directory from a doit task. Args: dir_path: Path to directory to delete \"\"\" if dir_path . is_dir (): logger . info ( f 'Deleting ` { dir_path } `' , dir_path = dir_path ) shutil . rmtree ( dir_path )","title":"delete_dir"},{"location":"docs/modules/calcipy/file_helpers/#delete_old_files","text":"def delete_old_files ( dir_path : pathlib . Path , * , ttl_seconds : int ) -> None Delete old files within the specified directory. Parameters: Name Type Description Default dir_path None Path to directory to delete None ttl_seconds None if last modified within this number of seconds, will not be deleted None View Source @beartype def delete_old_files ( dir_path : Path , * , ttl_seconds : int ) -> None : \"\"\"Delete old files within the specified directory. Args: dir_path: Path to directory to delete ttl_seconds: if last modified within this number of seconds, will not be deleted \"\"\" for pth in dir_path . rglob ( '*' ): if pth . is_file () and ( time . time () - pth . stat () . st_mtime ) > ttl_seconds : pth . unlink ()","title":"delete_old_files"},{"location":"docs/modules/calcipy/file_helpers/#ensure_dir","text":"def ensure_dir ( dir_path : pathlib . Path ) -> None Make sure that the specified dir_path exists and create any missing folders from a doit task. Parameters: Name Type Description Default dir_path None Path to directory that needs to exists None View Source @beartype def ensure_dir ( dir_path : Path ) -> None : \"\"\"Make sure that the specified dir_path exists and create any missing folders from a doit task. Args: dir_path: Path to directory that needs to exists \"\"\" logger . info ( f 'Creating ` { dir_path } `' , dir_path = dir_path ) dir_path . mkdir ( parents = True , exist_ok = True )","title":"ensure_dir"},{"location":"docs/modules/calcipy/file_helpers/#get_doc_dir","text":"def get_doc_dir ( path_project : pathlib . Path ) -> pathlib . Path Retrieve the documentation directory from teh copier answer file. Default directory is \u201cdocs\u201d if not found Parameters: Name Type Description Default path_project None Path to the project directory with contains .copier-answers.yml None Returns: Type Description Path to the source documentation directory View Source @beartype def get_doc_dir ( path_project : Path ) -> Path : \"\"\"Retrieve the documentation directory from teh copier answer file. > Default directory is \"docs\" if not found Args: path_project: Path to the project directory with contains `.copier-answers.yml` Returns: Path: to the source documentation directory \"\"\" path_copier = path_project / _COPIER_ANSWERS_NAME return path_project / _read_yaml_file ( path_copier ) . get ( 'doc_dir' , 'docs' )","title":"get_doc_dir"},{"location":"docs/modules/calcipy/file_helpers/#if_found_unlink","text":"def if_found_unlink ( path_file : pathlib . Path ) -> None Remove file if it exists. Function is intended to a doit action. Parameters: Name Type Description Default path_file None Path to file to remove None View Source @beartype def if_found_unlink ( path_file : Path ) -> None : \"\"\"Remove file if it exists. Function is intended to a doit action. Args: path_file: Path to file to remove \"\"\" if path_file . is_file (): logger . info ( f 'Deleting ` { path_file } `' , path_file = path_file ) path_file . unlink ()","title":"if_found_unlink"},{"location":"docs/modules/calcipy/file_helpers/#read_lines","text":"def read_lines ( path_file : pathlib . Path ) -> List [ str ] Read a file and split on newlines for later parsing. Parameters: Name Type Description Default path_file None path to the file None Returns: Type Description List[str] lines of text as list View Source @beartype def read_lines ( path_file : Path ) -> List [ str ]: \"\"\"Read a file and split on newlines for later parsing. Args: path_file: path to the file Returns: List[str]: lines of text as list \"\"\" if path_file . is_file (): return path_file . read_text () . split ( ' \\n ' ) return []","title":"read_lines"},{"location":"docs/modules/calcipy/file_helpers/#sanitize_filename","text":"def sanitize_filename ( filename : str , repl_char : str = '_' , allowed_chars : str = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-_.' ) -> str Replace all characters not in the allow_chars with repl_char . Parameters: Name Type Description Default filename None string filename (stem and suffix only) None repl_char None replacement character. Default is _ None allowed_chars None all allowed characters. Default is ALLOWED_CHARS None Returns: Type Description str sanitized filename View Source @beartype def sanitize_filename ( filename : str , repl_char : str = '_' , allowed_chars : str = ALLOWED_CHARS ) -> str : \"\"\"Replace all characters not in the `allow_chars` with `repl_char`. Args: filename: string filename (stem and suffix only) repl_char: replacement character. Default is `_` allowed_chars: all allowed characters. Default is `ALLOWED_CHARS` Returns: str: sanitized filename \"\"\" return '' . join (( char if char in allowed_chars else repl_char ) for char in filename )","title":"sanitize_filename"},{"location":"docs/modules/calcipy/file_helpers/#tail_lines","text":"def tail_lines ( path_file : pathlib . Path , * , count : int ) -> List [ str ] Tail a file for up to the last count (or full file) lines. Based on: https://stackoverflow.com/a/54278929 Tip: file_size = fh.tell() -or- os.fstat(fh.fileno()).st_size -or- return from fh.seek(0, os.SEEK_END) Parameters: Name Type Description Default path_file None path to the file None count None maximum number of lines to return None Returns: Type Description List[str] lines of text as list View Source @beartype def tail_lines ( path_file : Path , * , count : int ) -> List [ str ]: \"\"\"Tail a file for up to the last count (or full file) lines. Based on: https://stackoverflow.com/a/54278929 > Tip: `file_size = fh.tell()` -or- `os.fstat(fh.fileno()).st_size` -or- return from `fh.seek(0, os.SEEK_END)` Args: path_file: path to the file count: maximum number of lines to return Returns: List[str]: lines of text as list \"\"\" with open ( path_file , 'rb' ) as fh : rem_bytes = fh . seek ( 0 , os . SEEK_END ) step_size = 1 # Initially set to 1 so that the last byte is read found_lines = 0 while found_lines < count and rem_bytes >= step_size : rem_bytes = fh . seek ( - 1 * step_size , os . SEEK_CUR ) if fh . read ( 1 ) == b ' \\n ' : found_lines += 1 step_size = 2 # Increase so that repeats(read 1 / back 2) if rem_bytes < step_size : fh . seek ( 0 , os . SEEK_SET ) return [ line . rstrip ( ' \\r ' ) for line in fh . read () . decode () . split ( ' \\n ' )]","title":"tail_lines"},{"location":"docs/modules/calcipy/log_helpers/","text":"calcipy.log_helpers \u2693\ufe0e Loguru Helpers. View Source \"\"\"Loguru Helpers.\"\"\" from __future__ import annotations import logging import sys import time from inspect import signature from pathlib import Path from typing import Any , Callable , Dict , Generator , Iterable , List , Optional import loguru from beartype import beartype from decorator import contextmanager , decorator from loguru import logger from .file_helpers import delete_old_files try : from preconvert.output import simplejson as json except ImportError : # pragma: no cover import json # type: ignore[no-redef] @beartype def serializable_compact ( record : Dict [ str , Any ]) -> str : \"\"\"Loguru formatter to return a compact JSON string for JSONLines output. `record` documentation: https://loguru.readthedocs.io/en/stable/api/logger.html#record Based on the `_serialize_record` method: https://github.com/Delgan/loguru/blob/44f6771/loguru/_handler.py#L222 ```py from calcipy.log_helpers import serializable_compact logger.add(LOG_DIR / 'pkg-compact-{time}.jsonl', mode='w', level=logging.INFO, format=serializable_compact) ``` Args: record: dictionary passed by loguru for formatting Returns: str: dumped JSON without newlines \"\"\" exception = record [ 'exception' ] if exception : exception = { 'type' : None if exception . type is None else exception . type . __name__ , 'value' : exception . value , 'traceback' : bool ( record [ 'exception' ] . traceback ), } simplified = { 'record' : { 'exception' : exception , 'extra' : record [ 'extra' ], 'file' : { 'path' : record [ 'file' ] . path }, 'function' : record [ 'function' ] . strip ( '<>' ), 'level' : { 'name' : record [ 'level' ] . name }, 'line' : record [ 'line' ], 'message' : record [ 'message' ], 'module' : record [ 'module' ], 'name' : record [ 'name' ], 'time' : { 'timestamp' : record [ 'time' ] . timestamp ()}, }, } str_json : str = json . dumps ( simplified , default = str ) . replace ( '{' , '{{' ) . replace ( '}' , '}}' ) return str_json + ' \\n ' # Note: loguru.Logger is PEP563 Postponed and can't be use with beartype runtime def _log_action ( message : str , level : str = 'INFO' , _logger : loguru . Logger = logger , ** kwargs : Any , ) -> Generator [ loguru . Logger , None , None ]: \"\"\"Log the beggining and end of an action. Args: message: string message to describe the context level: log level. Default is `INFO` _logger: Optional logger instance kwargs: function keyword arguments passed to the start log statement Yields: yields the logger instance \"\"\" start_time = time . time_ns () _logger . log ( level , f '(start) { message } ' , start_time = start_time , ** kwargs ) yield _logger runtime = time . time_ns () - start_time _logger . log ( level , f '(end) { message } ' , start_time = start_time , runtime = runtime ) # When using `contextmanager` as a decorator, Deepsource won't see the __enter__/__exit__ methods (PYL-E1129) # Rather than skipping each use of log_action, use `contextmanager` as a function log_action = contextmanager ( _log_action ) @decorator def log_fun ( fun : Callable [[ Any ], Any ], * args : Iterable [ Any ], ** kwargs : Any ) -> Any : \"\"\"Decorate a function to log the function name and completed time. Args: fun: the decorated function args: functional arguments kwargs: function keyword arguments Returns: Any: result of the function \"\"\" fun_name = fun . __name__ with log_action ( f 'Running { fun_name }{ signature ( fun ) } ' , args = args , kwargs = kwargs ): return fun ( * args , ** kwargs ) # type: ignore[call-arg] _LOG_SUB_DIR = '.logs' \"\"\"Subdirectory to store log files relative to the project directory.\"\"\" @beartype def build_logger_config ( path_parent : Optional [ Path ] = None , * , production : bool = True ) -> Dict [ str , Any ]: \"\"\"Build the loguru configuration. Use with `loguru.configure(**configuration)`. ```py # Typical example enabling loguru for a package from pathlib import Path from loguru import logger from calcipy import __pkg_name__ from calcipy.log_helpers import build_logger_config logger.enable(__pkg_name__) # This will enable output from calcipy, which is off by default # See an example of toggling loguru at: https://github.com/KyleKing/calcipy/tree/examples/loguru-toggle path_parent = Path(__file__).resolve().parent log_config = build_logger_config(path_parent, production=False) logger.configure(**log_config) logger.info('Started logging to {path_parent}/.logs with {log_config}', path_parent=path_parent, log_config=log_config) ``` Args: path_parent: Path to the directory where the '.logs/' folder should be created. Default is this package production: if True, will tweak logging configuration for production code. Default is True Returns: Dict[str, Any]: the logger configuration as a dictionary \"\"\" if path_parent is None : path_parent = Path ( __file__ ) . resolve () . parent log_dir = path_parent / _LOG_SUB_DIR log_dir . mkdir ( exist_ok = True , parents = True ) logger . info ( f 'Started logging to { log_dir } (production= { production } )' ) log_level = logging . INFO if production else logging . DEBUG jsonl_handler = { 'sink' : log_dir / 'debug- {time} .jsonl' , 'mode' : 'w' , 'level' : log_level , 'rotation' : '1h' , 'backtrace' : True , 'diagnose' : not production , } if production : jsonl_handler [ 'format' ] = serializable_compact else : jsonl_handler [ 'serialize' ] = True return { 'handlers' : [ { 'sink' : sys . stdout , 'level' : logging . WARNING if production else logging . INFO , 'backtrace' : True , 'diagnose' : not production , }, jsonl_handler , { 'sink' : log_dir / 'debug- {time} .log' , 'mode' : 'w' , 'level' : log_level , 'rotation' : '1h' , 'backtrace' : True , 'diagnose' : not production , }, ], } @beartype def activate_debug_logging ( * , pkg_names : List [ str ], path_project : Optional [ Path ] = None , clear_log : bool = False , ) -> None : \"\"\"Wrap `build_logger_config` to configure verbose logging for debug use. Args: pkg_names: list of string package names to activate. If empty, likely no log output. path_project: path to the project directory. Defaults to `CWD` if not specified clear_log: if True, delete all log files that haven't been updated for at least an hour. Default is False \"\"\" if not path_project : path_project = Path . cwd () # See an example of toggling loguru at: https://github.com/KyleKing/calcipy/tree/examples/loguru-toggle for pkg_name in pkg_names : logger . enable ( pkg_name ) if clear_log : hour = 3600 delete_old_files ( path_project / _LOG_SUB_DIR , ttl_seconds = hour ) log_config = build_logger_config ( path_project , production = False ) logger . configure ( ** log_config ) logger . debug ( 'Started logging to {path_project} /.logs with {log_config} ' , path_project = path_project , log_config = log_config , ) Functions \u2693\ufe0e activate_debug_logging \u2693\ufe0e def activate_debug_logging ( * , pkg_names : List [ str ], path_project : Union [ pathlib . Path , NoneType ] = None , clear_log : bool = False ) -> None Wrap build_logger_config to configure verbose logging for debug use. Parameters: Name Type Description Default pkg_names None list of string package names to activate. If empty, likely no log output. None path_project None path to the project directory. Defaults to CWD if not specified None clear_log None if True, delete all log files that haven\u2019t been updated for at least an hour. Default is False None View Source @beartype def activate_debug_logging ( * , pkg_names : List [ str ], path_project : Optional [ Path ] = None , clear_log : bool = False , ) -> None : \"\"\"Wrap `build_logger_config` to configure verbose logging for debug use. Args: pkg_names: list of string package names to activate. If empty, likely no log output. path_project: path to the project directory. Defaults to `CWD` if not specified clear_log: if True, delete all log files that haven't been updated for at least an hour. Default is False \"\"\" if not path_project : path_project = Path . cwd () # See an example of toggling loguru at: https://github.com/KyleKing/calcipy/tree/examples/loguru-toggle for pkg_name in pkg_names : logger . enable ( pkg_name ) if clear_log : hour = 3600 delete_old_files ( path_project / _LOG_SUB_DIR , ttl_seconds = hour ) log_config = build_logger_config ( path_project , production = False ) logger . configure ( ** log_config ) logger . debug ( 'Started logging to {path_project} /.logs with {log_config} ' , path_project = path_project , log_config = log_config , ) build_logger_config \u2693\ufe0e def build_logger_config ( path_parent : Union [ pathlib . Path , NoneType ] = None , * , production : bool = True ) -> Dict [ str , Any ] Build the loguru configuration. Use with loguru.configure(**configuration) . # Typical example enabling loguru for a package from pathlib import Path from loguru import logger from calcipy import __pkg_name__ from calcipy.log_helpers import build_logger_config logger . enable ( __pkg_name__ ) # This will enable output from calcipy, which is off by default # See an example of toggling loguru at: https://github.com/KyleKing/calcipy/tree/examples/loguru-toggle path_parent = Path ( __file__ ) . resolve () . parent log_config = build_logger_config ( path_parent , production = False ) logger . configure ( ** log_config ) logger . info ( 'Started logging to {path_parent} /.logs with {log_config} ' , path_parent = path_parent , log_config = log_config ) Parameters: Name Type Description Default path_parent None Path to the directory where the \u2018.logs/\u2019 folder should be created. Default is this package None production None if True, will tweak logging configuration for production code. Default is True None Returns: Type Description Dict[str, Any] the logger configuration as a dictionary View Source @beartype def build_logger_config ( path_parent : Optional [ Path ] = None , * , production : bool = True ) -> Dict [ str , Any ]: \"\"\"Build the loguru configuration. Use with `loguru.configure(**configuration)`. ```py # Typical example enabling loguru for a package from pathlib import Path from loguru import logger from calcipy import __pkg_name__ from calcipy.log_helpers import build_logger_config logger.enable(__pkg_name__) # This will enable output from calcipy, which is off by default # See an example of toggling loguru at: https://github.com/KyleKing/calcipy/tree/examples/loguru-toggle path_parent = Path(__file__).resolve().parent log_config = build_logger_config(path_parent, production=False) logger.configure(**log_config) logger.info('Started logging to {path_parent}/.logs with {log_config}', path_parent=path_parent, log_config=log_config) ``` Args: path_parent: Path to the directory where the '.logs/' folder should be created. Default is this package production: if True, will tweak logging configuration for production code. Default is True Returns: Dict[str, Any]: the logger configuration as a dictionary \"\"\" if path_parent is None : path_parent = Path ( __file__ ) . resolve () . parent log_dir = path_parent / _LOG_SUB_DIR log_dir . mkdir ( exist_ok = True , parents = True ) logger . info ( f 'Started logging to { log_dir } (production= { production } )' ) log_level = logging . INFO if production else logging . DEBUG jsonl_handler = { 'sink' : log_dir / 'debug- {time} .jsonl' , 'mode' : 'w' , 'level' : log_level , 'rotation' : '1h' , 'backtrace' : True , 'diagnose' : not production , } if production : jsonl_handler [ 'format' ] = serializable_compact else : jsonl_handler [ 'serialize' ] = True return { 'handlers' : [ { 'sink' : sys . stdout , 'level' : logging . WARNING if production else logging . INFO , 'backtrace' : True , 'diagnose' : not production , }, jsonl_handler , { 'sink' : log_dir / 'debug- {time} .log' , 'mode' : 'w' , 'level' : log_level , 'rotation' : '1h' , 'backtrace' : True , 'diagnose' : not production , }, ], } log_action \u2693\ufe0e def log_action ( message : 'str' , level : 'str' = 'INFO' , _logger : 'loguru.Logger' = < loguru . logger handlers = [( id = 0 , level = 10 , sink =< stderr > )] > , ** kwargs : 'Any' ) -> 'Generator[loguru.Logger, None, None]' Log the beggining and end of an action. Parameters: Name Type Description Default message None string message to describe the context None level None log level. Default is INFO None _logger None Optional logger instance None kwargs None function keyword arguments passed to the start log statement None Yields: Type Description None yields the logger instance View Source def _log_action ( message : str , level : str = 'INFO' , _logger : loguru . Logger = logger , ** kwargs : Any , ) -> Generator [ loguru . Logger , None , None ]: \"\"\"Log the beggining and end of an action. Args: message: string message to describe the context level: log level. Default is `INFO` _logger: Optional logger instance kwargs: function keyword arguments passed to the start log statement Yields: yields the logger instance \"\"\" start_time = time . time_ns () _logger . log ( level , f '(start) { message } ' , start_time = start_time , ** kwargs ) yield _logger runtime = time . time_ns () - start_time _logger . log ( level , f '(end) { message } ' , start_time = start_time , runtime = runtime ) serializable_compact \u2693\ufe0e def serializable_compact ( record : Dict [ str , Any ] ) -> str Loguru formatter to return a compact JSON string for JSONLines output. record documentation: https://loguru.readthedocs.io/en/stable/api/logger.html#record Based on the _serialize_record method: https://github.com/Delgan/loguru/blob/44f6771/loguru/_handler.py#L222 from calcipy.log_helpers import serializable_compact logger . add ( LOG_DIR / 'pkg-compact- {time} .jsonl' , mode = 'w' , level = logging . INFO , format = serializable_compact ) Parameters: Name Type Description Default record None dictionary passed by loguru for formatting None Returns: Type Description str dumped JSON without newlines View Source @beartype def serializable_compact ( record : Dict [ str , Any ]) -> str : \"\"\"Loguru formatter to return a compact JSON string for JSONLines output. `record` documentation: https://loguru.readthedocs.io/en/stable/api/logger.html#record Based on the `_serialize_record` method: https://github.com/Delgan/loguru/blob/44f6771/loguru/_handler.py#L222 ```py from calcipy.log_helpers import serializable_compact logger.add(LOG_DIR / 'pkg-compact-{time}.jsonl', mode='w', level=logging.INFO, format=serializable_compact) ``` Args: record: dictionary passed by loguru for formatting Returns: str: dumped JSON without newlines \"\"\" exception = record [ 'exception' ] if exception : exception = { 'type' : None if exception . type is None else exception . type . __name__ , 'value' : exception . value , 'traceback' : bool ( record [ 'exception' ] . traceback ), } simplified = { 'record' : { 'exception' : exception , 'extra' : record [ 'extra' ], 'file' : { 'path' : record [ 'file' ] . path }, 'function' : record [ 'function' ] . strip ( '<>' ), 'level' : { 'name' : record [ 'level' ] . name }, 'line' : record [ 'line' ], 'message' : record [ 'message' ], 'module' : record [ 'module' ], 'name' : record [ 'name' ], 'time' : { 'timestamp' : record [ 'time' ] . timestamp ()}, }, } str_json : str = json . dumps ( simplified , default = str ) . replace ( '{' , '{{' ) . replace ( '}' , '}}' ) return str_json + ' \\n '","title":"calcipy.log_helpers"},{"location":"docs/modules/calcipy/log_helpers/#calcipylog_helpers","text":"Loguru Helpers. View Source \"\"\"Loguru Helpers.\"\"\" from __future__ import annotations import logging import sys import time from inspect import signature from pathlib import Path from typing import Any , Callable , Dict , Generator , Iterable , List , Optional import loguru from beartype import beartype from decorator import contextmanager , decorator from loguru import logger from .file_helpers import delete_old_files try : from preconvert.output import simplejson as json except ImportError : # pragma: no cover import json # type: ignore[no-redef] @beartype def serializable_compact ( record : Dict [ str , Any ]) -> str : \"\"\"Loguru formatter to return a compact JSON string for JSONLines output. `record` documentation: https://loguru.readthedocs.io/en/stable/api/logger.html#record Based on the `_serialize_record` method: https://github.com/Delgan/loguru/blob/44f6771/loguru/_handler.py#L222 ```py from calcipy.log_helpers import serializable_compact logger.add(LOG_DIR / 'pkg-compact-{time}.jsonl', mode='w', level=logging.INFO, format=serializable_compact) ``` Args: record: dictionary passed by loguru for formatting Returns: str: dumped JSON without newlines \"\"\" exception = record [ 'exception' ] if exception : exception = { 'type' : None if exception . type is None else exception . type . __name__ , 'value' : exception . value , 'traceback' : bool ( record [ 'exception' ] . traceback ), } simplified = { 'record' : { 'exception' : exception , 'extra' : record [ 'extra' ], 'file' : { 'path' : record [ 'file' ] . path }, 'function' : record [ 'function' ] . strip ( '<>' ), 'level' : { 'name' : record [ 'level' ] . name }, 'line' : record [ 'line' ], 'message' : record [ 'message' ], 'module' : record [ 'module' ], 'name' : record [ 'name' ], 'time' : { 'timestamp' : record [ 'time' ] . timestamp ()}, }, } str_json : str = json . dumps ( simplified , default = str ) . replace ( '{' , '{{' ) . replace ( '}' , '}}' ) return str_json + ' \\n ' # Note: loguru.Logger is PEP563 Postponed and can't be use with beartype runtime def _log_action ( message : str , level : str = 'INFO' , _logger : loguru . Logger = logger , ** kwargs : Any , ) -> Generator [ loguru . Logger , None , None ]: \"\"\"Log the beggining and end of an action. Args: message: string message to describe the context level: log level. Default is `INFO` _logger: Optional logger instance kwargs: function keyword arguments passed to the start log statement Yields: yields the logger instance \"\"\" start_time = time . time_ns () _logger . log ( level , f '(start) { message } ' , start_time = start_time , ** kwargs ) yield _logger runtime = time . time_ns () - start_time _logger . log ( level , f '(end) { message } ' , start_time = start_time , runtime = runtime ) # When using `contextmanager` as a decorator, Deepsource won't see the __enter__/__exit__ methods (PYL-E1129) # Rather than skipping each use of log_action, use `contextmanager` as a function log_action = contextmanager ( _log_action ) @decorator def log_fun ( fun : Callable [[ Any ], Any ], * args : Iterable [ Any ], ** kwargs : Any ) -> Any : \"\"\"Decorate a function to log the function name and completed time. Args: fun: the decorated function args: functional arguments kwargs: function keyword arguments Returns: Any: result of the function \"\"\" fun_name = fun . __name__ with log_action ( f 'Running { fun_name }{ signature ( fun ) } ' , args = args , kwargs = kwargs ): return fun ( * args , ** kwargs ) # type: ignore[call-arg] _LOG_SUB_DIR = '.logs' \"\"\"Subdirectory to store log files relative to the project directory.\"\"\" @beartype def build_logger_config ( path_parent : Optional [ Path ] = None , * , production : bool = True ) -> Dict [ str , Any ]: \"\"\"Build the loguru configuration. Use with `loguru.configure(**configuration)`. ```py # Typical example enabling loguru for a package from pathlib import Path from loguru import logger from calcipy import __pkg_name__ from calcipy.log_helpers import build_logger_config logger.enable(__pkg_name__) # This will enable output from calcipy, which is off by default # See an example of toggling loguru at: https://github.com/KyleKing/calcipy/tree/examples/loguru-toggle path_parent = Path(__file__).resolve().parent log_config = build_logger_config(path_parent, production=False) logger.configure(**log_config) logger.info('Started logging to {path_parent}/.logs with {log_config}', path_parent=path_parent, log_config=log_config) ``` Args: path_parent: Path to the directory where the '.logs/' folder should be created. Default is this package production: if True, will tweak logging configuration for production code. Default is True Returns: Dict[str, Any]: the logger configuration as a dictionary \"\"\" if path_parent is None : path_parent = Path ( __file__ ) . resolve () . parent log_dir = path_parent / _LOG_SUB_DIR log_dir . mkdir ( exist_ok = True , parents = True ) logger . info ( f 'Started logging to { log_dir } (production= { production } )' ) log_level = logging . INFO if production else logging . DEBUG jsonl_handler = { 'sink' : log_dir / 'debug- {time} .jsonl' , 'mode' : 'w' , 'level' : log_level , 'rotation' : '1h' , 'backtrace' : True , 'diagnose' : not production , } if production : jsonl_handler [ 'format' ] = serializable_compact else : jsonl_handler [ 'serialize' ] = True return { 'handlers' : [ { 'sink' : sys . stdout , 'level' : logging . WARNING if production else logging . INFO , 'backtrace' : True , 'diagnose' : not production , }, jsonl_handler , { 'sink' : log_dir / 'debug- {time} .log' , 'mode' : 'w' , 'level' : log_level , 'rotation' : '1h' , 'backtrace' : True , 'diagnose' : not production , }, ], } @beartype def activate_debug_logging ( * , pkg_names : List [ str ], path_project : Optional [ Path ] = None , clear_log : bool = False , ) -> None : \"\"\"Wrap `build_logger_config` to configure verbose logging for debug use. Args: pkg_names: list of string package names to activate. If empty, likely no log output. path_project: path to the project directory. Defaults to `CWD` if not specified clear_log: if True, delete all log files that haven't been updated for at least an hour. Default is False \"\"\" if not path_project : path_project = Path . cwd () # See an example of toggling loguru at: https://github.com/KyleKing/calcipy/tree/examples/loguru-toggle for pkg_name in pkg_names : logger . enable ( pkg_name ) if clear_log : hour = 3600 delete_old_files ( path_project / _LOG_SUB_DIR , ttl_seconds = hour ) log_config = build_logger_config ( path_project , production = False ) logger . configure ( ** log_config ) logger . debug ( 'Started logging to {path_project} /.logs with {log_config} ' , path_project = path_project , log_config = log_config , )","title":"calcipy.log_helpers"},{"location":"docs/modules/calcipy/log_helpers/#functions","text":"","title":"Functions"},{"location":"docs/modules/calcipy/log_helpers/#activate_debug_logging","text":"def activate_debug_logging ( * , pkg_names : List [ str ], path_project : Union [ pathlib . Path , NoneType ] = None , clear_log : bool = False ) -> None Wrap build_logger_config to configure verbose logging for debug use. Parameters: Name Type Description Default pkg_names None list of string package names to activate. If empty, likely no log output. None path_project None path to the project directory. Defaults to CWD if not specified None clear_log None if True, delete all log files that haven\u2019t been updated for at least an hour. Default is False None View Source @beartype def activate_debug_logging ( * , pkg_names : List [ str ], path_project : Optional [ Path ] = None , clear_log : bool = False , ) -> None : \"\"\"Wrap `build_logger_config` to configure verbose logging for debug use. Args: pkg_names: list of string package names to activate. If empty, likely no log output. path_project: path to the project directory. Defaults to `CWD` if not specified clear_log: if True, delete all log files that haven't been updated for at least an hour. Default is False \"\"\" if not path_project : path_project = Path . cwd () # See an example of toggling loguru at: https://github.com/KyleKing/calcipy/tree/examples/loguru-toggle for pkg_name in pkg_names : logger . enable ( pkg_name ) if clear_log : hour = 3600 delete_old_files ( path_project / _LOG_SUB_DIR , ttl_seconds = hour ) log_config = build_logger_config ( path_project , production = False ) logger . configure ( ** log_config ) logger . debug ( 'Started logging to {path_project} /.logs with {log_config} ' , path_project = path_project , log_config = log_config , )","title":"activate_debug_logging"},{"location":"docs/modules/calcipy/log_helpers/#build_logger_config","text":"def build_logger_config ( path_parent : Union [ pathlib . Path , NoneType ] = None , * , production : bool = True ) -> Dict [ str , Any ] Build the loguru configuration. Use with loguru.configure(**configuration) . # Typical example enabling loguru for a package from pathlib import Path from loguru import logger from calcipy import __pkg_name__ from calcipy.log_helpers import build_logger_config logger . enable ( __pkg_name__ ) # This will enable output from calcipy, which is off by default # See an example of toggling loguru at: https://github.com/KyleKing/calcipy/tree/examples/loguru-toggle path_parent = Path ( __file__ ) . resolve () . parent log_config = build_logger_config ( path_parent , production = False ) logger . configure ( ** log_config ) logger . info ( 'Started logging to {path_parent} /.logs with {log_config} ' , path_parent = path_parent , log_config = log_config ) Parameters: Name Type Description Default path_parent None Path to the directory where the \u2018.logs/\u2019 folder should be created. Default is this package None production None if True, will tweak logging configuration for production code. Default is True None Returns: Type Description Dict[str, Any] the logger configuration as a dictionary View Source @beartype def build_logger_config ( path_parent : Optional [ Path ] = None , * , production : bool = True ) -> Dict [ str , Any ]: \"\"\"Build the loguru configuration. Use with `loguru.configure(**configuration)`. ```py # Typical example enabling loguru for a package from pathlib import Path from loguru import logger from calcipy import __pkg_name__ from calcipy.log_helpers import build_logger_config logger.enable(__pkg_name__) # This will enable output from calcipy, which is off by default # See an example of toggling loguru at: https://github.com/KyleKing/calcipy/tree/examples/loguru-toggle path_parent = Path(__file__).resolve().parent log_config = build_logger_config(path_parent, production=False) logger.configure(**log_config) logger.info('Started logging to {path_parent}/.logs with {log_config}', path_parent=path_parent, log_config=log_config) ``` Args: path_parent: Path to the directory where the '.logs/' folder should be created. Default is this package production: if True, will tweak logging configuration for production code. Default is True Returns: Dict[str, Any]: the logger configuration as a dictionary \"\"\" if path_parent is None : path_parent = Path ( __file__ ) . resolve () . parent log_dir = path_parent / _LOG_SUB_DIR log_dir . mkdir ( exist_ok = True , parents = True ) logger . info ( f 'Started logging to { log_dir } (production= { production } )' ) log_level = logging . INFO if production else logging . DEBUG jsonl_handler = { 'sink' : log_dir / 'debug- {time} .jsonl' , 'mode' : 'w' , 'level' : log_level , 'rotation' : '1h' , 'backtrace' : True , 'diagnose' : not production , } if production : jsonl_handler [ 'format' ] = serializable_compact else : jsonl_handler [ 'serialize' ] = True return { 'handlers' : [ { 'sink' : sys . stdout , 'level' : logging . WARNING if production else logging . INFO , 'backtrace' : True , 'diagnose' : not production , }, jsonl_handler , { 'sink' : log_dir / 'debug- {time} .log' , 'mode' : 'w' , 'level' : log_level , 'rotation' : '1h' , 'backtrace' : True , 'diagnose' : not production , }, ], }","title":"build_logger_config"},{"location":"docs/modules/calcipy/log_helpers/#log_action","text":"def log_action ( message : 'str' , level : 'str' = 'INFO' , _logger : 'loguru.Logger' = < loguru . logger handlers = [( id = 0 , level = 10 , sink =< stderr > )] > , ** kwargs : 'Any' ) -> 'Generator[loguru.Logger, None, None]' Log the beggining and end of an action. Parameters: Name Type Description Default message None string message to describe the context None level None log level. Default is INFO None _logger None Optional logger instance None kwargs None function keyword arguments passed to the start log statement None Yields: Type Description None yields the logger instance View Source def _log_action ( message : str , level : str = 'INFO' , _logger : loguru . Logger = logger , ** kwargs : Any , ) -> Generator [ loguru . Logger , None , None ]: \"\"\"Log the beggining and end of an action. Args: message: string message to describe the context level: log level. Default is `INFO` _logger: Optional logger instance kwargs: function keyword arguments passed to the start log statement Yields: yields the logger instance \"\"\" start_time = time . time_ns () _logger . log ( level , f '(start) { message } ' , start_time = start_time , ** kwargs ) yield _logger runtime = time . time_ns () - start_time _logger . log ( level , f '(end) { message } ' , start_time = start_time , runtime = runtime )","title":"log_action"},{"location":"docs/modules/calcipy/log_helpers/#serializable_compact","text":"def serializable_compact ( record : Dict [ str , Any ] ) -> str Loguru formatter to return a compact JSON string for JSONLines output. record documentation: https://loguru.readthedocs.io/en/stable/api/logger.html#record Based on the _serialize_record method: https://github.com/Delgan/loguru/blob/44f6771/loguru/_handler.py#L222 from calcipy.log_helpers import serializable_compact logger . add ( LOG_DIR / 'pkg-compact- {time} .jsonl' , mode = 'w' , level = logging . INFO , format = serializable_compact ) Parameters: Name Type Description Default record None dictionary passed by loguru for formatting None Returns: Type Description str dumped JSON without newlines View Source @beartype def serializable_compact ( record : Dict [ str , Any ]) -> str : \"\"\"Loguru formatter to return a compact JSON string for JSONLines output. `record` documentation: https://loguru.readthedocs.io/en/stable/api/logger.html#record Based on the `_serialize_record` method: https://github.com/Delgan/loguru/blob/44f6771/loguru/_handler.py#L222 ```py from calcipy.log_helpers import serializable_compact logger.add(LOG_DIR / 'pkg-compact-{time}.jsonl', mode='w', level=logging.INFO, format=serializable_compact) ``` Args: record: dictionary passed by loguru for formatting Returns: str: dumped JSON without newlines \"\"\" exception = record [ 'exception' ] if exception : exception = { 'type' : None if exception . type is None else exception . type . __name__ , 'value' : exception . value , 'traceback' : bool ( record [ 'exception' ] . traceback ), } simplified = { 'record' : { 'exception' : exception , 'extra' : record [ 'extra' ], 'file' : { 'path' : record [ 'file' ] . path }, 'function' : record [ 'function' ] . strip ( '<>' ), 'level' : { 'name' : record [ 'level' ] . name }, 'line' : record [ 'line' ], 'message' : record [ 'message' ], 'module' : record [ 'module' ], 'name' : record [ 'name' ], 'time' : { 'timestamp' : record [ 'time' ] . timestamp ()}, }, } str_json : str = json . dumps ( simplified , default = str ) . replace ( '{' , '{{' ) . replace ( '}' , '}}' ) return str_json + ' \\n '","title":"serializable_compact"},{"location":"docs/modules/calcipy/wrappers/","text":"calcipy.wrappers \u2693\ufe0e Wrappers for external dependencies that may change without notice. View Source \"\"\"Wrappers for external dependencies that may change without notice.\"\"\" from typing import Any , Dict , Union from beartype import beartype from box import Box @beartype def ddict ( ** kwargs : Dict [ str , Any ]) -> Union [ Dict [ str , Any ], Box ]: \"\"\"Return a dotted dictionary that can also be accessed normally. Currently uses `python-box` because there is a more recent release, but could also use `munch` Other variations are no longer supported, such as `bunch` and `ddict` among others Args: kwargs: keyword arguments formatted into dictionary Returns: dotted dictionary \"\"\" return Box ( kwargs ) Functions \u2693\ufe0e ddict \u2693\ufe0e def ddict ( ** kwargs : Dict [ str , Any ] ) -> Union [ Dict [ str , Any ], box . box . Box ] Return a dotted dictionary that can also be accessed normally. Currently uses python-box because there is a more recent release, but could also use munch Other variations are no longer supported, such as bunch and ddict among others Parameters: Name Type Description Default kwargs None keyword arguments formatted into dictionary None Returns: Type Description None dotted dictionary View Source @beartype def ddict ( ** kwargs : Dict [ str , Any ]) -> Union [ Dict [ str , Any ], Box ]: \"\"\"Return a dotted dictionary that can also be accessed normally. Currently uses `python-box` because there is a more recent release, but could also use `munch` Other variations are no longer supported, such as `bunch` and `ddict` among others Args: kwargs: keyword arguments formatted into dictionary Returns: dotted dictionary \"\"\" return Box ( kwargs )","title":"calcipy.wrappers"},{"location":"docs/modules/calcipy/wrappers/#calcipywrappers","text":"Wrappers for external dependencies that may change without notice. View Source \"\"\"Wrappers for external dependencies that may change without notice.\"\"\" from typing import Any , Dict , Union from beartype import beartype from box import Box @beartype def ddict ( ** kwargs : Dict [ str , Any ]) -> Union [ Dict [ str , Any ], Box ]: \"\"\"Return a dotted dictionary that can also be accessed normally. Currently uses `python-box` because there is a more recent release, but could also use `munch` Other variations are no longer supported, such as `bunch` and `ddict` among others Args: kwargs: keyword arguments formatted into dictionary Returns: dotted dictionary \"\"\" return Box ( kwargs )","title":"calcipy.wrappers"},{"location":"docs/modules/calcipy/wrappers/#functions","text":"","title":"Functions"},{"location":"docs/modules/calcipy/wrappers/#ddict","text":"def ddict ( ** kwargs : Dict [ str , Any ] ) -> Union [ Dict [ str , Any ], box . box . Box ] Return a dotted dictionary that can also be accessed normally. Currently uses python-box because there is a more recent release, but could also use munch Other variations are no longer supported, such as bunch and ddict among others Parameters: Name Type Description Default kwargs None keyword arguments formatted into dictionary None Returns: Type Description None dotted dictionary View Source @beartype def ddict ( ** kwargs : Dict [ str , Any ]) -> Union [ Dict [ str , Any ], Box ]: \"\"\"Return a dotted dictionary that can also be accessed normally. Currently uses `python-box` because there is a more recent release, but could also use `munch` Other variations are no longer supported, such as `bunch` and `ddict` among others Args: kwargs: keyword arguments formatted into dictionary Returns: dotted dictionary \"\"\" return Box ( kwargs )","title":"ddict"},{"location":"docs/modules/calcipy/dev/","text":"calcipy.dev \u2693\ufe0e General non-doit Development Functionality. View Source \"\"\"General non-doit Development Functionality.\"\"\" Sub-modules \u2693\ufe0e calcipy.dev.conftest calcipy.dev.noxfile","title":"calcipy.dev"},{"location":"docs/modules/calcipy/dev/#calcipydev","text":"General non-doit Development Functionality. View Source \"\"\"General non-doit Development Functionality.\"\"\"","title":"calcipy.dev"},{"location":"docs/modules/calcipy/dev/#sub-modules","text":"calcipy.dev.conftest calcipy.dev.noxfile","title":"Sub-modules"},{"location":"docs/modules/calcipy/dev/conftest/","text":"calcipy.dev.conftest \u2693\ufe0e Custom Pytest Configuration. To use the custom markers, create a file tests/conftest.py and add this import: from calcipy.dev.conftest import pytest_configure # noqa: F401 For HTML Reports, see: https://pypi.org/project/pytest-html/. '''Custom PyTest-HTML Report Configuration.''' from calcipy.dev.conftest import pytest_html_results_table_header # noqa: F401 from calcipy.dev.conftest import pytest_html_results_table_row # noqa: F401 from calcipy.dev.conftest import pytest_runtest_makereport # noqa: F401 View Source \"\"\"Custom Pytest Configuration. To use the custom markers, create a file `tests/conftest.py` and add this import: ```py from calcipy.dev.conftest import pytest_configure # noqa: F401 For HTML Reports, see: https://pypi.org/project/pytest-html/. '''Custom PyTest-HTML Report Configuration.''' from calcipy.dev.conftest import pytest_html_results_table_header # noqa: F401 from calcipy.dev.conftest import pytest_html_results_table_row # noqa: F401 from calcipy.dev.conftest import pytest_runtest_makereport # noqa: F401 \u201d\u201c\u201d from datetime import datetime from typing import Any, Generator has_test_imports = False try: import pytest from py.xml import html has_test_imports = True except ImportError: # pragma: no cover pass if has_test_imports: @pytest.mark.optionalhook() def pytest_html_results_table_header(cells: Any) -> None: # pragma: no cover \u201c\u201d\u201cModify results table in the pytest-html output. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 Args : cells : argument from pytest \"\"\" cells.insert(1, html.th('Description')) cells.insert(1, html.th('Time', class_='sortable time', col='time')) @pytest.mark.optionalhook() def pytest_html_results_table_row(report: Any, cells: Any) -> None: # pragma: no cover \"\"\" Modify results table in the pytest - html output . Args : report : argument from pytest cells : argument from pytest \"\"\" try: cells.insert(1, html.td(report.description)) cells.insert(1, html.td(str(datetime.utcnow()), class_='col-time')) except AttributeError: pass # The test suite likely failed @pytest.hookimpl(hookwrapper=True) def pytest_runtest_makereport(item: Any, call: Any) -> Generator: # type: ignore[type-arg] # pragma: no cover \"\"\" Modify the pytest - html output . Args : item : argument from pytest call : argument from pytest Yields : outcome : required by pytest \"\"\" try: outcome = yield report = outcome.get_result() report.description = str(item.function.__doc__) report.duration_formatter = '%H:%M:%S.%f' except AttributeError: pass # The test suite likely failed def pytest_configure(config: Any) -> None: \"\"\" Configure pytest with custom markers ( SLOW , CHROME , and CURRENT ). Args : config : pytest configuration object \"\"\" config.addinivalue_line( 'markers', 'SLOW: tests that take a long time (>15s) and can be skipped with `-m \" not SLOW \"`', ) config.addinivalue_line( 'markers', 'CHROME: tests that open a Chrome window and can be skipped with `-m \" not CHROME \"` ', ) config.addinivalue_line( ' markers ', ' CURRENT : tests that are currently being developed . Useful for TDD with ptw ` poetry run ptw -- - m CURRENT `' , ) ``` Variables \u2693\ufe0e has_test_imports Functions \u2693\ufe0e pytest_configure \u2693\ufe0e def pytest_configure ( config : Any ) -> None Configure pytest with custom markers (SLOW, CHROME, and CURRENT). Parameters: Name Type Description Default config None pytest configuration object None View Source def pytest_configure ( config : Any ) -> None : \"\"\"Configure pytest with custom markers (SLOW, CHROME, and CURRENT). Args: config: pytest configuration object \"\"\" config . addinivalue_line ( 'markers' , 'SLOW: tests that take a long time (>15s) and can be skipped with `-m \"not SLOW\"`' , ) config . addinivalue_line ( 'markers' , 'CHROME: tests that open a Chrome window and can be skipped with `-m \"not CHROME\"`' , ) config . addinivalue_line ( 'markers' , 'CURRENT: tests that are currently being developed. Useful for TDD with ptw `poetry run ptw -- -m CURRENT`' , ) pytest_html_results_table_header \u2693\ufe0e def pytest_html_results_table_header ( cells : Any ) -> None Modify results table in the pytest-html output. Parameters: Name Type Description Default cells None argument from pytest None View Source @pytest . mark . optionalhook () def pytest_html_results_table_header ( cells : Any ) -> None : # pragma: no cover \"\"\"Modify results table in the pytest-html output. Args: cells: argument from pytest \"\"\" cells . insert ( 1 , html . th ( 'Description' )) cells . insert ( 1 , html . th ( 'Time' , class_ = 'sortable time' , col = 'time' )) pytest_html_results_table_row \u2693\ufe0e def pytest_html_results_table_row ( report : Any , cells : Any ) -> None Modify results table in the pytest-html output. Parameters: Name Type Description Default report None argument from pytest None cells None argument from pytest None View Source @pytest . mark . optionalhook () def pytest_html_results_table_row ( report : Any , cells : Any ) -> None : # pragma: no cover \"\"\"Modify results table in the pytest-html output. Args: report: argument from pytest cells: argument from pytest \"\"\" try : cells . insert ( 1 , html . td ( report . description )) cells . insert ( 1 , html . td ( str ( datetime . utcnow ()), class_ = 'col-time' )) except AttributeError : pass # The test suite likely failed pytest_runtest_makereport \u2693\ufe0e def pytest_runtest_makereport ( item : Any , call : Any ) -> Generator Modify the pytest-html output. Parameters: Name Type Description Default item None argument from pytest None call None argument from pytest None Yields: Type Description outcome required by pytest View Source @pytest . hookimpl ( hookwrapper = True ) def pytest_runtest_makereport ( item : Any , call : Any ) -> Generator : # type: ignore[type-arg] # pragma: no cover \"\"\"Modify the pytest-html output. Args: item: argument from pytest call: argument from pytest Yields: outcome: required by pytest \"\"\" try : outcome = yield report = outcome . get_result () report . description = str ( item . function . __doc__ ) report . duration_formatter = '%H:%M:%S. %f ' except AttributeError : pass # The test suite likely failed","title":"calcipy.dev.conftest"},{"location":"docs/modules/calcipy/dev/conftest/#calcipydevconftest","text":"Custom Pytest Configuration. To use the custom markers, create a file tests/conftest.py and add this import: from calcipy.dev.conftest import pytest_configure # noqa: F401 For HTML Reports, see: https://pypi.org/project/pytest-html/. '''Custom PyTest-HTML Report Configuration.''' from calcipy.dev.conftest import pytest_html_results_table_header # noqa: F401 from calcipy.dev.conftest import pytest_html_results_table_row # noqa: F401 from calcipy.dev.conftest import pytest_runtest_makereport # noqa: F401 View Source \"\"\"Custom Pytest Configuration. To use the custom markers, create a file `tests/conftest.py` and add this import: ```py from calcipy.dev.conftest import pytest_configure # noqa: F401 For HTML Reports, see: https://pypi.org/project/pytest-html/. '''Custom PyTest-HTML Report Configuration.''' from calcipy.dev.conftest import pytest_html_results_table_header # noqa: F401 from calcipy.dev.conftest import pytest_html_results_table_row # noqa: F401 from calcipy.dev.conftest import pytest_runtest_makereport # noqa: F401 \u201d\u201c\u201d from datetime import datetime from typing import Any, Generator has_test_imports = False try: import pytest from py.xml import html has_test_imports = True except ImportError: # pragma: no cover pass if has_test_imports: @pytest.mark.optionalhook() def pytest_html_results_table_header(cells: Any) -> None: # pragma: no cover \u201c\u201d\u201cModify results table in the pytest-html output. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 Args : cells : argument from pytest \"\"\" cells.insert(1, html.th('Description')) cells.insert(1, html.th('Time', class_='sortable time', col='time')) @pytest.mark.optionalhook() def pytest_html_results_table_row(report: Any, cells: Any) -> None: # pragma: no cover \"\"\" Modify results table in the pytest - html output . Args : report : argument from pytest cells : argument from pytest \"\"\" try: cells.insert(1, html.td(report.description)) cells.insert(1, html.td(str(datetime.utcnow()), class_='col-time')) except AttributeError: pass # The test suite likely failed @pytest.hookimpl(hookwrapper=True) def pytest_runtest_makereport(item: Any, call: Any) -> Generator: # type: ignore[type-arg] # pragma: no cover \"\"\" Modify the pytest - html output . Args : item : argument from pytest call : argument from pytest Yields : outcome : required by pytest \"\"\" try: outcome = yield report = outcome.get_result() report.description = str(item.function.__doc__) report.duration_formatter = '%H:%M:%S.%f' except AttributeError: pass # The test suite likely failed def pytest_configure(config: Any) -> None: \"\"\" Configure pytest with custom markers ( SLOW , CHROME , and CURRENT ). Args : config : pytest configuration object \"\"\" config.addinivalue_line( 'markers', 'SLOW: tests that take a long time (>15s) and can be skipped with `-m \" not SLOW \"`', ) config.addinivalue_line( 'markers', 'CHROME: tests that open a Chrome window and can be skipped with `-m \" not CHROME \"` ', ) config.addinivalue_line( ' markers ', ' CURRENT : tests that are currently being developed . Useful for TDD with ptw ` poetry run ptw -- - m CURRENT `' , ) ```","title":"calcipy.dev.conftest"},{"location":"docs/modules/calcipy/dev/conftest/#variables","text":"has_test_imports","title":"Variables"},{"location":"docs/modules/calcipy/dev/conftest/#functions","text":"","title":"Functions"},{"location":"docs/modules/calcipy/dev/conftest/#pytest_configure","text":"def pytest_configure ( config : Any ) -> None Configure pytest with custom markers (SLOW, CHROME, and CURRENT). Parameters: Name Type Description Default config None pytest configuration object None View Source def pytest_configure ( config : Any ) -> None : \"\"\"Configure pytest with custom markers (SLOW, CHROME, and CURRENT). Args: config: pytest configuration object \"\"\" config . addinivalue_line ( 'markers' , 'SLOW: tests that take a long time (>15s) and can be skipped with `-m \"not SLOW\"`' , ) config . addinivalue_line ( 'markers' , 'CHROME: tests that open a Chrome window and can be skipped with `-m \"not CHROME\"`' , ) config . addinivalue_line ( 'markers' , 'CURRENT: tests that are currently being developed. Useful for TDD with ptw `poetry run ptw -- -m CURRENT`' , )","title":"pytest_configure"},{"location":"docs/modules/calcipy/dev/conftest/#pytest_html_results_table_header","text":"def pytest_html_results_table_header ( cells : Any ) -> None Modify results table in the pytest-html output. Parameters: Name Type Description Default cells None argument from pytest None View Source @pytest . mark . optionalhook () def pytest_html_results_table_header ( cells : Any ) -> None : # pragma: no cover \"\"\"Modify results table in the pytest-html output. Args: cells: argument from pytest \"\"\" cells . insert ( 1 , html . th ( 'Description' )) cells . insert ( 1 , html . th ( 'Time' , class_ = 'sortable time' , col = 'time' ))","title":"pytest_html_results_table_header"},{"location":"docs/modules/calcipy/dev/conftest/#pytest_html_results_table_row","text":"def pytest_html_results_table_row ( report : Any , cells : Any ) -> None Modify results table in the pytest-html output. Parameters: Name Type Description Default report None argument from pytest None cells None argument from pytest None View Source @pytest . mark . optionalhook () def pytest_html_results_table_row ( report : Any , cells : Any ) -> None : # pragma: no cover \"\"\"Modify results table in the pytest-html output. Args: report: argument from pytest cells: argument from pytest \"\"\" try : cells . insert ( 1 , html . td ( report . description )) cells . insert ( 1 , html . td ( str ( datetime . utcnow ()), class_ = 'col-time' )) except AttributeError : pass # The test suite likely failed","title":"pytest_html_results_table_row"},{"location":"docs/modules/calcipy/dev/conftest/#pytest_runtest_makereport","text":"def pytest_runtest_makereport ( item : Any , call : Any ) -> Generator Modify the pytest-html output. Parameters: Name Type Description Default item None argument from pytest None call None argument from pytest None Yields: Type Description outcome required by pytest View Source @pytest . hookimpl ( hookwrapper = True ) def pytest_runtest_makereport ( item : Any , call : Any ) -> Generator : # type: ignore[type-arg] # pragma: no cover \"\"\"Modify the pytest-html output. Args: item: argument from pytest call: argument from pytest Yields: outcome: required by pytest \"\"\" try : outcome = yield report = outcome . get_result () report . description = str ( item . function . __doc__ ) report . duration_formatter = '%H:%M:%S. %f ' except AttributeError : pass # The test suite likely failed","title":"pytest_runtest_makereport"},{"location":"docs/modules/calcipy/dev/noxfile/","text":"calcipy.dev.noxfile \u2693\ufe0e nox-poetry configuration file. Useful snippets from docs poetry run nox -l poetry run nox --list-sessions poetry run nox -s build_check-3.9 build_dist-3.9 check_safety-3.9 poetry run nox --session check_safety-3.9 poetry run nox --python 3 .8 poetry run nox -k \"not tests and not check_safety\" Useful nox snippets # Example conditionally skipping a session if not session . interactive : session . skip ( 'Cannot run detect-secrets audit in non-interactive shell' ) # Install pinned version session . install ( 'detect-secrets==1.0.3' ) # Example capturing STDOUT into a file (could do the same for stderr) path_stdout = Path ( '.stdout.txt' ) . resolve () with open ( path_stdout , 'w' ) as out : session . run ( * shlex . split ( 'echo Hello World!' ), stdout = out ) View Source \"\"\"nox-poetry configuration file. [Useful snippets from docs](https://nox.thea.codes/en/stable/usage.html) ```sh poetry run nox -l poetry run nox --list-sessions poetry run nox -s build_check-3.9 build_dist-3.9 check_safety-3.9 poetry run nox --session check_safety-3.9 poetry run nox --python 3.8 poetry run nox -k \"not tests and not check_safety\" Useful nox snippets # Example conditionally skipping a session if not session . interactive : session . skip ( 'Cannot run detect-secrets audit in non-interactive shell' ) # Install pinned version session . install ( 'detect-secrets==1.0.3' ) # Example capturing STDOUT into a file (could do the same for stderr) path_stdout = Path ( '.stdout.txt' ) . resolve () with open ( path_stdout , 'w' ) as out : session . run ( * shlex . split ( 'echo Hello World!' ), stdout = out ) \u201d\u201c\u201d import re import shlex from pathlib import Path from typing import Callable from urllib.parse import urlparse from urllib.request import url2pathname from loguru import logger from ..doit_tasks.doit_globals import DG, DoitAction, DoitTask from ..doit_tasks.test import task_coverage, task_test from ..file_helpers import if_found_unlink has_test_imports = False try: from nox_poetry import session from nox_poetry.poetry import DistributionFormat from nox_poetry.sessions import Session has_test_imports = True except ImportError: # pragma: no cover pass if has_test_imports: # pragma: no cover # noqa: C901 def _run_str_cmd(session: Session, cmd_str: str) -> None: \u201c\u201d\u201cRun a command string. Ensure that poetry is left-stripped. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 Args : session : nox_poetry Session cmd_str : string command to run \"\"\" cmd_str = re.sub(r'^poetry run ', '', cmd_str) session.run(*shlex.split(cmd_str), stdout=True) def _run_func_cmd(action: DoitAction) -> None: \"\"\" Run a python action . Args : action : doit python action Raises : RuntimeError : if a function action fails \"\"\" # https://pydoit.org/tasks.html#python-action func, args, kwargs = [*list(action), {}][:3] result = func(args, **kwargs) if result not in [True, None] or not isinstance(result, (str, dict)): raise RuntimeError(f'Returned {result}. Failed to run task: {action}') def _run_doit_task(session: Session, task_fun: Callable[[], DoitTask]) -> None: \"\"\" Run a DoitTask actions without using doit . Args : session : nox_poetry Session task_fun : function that returns a DoitTask Raises : NotImplementedError : if the action is of an unknown type \"\"\" task = task_fun() for action in task['actions']: if isinstance(action, str): _run_str_cmd(session, action) elif getattr(action, 'action', None): _run_str_cmd(session, action.action) elif isinstance(action, (list, tuple)): _run_func_cmd(action) else: raise NotImplementedError(f'Unable to run {action} ({type(action)})') @session(python=DG.test.pythons, reuse_venv=True) def tests(session: Session) -> None: \"\"\" Run doit test task for specified python versions . Args : session : nox_poetry Session \"\"\" session.install('.[dev]', '.[test]') _run_doit_task(session, task_test) @session(python=[DG.test.pythons[-1]], reuse_venv=True) def coverage(session: Session) -> None: \"\"\" Run doit test task for specified python versions . Args : session : nox_poetry Session \"\"\" session.install('.[dev]', '.[test]') _run_doit_task(session, task_coverage) @session(python=[DG.test.pythons[-1]], reuse_venv=False) def build_dist(session: Session) -> None: \"\"\" Build the project files within a controlled environment for repeatability . Args : session : nox_poetry Session \"\"\" if_found_unlink(DG.meta.path_project / 'dist') path_wheel = session.poetry.build_package() logger.info(f'Created wheel: {path_wheel}') # Install the wheel and check that imports without any of the optional dependencies session.install(path_wheel) session.run(*shlex.split('python scripts/check_imports.py'), stdout=True) @session(python=[DG.test.pythons[-1]], reuse_venv=True) def build_check(session: Session) -> None: \"\"\" Check that the built output meets all checks . Args : session : nox_poetry Session \"\"\" # Build sdist and fix return URI, which will have file://...#egg=calcipy sdist_uri = session.poetry.build_package(distribution_format=DistributionFormat.SDIST) path_sdist = Path(url2pathname(urlparse(sdist_uri).path)) logger.debug(f'Fixed sdist URI ({sdist_uri}): {path_sdist}') # Check with pyroma session.install('pyroma', '--upgrade') # PLANNED: Troubleshoot why pyroma score is so low (6/10) session.run('pyroma', '--file', path_sdist.as_posix(), '--min=6', stdout=True) @session(python=[DG.test.pythons[-1]], reuse_venv=True) def check_safety(session: Session) -> None: \"\"\" Check for known vulnerabilities with safety . Based on : https : // github . com / pyupio / safety / issues / 201 #issuecomment - 632627366 Args : session : nox_poetry Session Raises : RuntimeError : if safety exited with errors , but not caught by session \"\" \" # Note : safety requires a requirements . txt file and doesn 't support pyproject.toml yet session.poetry.export_requirements() # Install and run session.install(' safety ', ' -- upgrade ') path_report = Path(' insecure_report . json ').resolve() logger.info(f' Creating safety report : { path_report } ') session.run(*shlex.split(f' safety check -- full - report -- cache -- output { path_report } -- json '), stdout=True) if path_report.read_text().strip() != ' [] ': raise RuntimeError(f' Found safety warnings in { path_report }' ) path_report . unlink () ``` Variables \u2693\ufe0e build_check build_dist check_safety coverage has_test_imports tests","title":"calcipy.dev.noxfile"},{"location":"docs/modules/calcipy/dev/noxfile/#calcipydevnoxfile","text":"nox-poetry configuration file. Useful snippets from docs poetry run nox -l poetry run nox --list-sessions poetry run nox -s build_check-3.9 build_dist-3.9 check_safety-3.9 poetry run nox --session check_safety-3.9 poetry run nox --python 3 .8 poetry run nox -k \"not tests and not check_safety\" Useful nox snippets # Example conditionally skipping a session if not session . interactive : session . skip ( 'Cannot run detect-secrets audit in non-interactive shell' ) # Install pinned version session . install ( 'detect-secrets==1.0.3' ) # Example capturing STDOUT into a file (could do the same for stderr) path_stdout = Path ( '.stdout.txt' ) . resolve () with open ( path_stdout , 'w' ) as out : session . run ( * shlex . split ( 'echo Hello World!' ), stdout = out ) View Source \"\"\"nox-poetry configuration file. [Useful snippets from docs](https://nox.thea.codes/en/stable/usage.html) ```sh poetry run nox -l poetry run nox --list-sessions poetry run nox -s build_check-3.9 build_dist-3.9 check_safety-3.9 poetry run nox --session check_safety-3.9 poetry run nox --python 3.8 poetry run nox -k \"not tests and not check_safety\" Useful nox snippets # Example conditionally skipping a session if not session . interactive : session . skip ( 'Cannot run detect-secrets audit in non-interactive shell' ) # Install pinned version session . install ( 'detect-secrets==1.0.3' ) # Example capturing STDOUT into a file (could do the same for stderr) path_stdout = Path ( '.stdout.txt' ) . resolve () with open ( path_stdout , 'w' ) as out : session . run ( * shlex . split ( 'echo Hello World!' ), stdout = out ) \u201d\u201c\u201d import re import shlex from pathlib import Path from typing import Callable from urllib.parse import urlparse from urllib.request import url2pathname from loguru import logger from ..doit_tasks.doit_globals import DG, DoitAction, DoitTask from ..doit_tasks.test import task_coverage, task_test from ..file_helpers import if_found_unlink has_test_imports = False try: from nox_poetry import session from nox_poetry.poetry import DistributionFormat from nox_poetry.sessions import Session has_test_imports = True except ImportError: # pragma: no cover pass if has_test_imports: # pragma: no cover # noqa: C901 def _run_str_cmd(session: Session, cmd_str: str) -> None: \u201c\u201d\u201cRun a command string. Ensure that poetry is left-stripped. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 Args : session : nox_poetry Session cmd_str : string command to run \"\"\" cmd_str = re.sub(r'^poetry run ', '', cmd_str) session.run(*shlex.split(cmd_str), stdout=True) def _run_func_cmd(action: DoitAction) -> None: \"\"\" Run a python action . Args : action : doit python action Raises : RuntimeError : if a function action fails \"\"\" # https://pydoit.org/tasks.html#python-action func, args, kwargs = [*list(action), {}][:3] result = func(args, **kwargs) if result not in [True, None] or not isinstance(result, (str, dict)): raise RuntimeError(f'Returned {result}. Failed to run task: {action}') def _run_doit_task(session: Session, task_fun: Callable[[], DoitTask]) -> None: \"\"\" Run a DoitTask actions without using doit . Args : session : nox_poetry Session task_fun : function that returns a DoitTask Raises : NotImplementedError : if the action is of an unknown type \"\"\" task = task_fun() for action in task['actions']: if isinstance(action, str): _run_str_cmd(session, action) elif getattr(action, 'action', None): _run_str_cmd(session, action.action) elif isinstance(action, (list, tuple)): _run_func_cmd(action) else: raise NotImplementedError(f'Unable to run {action} ({type(action)})') @session(python=DG.test.pythons, reuse_venv=True) def tests(session: Session) -> None: \"\"\" Run doit test task for specified python versions . Args : session : nox_poetry Session \"\"\" session.install('.[dev]', '.[test]') _run_doit_task(session, task_test) @session(python=[DG.test.pythons[-1]], reuse_venv=True) def coverage(session: Session) -> None: \"\"\" Run doit test task for specified python versions . Args : session : nox_poetry Session \"\"\" session.install('.[dev]', '.[test]') _run_doit_task(session, task_coverage) @session(python=[DG.test.pythons[-1]], reuse_venv=False) def build_dist(session: Session) -> None: \"\"\" Build the project files within a controlled environment for repeatability . Args : session : nox_poetry Session \"\"\" if_found_unlink(DG.meta.path_project / 'dist') path_wheel = session.poetry.build_package() logger.info(f'Created wheel: {path_wheel}') # Install the wheel and check that imports without any of the optional dependencies session.install(path_wheel) session.run(*shlex.split('python scripts/check_imports.py'), stdout=True) @session(python=[DG.test.pythons[-1]], reuse_venv=True) def build_check(session: Session) -> None: \"\"\" Check that the built output meets all checks . Args : session : nox_poetry Session \"\"\" # Build sdist and fix return URI, which will have file://...#egg=calcipy sdist_uri = session.poetry.build_package(distribution_format=DistributionFormat.SDIST) path_sdist = Path(url2pathname(urlparse(sdist_uri).path)) logger.debug(f'Fixed sdist URI ({sdist_uri}): {path_sdist}') # Check with pyroma session.install('pyroma', '--upgrade') # PLANNED: Troubleshoot why pyroma score is so low (6/10) session.run('pyroma', '--file', path_sdist.as_posix(), '--min=6', stdout=True) @session(python=[DG.test.pythons[-1]], reuse_venv=True) def check_safety(session: Session) -> None: \"\"\" Check for known vulnerabilities with safety . Based on : https : // github . com / pyupio / safety / issues / 201 #issuecomment - 632627366 Args : session : nox_poetry Session Raises : RuntimeError : if safety exited with errors , but not caught by session \"\" \" # Note : safety requires a requirements . txt file and doesn 't support pyproject.toml yet session.poetry.export_requirements() # Install and run session.install(' safety ', ' -- upgrade ') path_report = Path(' insecure_report . json ').resolve() logger.info(f' Creating safety report : { path_report } ') session.run(*shlex.split(f' safety check -- full - report -- cache -- output { path_report } -- json '), stdout=True) if path_report.read_text().strip() != ' [] ': raise RuntimeError(f' Found safety warnings in { path_report }' ) path_report . unlink () ```","title":"calcipy.dev.noxfile"},{"location":"docs/modules/calcipy/dev/noxfile/#variables","text":"build_check build_dist check_safety coverage has_test_imports tests","title":"Variables"},{"location":"docs/modules/calcipy/doit_tasks/","text":"calcipy.doit_tasks \u2693\ufe0e doit Helpers. Register all defaults doit tasks in a dodo.py file with the below snippet: from calcipy.doit_tasks import * # noqa: F401,F403,H303 (Run 'doit list' to see tasks). skipcq: PYL-W0614 View Source \"\"\"doit Helpers. Register all defaults doit tasks in a dodo.py file with the below snippet: `from calcipy.doit_tasks import * # noqa: F401,F403,H303 (Run 'doit list' to see tasks). skipcq: PYL-W0614` \"\"\" __all__ = [ # noqa: F405 'DOIT_CONFIG_RECOMMENDED' , 'TASKS_CI' , 'TASKS_LOCAL' , # from .code_tag_collector 'task_collect_code_tags' , # from .doc 'task_cl_bump_pre' , 'task_cl_bump' , 'task_cl_write' , 'task_deploy_docs' , 'task_document' , 'task_open_docs' , # from .lint 'task_auto_format' , 'task_lint_critical_only' , 'task_lint_project' , 'task_lint_python' , 'task_pre_commit_hooks' , 'task_radon_lint' , 'task_security_checks' , # from .packaging 'task_check_for_stale_packages' , 'task_check_license' , 'task_lock' , 'task_publish' , # from .test 'task_check_types' , 'task_coverage' , 'task_nox_test' , 'task_nox_coverage' , 'task_nox' , 'task_open_test_docs' , 'task_ptw_current' , 'task_ptw_ff' , 'task_ptw_marker' , 'task_ptw_not_chrome' , 'task_test_all' , 'task_test_keyword' , 'task_test_marker' , 'task_test' , ] from getpass import getuser from .code_tag_collector import task_collect_code_tags from .doc import * # noqa: F401,F403,H303. lgtm [py/polluting-import] from .lint import * # noqa: F401,F403,H303. lgtm [py/polluting-import] from .packaging import * # noqa: F401,F403,H303. lgtm [py/polluting-import] from .summary_reporter import SummaryReporter from .test import * # noqa: F401,F403,H303. lgtm [py/polluting-import] TASKS_CI = [ 'nox_test' , 'security_checks' , ] \"\"\"More forgiving tasks to be run in CI.\"\"\" TASKS_LOCAL = [ 'collect_code_tags' , 'cl_write' , 'lock' , 'nox_coverage' , 'auto_format' , 'document' , 'check_for_stale_packages' , 'pre_commit_hooks' , 'lint_project' , 'security_checks' , 'check_types' , ] \"\"\"Full suite of tasks for local development.\"\"\" DOIT_CONFIG_RECOMMENDED = { 'action_string_formatting' : 'old' , # Required for keyword-based tasks 'default_tasks' : TASKS_CI if getuser () . lower () == 'appveyor' else TASKS_LOCAL , 'reporter' : SummaryReporter , } \"\"\"doit Configuration Settings. Run with `poetry run doit`.\"\"\" Sub-modules \u2693\ufe0e calcipy.doit_tasks.base calcipy.doit_tasks.code_tag_collector calcipy.doit_tasks.doc calcipy.doit_tasks.doit_globals calcipy.doit_tasks.file_search calcipy.doit_tasks.lint calcipy.doit_tasks.packaging calcipy.doit_tasks.summary_reporter calcipy.doit_tasks.test Variables \u2693\ufe0e DOIT_CONFIG_RECOMMENDED doit Configuration Settings. Run with poetry run doit . TASKS_CI More forgiving tasks to be run in CI. TASKS_LOCAL Full suite of tasks for local development. Functions \u2693\ufe0e task_auto_format \u2693\ufe0e def task_auto_format () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Format code with isort and autopep8. Other Useful Format Snippets: poetry run isort --recursive --check --diff calcipy/ tests/ Returns: Type Description DoitTask doit task View Source @beartype def task_auto_format () -> DoitTask : \"\"\"Format code with isort and autopep8. Other Useful Format Snippets: ```sh poetry run isort --recursive --check --diff calcipy/ tests/ ``` Returns: DoitTask: doit task \"\"\" run = 'poetry run python -m' paths = ' ' . join ( f '\" { pth } \"' for pth in DG . lint . paths_py ) return debug_task ([ f ' { run } autopep8 { paths } --in-place --aggressive' , f ' { run } isort { paths } --settings-path \" { DG . lint . path_isort } \"' , ]) task_check_for_stale_packages \u2693\ufe0e def task_check_for_stale_packages () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Check for stale packages. Returns: Type Description DoitTask doit task View Source @beartype def task_check_for_stale_packages () -> DoitTask : \"\"\"Check for stale packages. Returns: DoitTask: doit task \"\"\" path_lock = DG . meta . path_project / 'poetry.lock' path_pack_lock = _PATH_PACK_LOCK task = debug_task ([ ( find_stale_packages , ( path_lock , path_pack_lock ), { 'stale_months' : 48 }), Interactive ( 'poetry run pip list --outdated' ), ]) task [ 'file_dep' ] . append ( path_lock ) task [ 'targets' ] . append ( path_pack_lock ) return task task_check_license \u2693\ufe0e def task_check_license () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Check licenses for compatibility. Returns: Type Description DoitTask doit task View Source @beartype def task_check_license () -> DoitTask : \"\"\"Check licenses for compatibility. Returns: DoitTask: doit task \"\"\" return debug_task ([ 'poetry run licensecheck --zero' ]) task_check_types \u2693\ufe0e def task_check_types () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run type annotation checks. Returns: Type Description DoitTask doit task View Source @beartype def task_check_types () -> DoitTask : \"\"\"Run type annotation checks. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run mypy { DG . meta . pkg_name } --show-error-codes' ), ]) task_cl_bump \u2693\ufe0e def task_cl_bump () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Bumps project version based on commits & settings in pyproject.toml. Returns: Type Description DoitTask doit task View Source @beartype def task_cl_bump () -> DoitTask : \"\"\"Bumps project version based on commits & settings in pyproject.toml. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run cz bump --changelog --annotated-tag' ), ( _move_cl , ()), 'git push origin --tags --no-verify' , ]) task_cl_bump_pre \u2693\ufe0e def task_cl_bump_pre () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Bump with specified pre-release tag. Example: doit run cl_bump_pre -p alpha or doit run cl_bump_pre -p rc Returns: Type Description DoitTask doit task View Source @beartype def task_cl_bump_pre () -> DoitTask : \"\"\"Bump with specified pre-release tag. Example: `doit run cl_bump_pre -p alpha` or `doit run cl_bump_pre -p rc` Returns: DoitTask: doit task \"\"\" task = debug_task ([ Interactive ( 'poetry run cz bump --changelog --prerelease %(prerelease)s ' ), ( _move_cl , ()), 'git push origin --tags --no-verify' , ]) task [ 'params' ] = [{ 'name' : 'prerelease' , 'short' : 'p' , 'long' : 'prerelease' , 'default' : '' , 'help' : 'Specify prerelease version for bump (alpha, beta, rc)' , }] return task task_cl_write \u2693\ufe0e def task_cl_write () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Write a Changelog file with the raw Git history. Resources: https://keepachangelog.com/en/1.0.0/ https://www.conventionalcommits.org/en/v1.0.0/ https://writingfordevelopers.substack.com/p/how-to-write-a-commit-message https://chris.beams.io/posts/git-commit/ https://semver.org/ https://calver.org/ Returns: Type Description DoitTask doit task View Source @beartype def task_cl_write () -> DoitTask : \"\"\"Write a Changelog file with the raw Git history. Resources: - https://keepachangelog.com/en/1.0.0/ - https://www.conventionalcommits.org/en/v1.0.0/ - https://writingfordevelopers.substack.com/p/how-to-write-a-commit-message - https://chris.beams.io/posts/git-commit/ - https://semver.org/ - https://calver.org/ Returns: DoitTask: doit task \"\"\" return debug_task ([ 'poetry run cz changelog' , ( _move_cl , ()), ]) task_collect_code_tags \u2693\ufe0e def task_collect_code_tags () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Create a summary file with all of the found code tags. Returns: Type Description DoitTask doit task View Source @beartype def task_collect_code_tags () -> DoitTask : \"\"\"Create a summary file with all of the found code tags. Returns: DoitTask: doit task \"\"\" return debug_task ([( _write_code_tag_file , ( DG . ct . path_code_tag_summary ,))]) task_coverage \u2693\ufe0e def task_coverage () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run pytest and create coverage and test reports. Returns: Type Description DoitTask doit task View Source @beartype def task_coverage () -> DoitTask : \"\"\"Run pytest and create coverage and test reports. Returns: DoitTask: doit task \"\"\" path_tests = DG . test . path_tests cov_dir = DG . test . path_coverage_index . parent cov_html = f '--cov-report=html:\" { cov_dir } \" --html=\" { DG . test . path_test_report } \" --self-contained-html' diff_html = f '--html-report { DG . test . path_diff_test_report } ' return debug_task ([ Interactive ( f 'poetry run pytest \" { path_tests } \" { DG . test . args_pytest } --cov= { DG . meta . pkg_name } { cov_html } ' ), 'poetry run python -m coverage json' , # Create coverage.json file for \"_write_coverage_to_md\" 'poetry run python -m coverage xml' , Interactive ( f 'poetry run diff-cover coverage.xml { DG . test . args_diff } { diff_html } ' ), ]) task_deploy_docs \u2693\ufe0e def task_deploy_docs () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Deploy docs to the Github gh-pages branch. Returns: Type Description DoitTask doit task View Source @beartype def task_deploy_docs () -> DoitTask : \"\"\"Deploy docs to the Github `gh-pages` branch. Returns: DoitTask: doit task \"\"\" if _is_mkdocs_local (): # pragma: no cover return debug_task ([ ( NotImplementedError , ( 'Deploy cannot be used with mkdocs built with local-links' ,)), ]) return debug_task ([ Interactive ( 'poetry run mkdocs gh-deploy' )]) task_document \u2693\ufe0e def task_document () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Build the HTML documentation. Returns: Type Description DoitTask doit task View Source @beartype def task_document () -> DoitTask : \"\"\"Build the HTML documentation. Returns: DoitTask: doit task \"\"\" _ensure_handler_lookup () pdoc_out = f '--output_dir { DG . doc . doc_dir } /modules --overwrite' pdoc_template = f '--template_dir { DG . calcipy_dir } /doit_tasks/templates' return debug_task ([ ( write_autoformatted_md_sections , ()), Interactive ( f 'poetry run pdocs as_markdown { DG . meta . pkg_name } { pdoc_out } { pdoc_template } ' ), Interactive ( f 'poetry run mkdocs build --site-dir { DG . doc . path_out } ' ), ]) task_lint_critical_only \u2693\ufe0e def task_lint_critical_only () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Suppress non-critical linting errors. Great for gating PRs/commits. Returns: Type Description DoitTask doit task View Source @beartype def task_lint_critical_only () -> DoitTask : \"\"\"Suppress non-critical linting errors. Great for gating PRs/commits. Returns: DoitTask: doit task \"\"\" actions = _lint_python ( DG . lint . paths_py , path_flake8 = DG . lint . path_flake8 , ignore_errors = DG . lint . ignore_errors ) actions . extend ( _lint_non_python ()) return debug_task ( actions ) task_lint_project \u2693\ufe0e def task_lint_project () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Lint all project files that can be checked. Returns: Type Description DoitTask doit task View Source @beartype def task_lint_project () -> DoitTask : \"\"\"Lint all project files that can be checked. Returns: DoitTask: doit task \"\"\" actions = _lint_python ( DG . lint . paths_py , path_flake8 = DG . lint . path_flake8 , ignore_errors = []) actions . extend ( _lint_non_python ( strict = True )) return debug_task ( actions ) task_lint_python \u2693\ufe0e def task_lint_python () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Lint all Python files and create summary of errors. Returns: Type Description DoitTask doit task View Source @beartype def task_lint_python () -> DoitTask : \"\"\"Lint all Python files and create summary of errors. Returns: DoitTask: doit task \"\"\" actions = _lint_python ( DG . lint . paths_py , path_flake8 = DG . lint . path_flake8 , ignore_errors = []) return debug_task ( actions ) task_lock \u2693\ufe0e def task_lock () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Lock dependencies. Returns: Type Description DoitTask doit task View Source @beartype def task_lock () -> DoitTask : \"\"\"Lock dependencies. Returns: DoitTask: doit task \"\"\" path_req = DG . meta . path_project / 'requirements.txt' # Ensure that extras are exported as well toml_data = toml . loads ( DG . meta . path_toml . read_text ()) extras = [ * toml_data [ 'tool' ][ 'poetry' ] . get ( 'extras' , {}) . keys ()] extras_arg = ' -E ' . join ([ '' ] + extras ) if extras else '' task = debug_task ([ 'poetry lock' , f 'poetry export -f { path_req . name } -o { path_req . name }{ extras_arg } --dev' , ]) task [ 'file_dep' ] . append ( DG . meta . path_toml ) task [ 'targets' ] . extend ([ DG . meta . path_project / 'poetry.lock' , path_req ]) return task task_nox \u2693\ufe0e def task_nox () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run the full nox test suite. Note: some nox tasks are run in more-specific doit tasks, but this will run everything Returns: Type Description DoitTask doit task View Source @beartype def task_nox () -> DoitTask : \"\"\"Run the full nox test suite. > Note: some nox tasks are run in more-specific doit tasks, but this will run everything Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run nox' ), ]) task_nox_coverage \u2693\ufe0e def task_nox_coverage () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run all nox tests. Returns: Type Description DoitTask doit task View Source @beartype def task_nox_coverage () -> DoitTask : \"\"\"Run all nox tests. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run nox --session coverage' ), ]) task_nox_test \u2693\ufe0e def task_nox_test () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run all nox tests. Returns: Type Description DoitTask doit task View Source @beartype def task_nox_test () -> DoitTask : \"\"\"Run all nox tests. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run nox --session tests build_check' ), ]) task_open_docs \u2693\ufe0e def task_open_docs () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Open the documentation files in the default browser. Returns: Type Description DoitTask doit task View Source @beartype def task_open_docs () -> DoitTask : \"\"\"Open the documentation files in the default browser. Returns: DoitTask: doit task \"\"\" if _is_mkdocs_local (): # pragma: no cover path_doc_index = DG . doc . path_out / DG . meta . pkg_name / 'index.html' return debug_task ([ ( open_in_browser , ( path_doc_index ,)), ]) return debug_task ([ ( webbrowser . open , ( 'http://localhost:8000' ,)), Interactive ( 'poetry run mkdocs serve --dirtyreload' ), ]) task_open_test_docs \u2693\ufe0e def task_open_test_docs () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Open the test and coverage files in default browser. Returns: Type Description DoitTask doit task View Source @beartype def task_open_test_docs () -> DoitTask : \"\"\"Open the test and coverage files in default browser. Returns: DoitTask: doit task \"\"\" actions = [ ( open_in_browser , ( DG . test . path_coverage_index ,)), ( open_in_browser , ( DG . test . path_test_report ,)), ] if DG . test . path_mypy_index . is_file (): actions . append (( open_in_browser , ( DG . test . path_mypy_index ,))) return debug_task ( actions ) task_pre_commit_hooks \u2693\ufe0e def task_pre_commit_hooks () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run the pre-commit hooks on all files. Note: use git commit or git push with --no-verify if needed Returns: Type Description DoitTask doit task View Source @beartype def task_pre_commit_hooks () -> DoitTask : \"\"\"Run the [pre-commit hooks](https://pre-commit.com/) on all files. > Note: use `git commit` or `git push` with `--no-verify` if needed Returns: DoitTask: doit task \"\"\" # Only use these two stages for all pre-commit hooks stages = [ 'commit-msg' , 'pre-push' ] return debug_task ([ Interactive ( 'poetry run pre-commit autoupdate' ), Interactive ( 'poetry run pre-commit install --install-hooks' + ' --hook-type ' . join ([ '' ] + stages )), Interactive ( 'poetry run pre-commit run --all-files --hook-stage push' ), ]) task_ptw_current \u2693\ufe0e def task_ptw_current () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run pytest watch for only tests with the CURRENT marker. kwargs: -m 'CURRENT' -vv Returns: Type Description DoitTask doit task View Source @beartype def task_ptw_current () -> DoitTask : \"\"\"Run pytest watch for only tests with the CURRENT marker. kwargs: `-m 'CURRENT' -vv` Returns: DoitTask: doit task \"\"\" return ptw_task ( '-m \"CURRENT\" -vv' ) task_ptw_ff \u2693\ufe0e def task_ptw_ff () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run pytest watch for failed first and skip the CHROME marker. kwargs: --last-failed --new-first -m 'not CHROME' -vv Returns: Type Description DoitTask doit task View Source @beartype def task_ptw_ff () -> DoitTask : \"\"\"Run pytest watch for failed first and skip the CHROME marker. kwargs: `--last-failed --new-first -m 'not CHROME' -vv` Returns: DoitTask: doit task \"\"\" return ptw_task ( '--last-failed --new-first -m \"not CHROME\" -vv' ) task_ptw_marker \u2693\ufe0e def task_ptw_marker () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Specify a marker to run a subset of tests in Interactive ptw task. Example: doit run ptw_marker -m \"not MARKER\" or doit run ptw_marker -m \"MARKER\" Returns: Type Description DoitTask doit task View Source @beartype def task_ptw_marker () -> DoitTask : \"\"\"Specify a marker to run a subset of tests in Interactive `ptw` task. Example: `doit run ptw_marker -m \"not MARKER\"` or `doit run ptw_marker -m \"MARKER\"` Returns: DoitTask: doit task \"\"\" task = ptw_task ( '-vvv -m \" %(marker)s \"' ) task [ 'params' ] = [{ 'name' : 'marker' , 'short' : 'm' , 'long' : 'marker' , 'default' : '' , 'help' : ( 'Runs test with specified marker logic \\n See: ' 'https://docs.pytest.org/en/latest/example/markers.html?highlight=-m' ), }] return task task_ptw_not_chrome \u2693\ufe0e def task_ptw_not_chrome () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run pytest watch for failed first and skip the CHROME marker. kwargs: -m 'not CHROME' -vvv Returns: Type Description DoitTask doit task View Source @beartype def task_ptw_not_chrome () -> DoitTask : \"\"\"Run pytest watch for failed first and skip the CHROME marker. kwargs: `-m 'not CHROME' -vvv` Returns: DoitTask: doit task \"\"\" return ptw_task ( '-m \"not CHROME\" -vvv' ) task_publish \u2693\ufe0e def task_publish () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Build the distributable format(s) and publish. See the Developer Guide for configuring pypi token Use in conjunction with task_cl_bump Returns: Type Description DoitTask doit task View Source @beartype def task_publish () -> DoitTask : \"\"\"Build the distributable format(s) and publish. > See the Developer Guide for configuring pypi token > Use in conjunction with `task_cl_bump` Returns: DoitTask: doit task \"\"\" return _publish_task () task_radon_lint \u2693\ufe0e def task_radon_lint () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Lint project with Radon. See documentation: https://radon.readthedocs.io/en/latest/intro.html Returns: Type Description DoitTask doit task View Source @beartype def task_radon_lint () -> DoitTask : \"\"\"Lint project with Radon. See documentation: https://radon.readthedocs.io/en/latest/intro.html Returns: DoitTask: doit task \"\"\" actions : List [ DoitAction ] = [] for args in [ 'mi' , 'cc --total-average -nb' , 'hal' ]: actions . append (( echo , ( f '# Radon with args: { args } ' ,))) actions . extend ([ f 'poetry run radon { args } \" { lint_path } \"' for lint_path in DG . lint . paths_py ]) return debug_task ( actions ) task_security_checks \u2693\ufe0e def task_security_checks () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Use linting tools to identify possible security vulnerabilities. Returns: Type Description DoitTask doit task View Source @beartype def task_security_checks () -> DoitTask : \"\"\"Use linting tools to identify possible security vulnerabilities. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run bandit -r { DG . meta . pkg_name } ' ), Interactive ( 'poetry run nox --session check_safety' ), ]) task_test \u2693\ufe0e def task_test () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run tests with Pytest and stop on the first failure. Test are randomly ordered by default with pytest-randomly because that can help catch common errors Tests can be re-run in the last order with poetry run pytest --randomly-seed=last Tip: --record-mode=rewrite can be useful if working with pytest-recording Returns: Type Description DoitTask doit task View Source @beartype def task_test () -> DoitTask : \"\"\"Run tests with Pytest and stop on the first failure. > Test are randomly ordered by default with pytest-randomly because that can help catch common errors > Tests can be re-run in the last order with `poetry run pytest --randomly-seed=last` > Tip: `--record-mode=rewrite` can be useful if working with `pytest-recording` Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" { DG . test . args_pytest } ' ), ]) task_test_all \u2693\ufe0e def task_test_all () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run all possible tests with Pytest even if one or more failures. Returns: Type Description DoitTask doit task View Source @beartype def task_test_all () -> DoitTask : \"\"\"Run all possible tests with Pytest even if one or more failures. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" --ff -vv' ), ]) task_test_keyword \u2693\ufe0e def task_test_keyword () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Specify a keyword to run a subset of tests. Example: doit run test_keyword -k \"KEYWORD\" Returns: Type Description DoitTask doit task View Source @beartype def task_test_keyword () -> DoitTask : \"\"\"Specify a keyword to run a subset of tests. Example: `doit run test_keyword -k \"KEYWORD\"` Returns: DoitTask: doit task \"\"\" return { 'actions' : [ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" { DG . test . args_pytest } -k \"%(keyword)s\"' ), ], 'params' : [{ 'name' : 'keyword' , 'short' : 'k' , 'long' : 'keyword' , 'default' : '' , 'help' : ( 'Runs only tests that match the string pattern \\n See: ' 'https://docs.pytest.org/en/latest/usage.html#specifying-tests-selecting-tests' ), }], 'verbosity' : 2 , } task_test_marker \u2693\ufe0e def task_test_marker () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Specify a marker to run a subset of tests. Example: doit run test_marker -m \"not MARKER\" or doit run test_marker -m \"MARKER\" Returns: Type Description DoitTask doit task View Source @beartype def task_test_marker () -> DoitTask : \"\"\"Specify a marker to run a subset of tests. Example: `doit run test_marker -m \"not MARKER\"` or `doit run test_marker -m \"MARKER\"` Returns: DoitTask: doit task \"\"\" task = debug_task ([ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" { DG . test . args_pytest } -m \"%(marker)s\"' )]) task [ 'params' ] = [{ 'name' : 'marker' , 'short' : 'm' , 'long' : 'marker' , 'default' : '' , 'help' : ( 'Runs test with specified marker logic \\n See: ' 'https://docs.pytest.org/en/latest/example/markers.html?highlight=-m' ), }] return task","title":"calcipy.doit_tasks"},{"location":"docs/modules/calcipy/doit_tasks/#calcipydoit_tasks","text":"doit Helpers. Register all defaults doit tasks in a dodo.py file with the below snippet: from calcipy.doit_tasks import * # noqa: F401,F403,H303 (Run 'doit list' to see tasks). skipcq: PYL-W0614 View Source \"\"\"doit Helpers. Register all defaults doit tasks in a dodo.py file with the below snippet: `from calcipy.doit_tasks import * # noqa: F401,F403,H303 (Run 'doit list' to see tasks). skipcq: PYL-W0614` \"\"\" __all__ = [ # noqa: F405 'DOIT_CONFIG_RECOMMENDED' , 'TASKS_CI' , 'TASKS_LOCAL' , # from .code_tag_collector 'task_collect_code_tags' , # from .doc 'task_cl_bump_pre' , 'task_cl_bump' , 'task_cl_write' , 'task_deploy_docs' , 'task_document' , 'task_open_docs' , # from .lint 'task_auto_format' , 'task_lint_critical_only' , 'task_lint_project' , 'task_lint_python' , 'task_pre_commit_hooks' , 'task_radon_lint' , 'task_security_checks' , # from .packaging 'task_check_for_stale_packages' , 'task_check_license' , 'task_lock' , 'task_publish' , # from .test 'task_check_types' , 'task_coverage' , 'task_nox_test' , 'task_nox_coverage' , 'task_nox' , 'task_open_test_docs' , 'task_ptw_current' , 'task_ptw_ff' , 'task_ptw_marker' , 'task_ptw_not_chrome' , 'task_test_all' , 'task_test_keyword' , 'task_test_marker' , 'task_test' , ] from getpass import getuser from .code_tag_collector import task_collect_code_tags from .doc import * # noqa: F401,F403,H303. lgtm [py/polluting-import] from .lint import * # noqa: F401,F403,H303. lgtm [py/polluting-import] from .packaging import * # noqa: F401,F403,H303. lgtm [py/polluting-import] from .summary_reporter import SummaryReporter from .test import * # noqa: F401,F403,H303. lgtm [py/polluting-import] TASKS_CI = [ 'nox_test' , 'security_checks' , ] \"\"\"More forgiving tasks to be run in CI.\"\"\" TASKS_LOCAL = [ 'collect_code_tags' , 'cl_write' , 'lock' , 'nox_coverage' , 'auto_format' , 'document' , 'check_for_stale_packages' , 'pre_commit_hooks' , 'lint_project' , 'security_checks' , 'check_types' , ] \"\"\"Full suite of tasks for local development.\"\"\" DOIT_CONFIG_RECOMMENDED = { 'action_string_formatting' : 'old' , # Required for keyword-based tasks 'default_tasks' : TASKS_CI if getuser () . lower () == 'appveyor' else TASKS_LOCAL , 'reporter' : SummaryReporter , } \"\"\"doit Configuration Settings. Run with `poetry run doit`.\"\"\"","title":"calcipy.doit_tasks"},{"location":"docs/modules/calcipy/doit_tasks/#sub-modules","text":"calcipy.doit_tasks.base calcipy.doit_tasks.code_tag_collector calcipy.doit_tasks.doc calcipy.doit_tasks.doit_globals calcipy.doit_tasks.file_search calcipy.doit_tasks.lint calcipy.doit_tasks.packaging calcipy.doit_tasks.summary_reporter calcipy.doit_tasks.test","title":"Sub-modules"},{"location":"docs/modules/calcipy/doit_tasks/#variables","text":"DOIT_CONFIG_RECOMMENDED doit Configuration Settings. Run with poetry run doit . TASKS_CI More forgiving tasks to be run in CI. TASKS_LOCAL Full suite of tasks for local development.","title":"Variables"},{"location":"docs/modules/calcipy/doit_tasks/#functions","text":"","title":"Functions"},{"location":"docs/modules/calcipy/doit_tasks/#task_auto_format","text":"def task_auto_format () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Format code with isort and autopep8. Other Useful Format Snippets: poetry run isort --recursive --check --diff calcipy/ tests/ Returns: Type Description DoitTask doit task View Source @beartype def task_auto_format () -> DoitTask : \"\"\"Format code with isort and autopep8. Other Useful Format Snippets: ```sh poetry run isort --recursive --check --diff calcipy/ tests/ ``` Returns: DoitTask: doit task \"\"\" run = 'poetry run python -m' paths = ' ' . join ( f '\" { pth } \"' for pth in DG . lint . paths_py ) return debug_task ([ f ' { run } autopep8 { paths } --in-place --aggressive' , f ' { run } isort { paths } --settings-path \" { DG . lint . path_isort } \"' , ])","title":"task_auto_format"},{"location":"docs/modules/calcipy/doit_tasks/#task_check_for_stale_packages","text":"def task_check_for_stale_packages () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Check for stale packages. Returns: Type Description DoitTask doit task View Source @beartype def task_check_for_stale_packages () -> DoitTask : \"\"\"Check for stale packages. Returns: DoitTask: doit task \"\"\" path_lock = DG . meta . path_project / 'poetry.lock' path_pack_lock = _PATH_PACK_LOCK task = debug_task ([ ( find_stale_packages , ( path_lock , path_pack_lock ), { 'stale_months' : 48 }), Interactive ( 'poetry run pip list --outdated' ), ]) task [ 'file_dep' ] . append ( path_lock ) task [ 'targets' ] . append ( path_pack_lock ) return task","title":"task_check_for_stale_packages"},{"location":"docs/modules/calcipy/doit_tasks/#task_check_license","text":"def task_check_license () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Check licenses for compatibility. Returns: Type Description DoitTask doit task View Source @beartype def task_check_license () -> DoitTask : \"\"\"Check licenses for compatibility. Returns: DoitTask: doit task \"\"\" return debug_task ([ 'poetry run licensecheck --zero' ])","title":"task_check_license"},{"location":"docs/modules/calcipy/doit_tasks/#task_check_types","text":"def task_check_types () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run type annotation checks. Returns: Type Description DoitTask doit task View Source @beartype def task_check_types () -> DoitTask : \"\"\"Run type annotation checks. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run mypy { DG . meta . pkg_name } --show-error-codes' ), ])","title":"task_check_types"},{"location":"docs/modules/calcipy/doit_tasks/#task_cl_bump","text":"def task_cl_bump () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Bumps project version based on commits & settings in pyproject.toml. Returns: Type Description DoitTask doit task View Source @beartype def task_cl_bump () -> DoitTask : \"\"\"Bumps project version based on commits & settings in pyproject.toml. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run cz bump --changelog --annotated-tag' ), ( _move_cl , ()), 'git push origin --tags --no-verify' , ])","title":"task_cl_bump"},{"location":"docs/modules/calcipy/doit_tasks/#task_cl_bump_pre","text":"def task_cl_bump_pre () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Bump with specified pre-release tag. Example: doit run cl_bump_pre -p alpha or doit run cl_bump_pre -p rc Returns: Type Description DoitTask doit task View Source @beartype def task_cl_bump_pre () -> DoitTask : \"\"\"Bump with specified pre-release tag. Example: `doit run cl_bump_pre -p alpha` or `doit run cl_bump_pre -p rc` Returns: DoitTask: doit task \"\"\" task = debug_task ([ Interactive ( 'poetry run cz bump --changelog --prerelease %(prerelease)s ' ), ( _move_cl , ()), 'git push origin --tags --no-verify' , ]) task [ 'params' ] = [{ 'name' : 'prerelease' , 'short' : 'p' , 'long' : 'prerelease' , 'default' : '' , 'help' : 'Specify prerelease version for bump (alpha, beta, rc)' , }] return task","title":"task_cl_bump_pre"},{"location":"docs/modules/calcipy/doit_tasks/#task_cl_write","text":"def task_cl_write () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Write a Changelog file with the raw Git history. Resources: https://keepachangelog.com/en/1.0.0/ https://www.conventionalcommits.org/en/v1.0.0/ https://writingfordevelopers.substack.com/p/how-to-write-a-commit-message https://chris.beams.io/posts/git-commit/ https://semver.org/ https://calver.org/ Returns: Type Description DoitTask doit task View Source @beartype def task_cl_write () -> DoitTask : \"\"\"Write a Changelog file with the raw Git history. Resources: - https://keepachangelog.com/en/1.0.0/ - https://www.conventionalcommits.org/en/v1.0.0/ - https://writingfordevelopers.substack.com/p/how-to-write-a-commit-message - https://chris.beams.io/posts/git-commit/ - https://semver.org/ - https://calver.org/ Returns: DoitTask: doit task \"\"\" return debug_task ([ 'poetry run cz changelog' , ( _move_cl , ()), ])","title":"task_cl_write"},{"location":"docs/modules/calcipy/doit_tasks/#task_collect_code_tags","text":"def task_collect_code_tags () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Create a summary file with all of the found code tags. Returns: Type Description DoitTask doit task View Source @beartype def task_collect_code_tags () -> DoitTask : \"\"\"Create a summary file with all of the found code tags. Returns: DoitTask: doit task \"\"\" return debug_task ([( _write_code_tag_file , ( DG . ct . path_code_tag_summary ,))])","title":"task_collect_code_tags"},{"location":"docs/modules/calcipy/doit_tasks/#task_coverage","text":"def task_coverage () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run pytest and create coverage and test reports. Returns: Type Description DoitTask doit task View Source @beartype def task_coverage () -> DoitTask : \"\"\"Run pytest and create coverage and test reports. Returns: DoitTask: doit task \"\"\" path_tests = DG . test . path_tests cov_dir = DG . test . path_coverage_index . parent cov_html = f '--cov-report=html:\" { cov_dir } \" --html=\" { DG . test . path_test_report } \" --self-contained-html' diff_html = f '--html-report { DG . test . path_diff_test_report } ' return debug_task ([ Interactive ( f 'poetry run pytest \" { path_tests } \" { DG . test . args_pytest } --cov= { DG . meta . pkg_name } { cov_html } ' ), 'poetry run python -m coverage json' , # Create coverage.json file for \"_write_coverage_to_md\" 'poetry run python -m coverage xml' , Interactive ( f 'poetry run diff-cover coverage.xml { DG . test . args_diff } { diff_html } ' ), ])","title":"task_coverage"},{"location":"docs/modules/calcipy/doit_tasks/#task_deploy_docs","text":"def task_deploy_docs () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Deploy docs to the Github gh-pages branch. Returns: Type Description DoitTask doit task View Source @beartype def task_deploy_docs () -> DoitTask : \"\"\"Deploy docs to the Github `gh-pages` branch. Returns: DoitTask: doit task \"\"\" if _is_mkdocs_local (): # pragma: no cover return debug_task ([ ( NotImplementedError , ( 'Deploy cannot be used with mkdocs built with local-links' ,)), ]) return debug_task ([ Interactive ( 'poetry run mkdocs gh-deploy' )])","title":"task_deploy_docs"},{"location":"docs/modules/calcipy/doit_tasks/#task_document","text":"def task_document () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Build the HTML documentation. Returns: Type Description DoitTask doit task View Source @beartype def task_document () -> DoitTask : \"\"\"Build the HTML documentation. Returns: DoitTask: doit task \"\"\" _ensure_handler_lookup () pdoc_out = f '--output_dir { DG . doc . doc_dir } /modules --overwrite' pdoc_template = f '--template_dir { DG . calcipy_dir } /doit_tasks/templates' return debug_task ([ ( write_autoformatted_md_sections , ()), Interactive ( f 'poetry run pdocs as_markdown { DG . meta . pkg_name } { pdoc_out } { pdoc_template } ' ), Interactive ( f 'poetry run mkdocs build --site-dir { DG . doc . path_out } ' ), ])","title":"task_document"},{"location":"docs/modules/calcipy/doit_tasks/#task_lint_critical_only","text":"def task_lint_critical_only () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Suppress non-critical linting errors. Great for gating PRs/commits. Returns: Type Description DoitTask doit task View Source @beartype def task_lint_critical_only () -> DoitTask : \"\"\"Suppress non-critical linting errors. Great for gating PRs/commits. Returns: DoitTask: doit task \"\"\" actions = _lint_python ( DG . lint . paths_py , path_flake8 = DG . lint . path_flake8 , ignore_errors = DG . lint . ignore_errors ) actions . extend ( _lint_non_python ()) return debug_task ( actions )","title":"task_lint_critical_only"},{"location":"docs/modules/calcipy/doit_tasks/#task_lint_project","text":"def task_lint_project () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Lint all project files that can be checked. Returns: Type Description DoitTask doit task View Source @beartype def task_lint_project () -> DoitTask : \"\"\"Lint all project files that can be checked. Returns: DoitTask: doit task \"\"\" actions = _lint_python ( DG . lint . paths_py , path_flake8 = DG . lint . path_flake8 , ignore_errors = []) actions . extend ( _lint_non_python ( strict = True )) return debug_task ( actions )","title":"task_lint_project"},{"location":"docs/modules/calcipy/doit_tasks/#task_lint_python","text":"def task_lint_python () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Lint all Python files and create summary of errors. Returns: Type Description DoitTask doit task View Source @beartype def task_lint_python () -> DoitTask : \"\"\"Lint all Python files and create summary of errors. Returns: DoitTask: doit task \"\"\" actions = _lint_python ( DG . lint . paths_py , path_flake8 = DG . lint . path_flake8 , ignore_errors = []) return debug_task ( actions )","title":"task_lint_python"},{"location":"docs/modules/calcipy/doit_tasks/#task_lock","text":"def task_lock () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Lock dependencies. Returns: Type Description DoitTask doit task View Source @beartype def task_lock () -> DoitTask : \"\"\"Lock dependencies. Returns: DoitTask: doit task \"\"\" path_req = DG . meta . path_project / 'requirements.txt' # Ensure that extras are exported as well toml_data = toml . loads ( DG . meta . path_toml . read_text ()) extras = [ * toml_data [ 'tool' ][ 'poetry' ] . get ( 'extras' , {}) . keys ()] extras_arg = ' -E ' . join ([ '' ] + extras ) if extras else '' task = debug_task ([ 'poetry lock' , f 'poetry export -f { path_req . name } -o { path_req . name }{ extras_arg } --dev' , ]) task [ 'file_dep' ] . append ( DG . meta . path_toml ) task [ 'targets' ] . extend ([ DG . meta . path_project / 'poetry.lock' , path_req ]) return task","title":"task_lock"},{"location":"docs/modules/calcipy/doit_tasks/#task_nox","text":"def task_nox () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run the full nox test suite. Note: some nox tasks are run in more-specific doit tasks, but this will run everything Returns: Type Description DoitTask doit task View Source @beartype def task_nox () -> DoitTask : \"\"\"Run the full nox test suite. > Note: some nox tasks are run in more-specific doit tasks, but this will run everything Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run nox' ), ])","title":"task_nox"},{"location":"docs/modules/calcipy/doit_tasks/#task_nox_coverage","text":"def task_nox_coverage () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run all nox tests. Returns: Type Description DoitTask doit task View Source @beartype def task_nox_coverage () -> DoitTask : \"\"\"Run all nox tests. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run nox --session coverage' ), ])","title":"task_nox_coverage"},{"location":"docs/modules/calcipy/doit_tasks/#task_nox_test","text":"def task_nox_test () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run all nox tests. Returns: Type Description DoitTask doit task View Source @beartype def task_nox_test () -> DoitTask : \"\"\"Run all nox tests. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run nox --session tests build_check' ), ])","title":"task_nox_test"},{"location":"docs/modules/calcipy/doit_tasks/#task_open_docs","text":"def task_open_docs () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Open the documentation files in the default browser. Returns: Type Description DoitTask doit task View Source @beartype def task_open_docs () -> DoitTask : \"\"\"Open the documentation files in the default browser. Returns: DoitTask: doit task \"\"\" if _is_mkdocs_local (): # pragma: no cover path_doc_index = DG . doc . path_out / DG . meta . pkg_name / 'index.html' return debug_task ([ ( open_in_browser , ( path_doc_index ,)), ]) return debug_task ([ ( webbrowser . open , ( 'http://localhost:8000' ,)), Interactive ( 'poetry run mkdocs serve --dirtyreload' ), ])","title":"task_open_docs"},{"location":"docs/modules/calcipy/doit_tasks/#task_open_test_docs","text":"def task_open_test_docs () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Open the test and coverage files in default browser. Returns: Type Description DoitTask doit task View Source @beartype def task_open_test_docs () -> DoitTask : \"\"\"Open the test and coverage files in default browser. Returns: DoitTask: doit task \"\"\" actions = [ ( open_in_browser , ( DG . test . path_coverage_index ,)), ( open_in_browser , ( DG . test . path_test_report ,)), ] if DG . test . path_mypy_index . is_file (): actions . append (( open_in_browser , ( DG . test . path_mypy_index ,))) return debug_task ( actions )","title":"task_open_test_docs"},{"location":"docs/modules/calcipy/doit_tasks/#task_pre_commit_hooks","text":"def task_pre_commit_hooks () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run the pre-commit hooks on all files. Note: use git commit or git push with --no-verify if needed Returns: Type Description DoitTask doit task View Source @beartype def task_pre_commit_hooks () -> DoitTask : \"\"\"Run the [pre-commit hooks](https://pre-commit.com/) on all files. > Note: use `git commit` or `git push` with `--no-verify` if needed Returns: DoitTask: doit task \"\"\" # Only use these two stages for all pre-commit hooks stages = [ 'commit-msg' , 'pre-push' ] return debug_task ([ Interactive ( 'poetry run pre-commit autoupdate' ), Interactive ( 'poetry run pre-commit install --install-hooks' + ' --hook-type ' . join ([ '' ] + stages )), Interactive ( 'poetry run pre-commit run --all-files --hook-stage push' ), ])","title":"task_pre_commit_hooks"},{"location":"docs/modules/calcipy/doit_tasks/#task_ptw_current","text":"def task_ptw_current () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run pytest watch for only tests with the CURRENT marker. kwargs: -m 'CURRENT' -vv Returns: Type Description DoitTask doit task View Source @beartype def task_ptw_current () -> DoitTask : \"\"\"Run pytest watch for only tests with the CURRENT marker. kwargs: `-m 'CURRENT' -vv` Returns: DoitTask: doit task \"\"\" return ptw_task ( '-m \"CURRENT\" -vv' )","title":"task_ptw_current"},{"location":"docs/modules/calcipy/doit_tasks/#task_ptw_ff","text":"def task_ptw_ff () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run pytest watch for failed first and skip the CHROME marker. kwargs: --last-failed --new-first -m 'not CHROME' -vv Returns: Type Description DoitTask doit task View Source @beartype def task_ptw_ff () -> DoitTask : \"\"\"Run pytest watch for failed first and skip the CHROME marker. kwargs: `--last-failed --new-first -m 'not CHROME' -vv` Returns: DoitTask: doit task \"\"\" return ptw_task ( '--last-failed --new-first -m \"not CHROME\" -vv' )","title":"task_ptw_ff"},{"location":"docs/modules/calcipy/doit_tasks/#task_ptw_marker","text":"def task_ptw_marker () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Specify a marker to run a subset of tests in Interactive ptw task. Example: doit run ptw_marker -m \"not MARKER\" or doit run ptw_marker -m \"MARKER\" Returns: Type Description DoitTask doit task View Source @beartype def task_ptw_marker () -> DoitTask : \"\"\"Specify a marker to run a subset of tests in Interactive `ptw` task. Example: `doit run ptw_marker -m \"not MARKER\"` or `doit run ptw_marker -m \"MARKER\"` Returns: DoitTask: doit task \"\"\" task = ptw_task ( '-vvv -m \" %(marker)s \"' ) task [ 'params' ] = [{ 'name' : 'marker' , 'short' : 'm' , 'long' : 'marker' , 'default' : '' , 'help' : ( 'Runs test with specified marker logic \\n See: ' 'https://docs.pytest.org/en/latest/example/markers.html?highlight=-m' ), }] return task","title":"task_ptw_marker"},{"location":"docs/modules/calcipy/doit_tasks/#task_ptw_not_chrome","text":"def task_ptw_not_chrome () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run pytest watch for failed first and skip the CHROME marker. kwargs: -m 'not CHROME' -vvv Returns: Type Description DoitTask doit task View Source @beartype def task_ptw_not_chrome () -> DoitTask : \"\"\"Run pytest watch for failed first and skip the CHROME marker. kwargs: `-m 'not CHROME' -vvv` Returns: DoitTask: doit task \"\"\" return ptw_task ( '-m \"not CHROME\" -vvv' )","title":"task_ptw_not_chrome"},{"location":"docs/modules/calcipy/doit_tasks/#task_publish","text":"def task_publish () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Build the distributable format(s) and publish. See the Developer Guide for configuring pypi token Use in conjunction with task_cl_bump Returns: Type Description DoitTask doit task View Source @beartype def task_publish () -> DoitTask : \"\"\"Build the distributable format(s) and publish. > See the Developer Guide for configuring pypi token > Use in conjunction with `task_cl_bump` Returns: DoitTask: doit task \"\"\" return _publish_task ()","title":"task_publish"},{"location":"docs/modules/calcipy/doit_tasks/#task_radon_lint","text":"def task_radon_lint () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Lint project with Radon. See documentation: https://radon.readthedocs.io/en/latest/intro.html Returns: Type Description DoitTask doit task View Source @beartype def task_radon_lint () -> DoitTask : \"\"\"Lint project with Radon. See documentation: https://radon.readthedocs.io/en/latest/intro.html Returns: DoitTask: doit task \"\"\" actions : List [ DoitAction ] = [] for args in [ 'mi' , 'cc --total-average -nb' , 'hal' ]: actions . append (( echo , ( f '# Radon with args: { args } ' ,))) actions . extend ([ f 'poetry run radon { args } \" { lint_path } \"' for lint_path in DG . lint . paths_py ]) return debug_task ( actions )","title":"task_radon_lint"},{"location":"docs/modules/calcipy/doit_tasks/#task_security_checks","text":"def task_security_checks () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Use linting tools to identify possible security vulnerabilities. Returns: Type Description DoitTask doit task View Source @beartype def task_security_checks () -> DoitTask : \"\"\"Use linting tools to identify possible security vulnerabilities. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run bandit -r { DG . meta . pkg_name } ' ), Interactive ( 'poetry run nox --session check_safety' ), ])","title":"task_security_checks"},{"location":"docs/modules/calcipy/doit_tasks/#task_test","text":"def task_test () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run tests with Pytest and stop on the first failure. Test are randomly ordered by default with pytest-randomly because that can help catch common errors Tests can be re-run in the last order with poetry run pytest --randomly-seed=last Tip: --record-mode=rewrite can be useful if working with pytest-recording Returns: Type Description DoitTask doit task View Source @beartype def task_test () -> DoitTask : \"\"\"Run tests with Pytest and stop on the first failure. > Test are randomly ordered by default with pytest-randomly because that can help catch common errors > Tests can be re-run in the last order with `poetry run pytest --randomly-seed=last` > Tip: `--record-mode=rewrite` can be useful if working with `pytest-recording` Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" { DG . test . args_pytest } ' ), ])","title":"task_test"},{"location":"docs/modules/calcipy/doit_tasks/#task_test_all","text":"def task_test_all () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run all possible tests with Pytest even if one or more failures. Returns: Type Description DoitTask doit task View Source @beartype def task_test_all () -> DoitTask : \"\"\"Run all possible tests with Pytest even if one or more failures. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" --ff -vv' ), ])","title":"task_test_all"},{"location":"docs/modules/calcipy/doit_tasks/#task_test_keyword","text":"def task_test_keyword () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Specify a keyword to run a subset of tests. Example: doit run test_keyword -k \"KEYWORD\" Returns: Type Description DoitTask doit task View Source @beartype def task_test_keyword () -> DoitTask : \"\"\"Specify a keyword to run a subset of tests. Example: `doit run test_keyword -k \"KEYWORD\"` Returns: DoitTask: doit task \"\"\" return { 'actions' : [ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" { DG . test . args_pytest } -k \"%(keyword)s\"' ), ], 'params' : [{ 'name' : 'keyword' , 'short' : 'k' , 'long' : 'keyword' , 'default' : '' , 'help' : ( 'Runs only tests that match the string pattern \\n See: ' 'https://docs.pytest.org/en/latest/usage.html#specifying-tests-selecting-tests' ), }], 'verbosity' : 2 , }","title":"task_test_keyword"},{"location":"docs/modules/calcipy/doit_tasks/#task_test_marker","text":"def task_test_marker () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Specify a marker to run a subset of tests. Example: doit run test_marker -m \"not MARKER\" or doit run test_marker -m \"MARKER\" Returns: Type Description DoitTask doit task View Source @beartype def task_test_marker () -> DoitTask : \"\"\"Specify a marker to run a subset of tests. Example: `doit run test_marker -m \"not MARKER\"` or `doit run test_marker -m \"MARKER\"` Returns: DoitTask: doit task \"\"\" task = debug_task ([ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" { DG . test . args_pytest } -m \"%(marker)s\"' )]) task [ 'params' ] = [{ 'name' : 'marker' , 'short' : 'm' , 'long' : 'marker' , 'default' : '' , 'help' : ( 'Runs test with specified marker logic \\n See: ' 'https://docs.pytest.org/en/latest/example/markers.html?highlight=-m' ), }] return task","title":"task_test_marker"},{"location":"docs/modules/calcipy/doit_tasks/base/","text":"calcipy.doit_tasks.base \u2693\ufe0e General doit Utilities. View Source \"\"\"General doit Utilities.\"\"\" import webbrowser from collections import defaultdict from pathlib import Path from typing import Iterable from beartype import beartype from doit.task import Task from loguru import logger from .doit_globals import DoitAction , DoitTask @beartype def _show_cmd ( task : Task ) -> str : \"\"\"For debugging, log the full command to the console. Args: task: doit Task Returns: str: describing the sequence of actions \"\"\" actions = '' . join ( f ' \\n\\t { act } ' for act in task . actions ) return f ' { task . name } > [ { actions } \\n ] \\n ' @beartype def debug_task ( actions : Iterable [ DoitAction ], verbosity : int = 2 ) -> DoitTask : \"\"\"Activate verbose logging for the specified actions. Args: actions: list of doit actions verbosity: 2 is maximum, while 0 is deactivated. Default is 2 Returns: DoitTask: doit task \"\"\" task : DoitTask = defaultdict ( list ) task [ 'actions' ] = actions task [ 'title' ] = _show_cmd task [ 'verbosity' ] = verbosity logger . debug ( 'Created task. See extras' , task = f ' { task } ' ) return task @beartype def echo ( msg : str ) -> None : \"\"\"Wrap the system print command. Args: msg: string to write to STDOUT \"\"\" print ( msg ) # noqa: T001 # pragma: no cover @beartype def write_text ( path_file : Path , text : str ) -> None : \"\"\"path_file.write_text wrapper for doit. Args: path_file: Path to the file text: string to write to file \"\"\" path_file . write_text ( text ) # pragma: no cover @beartype def open_in_browser ( path_file : Path ) -> None : \"\"\"Open the path in the default web browser. Args: path_file: Path to file \"\"\" webbrowser . open ( Path ( path_file ) . as_uri ()) # pragma: no cover Functions \u2693\ufe0e debug_task \u2693\ufe0e def debug_task ( actions : Iterable [ Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]], verbosity : int = 2 ) -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Activate verbose logging for the specified actions. Parameters: Name Type Description Default actions None list of doit actions None verbosity None 2 is maximum, while 0 is deactivated. Default is 2 None Returns: Type Description DoitTask doit task View Source @beartype def debug_task ( actions : Iterable [ DoitAction ], verbosity : int = 2 ) -> DoitTask : \"\"\"Activate verbose logging for the specified actions. Args: actions: list of doit actions verbosity: 2 is maximum, while 0 is deactivated. Default is 2 Returns: DoitTask: doit task \"\"\" task : DoitTask = defaultdict ( list ) task [ 'actions' ] = actions task [ 'title' ] = _show_cmd task [ 'verbosity' ] = verbosity logger . debug ( 'Created task. See extras' , task = f ' { task } ' ) return task echo \u2693\ufe0e def echo ( msg : str ) -> None Wrap the system print command. Parameters: Name Type Description Default msg None string to write to STDOUT None View Source @beartype def echo ( msg : str ) -> None : \"\"\"Wrap the system print command. Args: msg: string to write to STDOUT \"\"\" print ( msg ) # noqa: T001 # pragma: no cover open_in_browser \u2693\ufe0e def open_in_browser ( path_file : pathlib . Path ) -> None Open the path in the default web browser. Parameters: Name Type Description Default path_file None Path to file None View Source @beartype def open_in_browser ( path_file : Path ) -> None : \"\"\"Open the path in the default web browser. Args: path_file: Path to file \"\"\" webbrowser . open ( Path ( path_file ) . as_uri ()) # pragma: no cover write_text \u2693\ufe0e def write_text ( path_file : pathlib . Path , text : str ) -> None path_file.write_text wrapper for doit. Parameters: Name Type Description Default path_file None Path to the file None text None string to write to file None View Source @beartype def write_text ( path_file : Path , text : str ) -> None : \"\"\"path_file.write_text wrapper for doit. Args: path_file: Path to the file text: string to write to file \"\"\" path_file . write_text ( text ) # pragma: no cover","title":"calcipy.doit_tasks.base"},{"location":"docs/modules/calcipy/doit_tasks/base/#calcipydoit_tasksbase","text":"General doit Utilities. View Source \"\"\"General doit Utilities.\"\"\" import webbrowser from collections import defaultdict from pathlib import Path from typing import Iterable from beartype import beartype from doit.task import Task from loguru import logger from .doit_globals import DoitAction , DoitTask @beartype def _show_cmd ( task : Task ) -> str : \"\"\"For debugging, log the full command to the console. Args: task: doit Task Returns: str: describing the sequence of actions \"\"\" actions = '' . join ( f ' \\n\\t { act } ' for act in task . actions ) return f ' { task . name } > [ { actions } \\n ] \\n ' @beartype def debug_task ( actions : Iterable [ DoitAction ], verbosity : int = 2 ) -> DoitTask : \"\"\"Activate verbose logging for the specified actions. Args: actions: list of doit actions verbosity: 2 is maximum, while 0 is deactivated. Default is 2 Returns: DoitTask: doit task \"\"\" task : DoitTask = defaultdict ( list ) task [ 'actions' ] = actions task [ 'title' ] = _show_cmd task [ 'verbosity' ] = verbosity logger . debug ( 'Created task. See extras' , task = f ' { task } ' ) return task @beartype def echo ( msg : str ) -> None : \"\"\"Wrap the system print command. Args: msg: string to write to STDOUT \"\"\" print ( msg ) # noqa: T001 # pragma: no cover @beartype def write_text ( path_file : Path , text : str ) -> None : \"\"\"path_file.write_text wrapper for doit. Args: path_file: Path to the file text: string to write to file \"\"\" path_file . write_text ( text ) # pragma: no cover @beartype def open_in_browser ( path_file : Path ) -> None : \"\"\"Open the path in the default web browser. Args: path_file: Path to file \"\"\" webbrowser . open ( Path ( path_file ) . as_uri ()) # pragma: no cover","title":"calcipy.doit_tasks.base"},{"location":"docs/modules/calcipy/doit_tasks/base/#functions","text":"","title":"Functions"},{"location":"docs/modules/calcipy/doit_tasks/base/#debug_task","text":"def debug_task ( actions : Iterable [ Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]], verbosity : int = 2 ) -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Activate verbose logging for the specified actions. Parameters: Name Type Description Default actions None list of doit actions None verbosity None 2 is maximum, while 0 is deactivated. Default is 2 None Returns: Type Description DoitTask doit task View Source @beartype def debug_task ( actions : Iterable [ DoitAction ], verbosity : int = 2 ) -> DoitTask : \"\"\"Activate verbose logging for the specified actions. Args: actions: list of doit actions verbosity: 2 is maximum, while 0 is deactivated. Default is 2 Returns: DoitTask: doit task \"\"\" task : DoitTask = defaultdict ( list ) task [ 'actions' ] = actions task [ 'title' ] = _show_cmd task [ 'verbosity' ] = verbosity logger . debug ( 'Created task. See extras' , task = f ' { task } ' ) return task","title":"debug_task"},{"location":"docs/modules/calcipy/doit_tasks/base/#echo","text":"def echo ( msg : str ) -> None Wrap the system print command. Parameters: Name Type Description Default msg None string to write to STDOUT None View Source @beartype def echo ( msg : str ) -> None : \"\"\"Wrap the system print command. Args: msg: string to write to STDOUT \"\"\" print ( msg ) # noqa: T001 # pragma: no cover","title":"echo"},{"location":"docs/modules/calcipy/doit_tasks/base/#open_in_browser","text":"def open_in_browser ( path_file : pathlib . Path ) -> None Open the path in the default web browser. Parameters: Name Type Description Default path_file None Path to file None View Source @beartype def open_in_browser ( path_file : Path ) -> None : \"\"\"Open the path in the default web browser. Args: path_file: Path to file \"\"\" webbrowser . open ( Path ( path_file ) . as_uri ()) # pragma: no cover","title":"open_in_browser"},{"location":"docs/modules/calcipy/doit_tasks/base/#write_text","text":"def write_text ( path_file : pathlib . Path , text : str ) -> None path_file.write_text wrapper for doit. Parameters: Name Type Description Default path_file None Path to the file None text None string to write to file None View Source @beartype def write_text ( path_file : Path , text : str ) -> None : \"\"\"path_file.write_text wrapper for doit. Args: path_file: Path to the file text: string to write to file \"\"\" path_file . write_text ( text ) # pragma: no cover","title":"write_text"},{"location":"docs/modules/calcipy/doit_tasks/code_tag_collector/","text":"calcipy.doit_tasks.code_tag_collector \u2693\ufe0e Collect code tags and output for review in a single location. View Source \"\"\"Collect code tags and output for review in a single location.\"\"\" from collections import defaultdict from pathlib import Path from typing import Dict , List , Pattern , Sequence import attr from beartype import beartype from loguru import logger from ..file_helpers import read_lines from ..log_helpers import log_fun from .base import debug_task from .doit_globals import DG , DoitTask SKIP_PHRASE = 'calcipy:skip_tags' \"\"\"String that indicates the file should be excluded from the tag search.\"\"\" @attr . s ( auto_attribs = True ) class _CodeTag : # noqa: H601 \"\"\"Code Tag (FIXME,TODO,etc) with contextual information.\"\"\" # noqa: T100,T101 lineno : int tag : str text : str @attr . s ( auto_attribs = True ) class _Tags : # noqa: H601 \"\"\"Collection of code tags with additional contextual information.\"\"\" path_source : Path code_tags : List [ _CodeTag ] @beartype def _search_lines ( lines : List [ str ], regex_compiled : Pattern [ str ], skip_phrase : str = 'calcipy:skip_tags' , ) -> List [ _CodeTag ]: \"\"\"Search lines of text for matches to the compiled regular expression. Args: lines: lines of text as list regex_compiled: compiled regular expression. Expected to have matching groups `(tag, text)` skip_phrase: skip file if string is found in final two lines. Default is `SKIP_PHRASE` Returns: List[_CodeTag]: list of all code tags found in lines \"\"\" if skip_phrase in ' \\n ' . join ( lines [ - 2 :]): return [] comments = [] for lineno , line in enumerate ( lines ): match = regex_compiled . search ( line ) if match : mg = match . groupdict () comments . append ( _CodeTag ( lineno + 1 , tag = mg [ 'tag' ], text = mg [ 'text' ])) return comments @beartype def _search_files ( paths_source : Sequence [ Path ], regex_compiled : Pattern [ str ]) -> List [ _Tags ]: \"\"\"Collect matches from multiple files. Args: paths_source: list of source files to parse regex_compiled: compiled regular expression. Expected to have matching groups `(tag, text)` Returns: List[_Tags]: list of all code tags found in files \"\"\" matches = [] for path_source in paths_source : lines = [] try : lines = read_lines ( path_source ) except UnicodeDecodeError as err : logger . warning ( f 'Could not parse: { path_source } ' , err = err ) comments = _search_lines ( lines , regex_compiled ) if comments : matches . append ( _Tags ( path_source , comments )) return matches @beartype def _format_report ( base_dir : Path , code_tags : List [ _Tags ]) -> str : # noqa: CCR001 \"\"\"Pretty-format the code tags by file and line number. Args: base_dir: base directory relative to the searched files code_tags: list of all code tags found in files Returns: str: pretty-formatted text \"\"\" output = '' counter : Dict [ str , int ] = defaultdict ( lambda : 0 ) for comments in sorted ( code_tags , key = lambda tc : tc . path_source , reverse = False ): output += f '- { comments . path_source . relative_to ( base_dir ) . as_posix () } \\n ' for comment in comments . code_tags : output += f ' - line { comment . lineno : >3 } { comment . tag : >7 } : { comment . text } \\n ' counter [ comment . tag ] += 1 output += ' \\n ' logger . debug ( 'counter= {counter} ' , counter = counter ) sorted_counter = { tag : counter [ tag ] for tag in DG . ct . tags if tag in counter } logger . debug ( 'sorted_counter= {sorted_counter} ' , sorted_counter = sorted_counter ) formatted_summary = ', ' . join ( f ' { tag } ( { count } )' for tag , count in sorted_counter . items ()) if formatted_summary : output += f 'Found code tags for { formatted_summary } \\n ' return output @log_fun @beartype def _write_code_tag_file ( path_tag_summary : Path ) -> None : \"\"\"Create the code tag summary file. Args: path_tag_summary: Path to the output file \"\"\" header = f '# Task Summary \\n\\n Auto-Generated by ` { DG . meta . pkg_name } `' regex_compiled = DG . ct . compile_issue_regex () matches = _search_files ( DG . meta . paths , regex_compiled ) report = _format_report ( DG . meta . path_project , matches ) . strip () if report : path_tag_summary . write_text ( f ' { header } \\n\\n { report } \\n\\n <!-- { SKIP_PHRASE } --> \\n ' ) elif path_tag_summary . is_file (): path_tag_summary . unlink () @beartype def task_collect_code_tags () -> DoitTask : \"\"\"Create a summary file with all of the found code tags. Returns: DoitTask: doit task \"\"\" return debug_task ([( _write_code_tag_file , ( DG . ct . path_code_tag_summary ,))]) Variables \u2693\ufe0e SKIP_PHRASE String that indicates the file should be excluded from the tag search. Functions \u2693\ufe0e task_collect_code_tags \u2693\ufe0e def task_collect_code_tags () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Create a summary file with all of the found code tags. Returns: Type Description DoitTask doit task View Source @beartype def task_collect_code_tags () -> DoitTask : \"\"\"Create a summary file with all of the found code tags. Returns: DoitTask: doit task \"\"\" return debug_task ([( _write_code_tag_file , ( DG . ct . path_code_tag_summary ,))])","title":"calcipy.doit_tasks.code_tag_collector"},{"location":"docs/modules/calcipy/doit_tasks/code_tag_collector/#calcipydoit_taskscode_tag_collector","text":"Collect code tags and output for review in a single location. View Source \"\"\"Collect code tags and output for review in a single location.\"\"\" from collections import defaultdict from pathlib import Path from typing import Dict , List , Pattern , Sequence import attr from beartype import beartype from loguru import logger from ..file_helpers import read_lines from ..log_helpers import log_fun from .base import debug_task from .doit_globals import DG , DoitTask SKIP_PHRASE = 'calcipy:skip_tags' \"\"\"String that indicates the file should be excluded from the tag search.\"\"\" @attr . s ( auto_attribs = True ) class _CodeTag : # noqa: H601 \"\"\"Code Tag (FIXME,TODO,etc) with contextual information.\"\"\" # noqa: T100,T101 lineno : int tag : str text : str @attr . s ( auto_attribs = True ) class _Tags : # noqa: H601 \"\"\"Collection of code tags with additional contextual information.\"\"\" path_source : Path code_tags : List [ _CodeTag ] @beartype def _search_lines ( lines : List [ str ], regex_compiled : Pattern [ str ], skip_phrase : str = 'calcipy:skip_tags' , ) -> List [ _CodeTag ]: \"\"\"Search lines of text for matches to the compiled regular expression. Args: lines: lines of text as list regex_compiled: compiled regular expression. Expected to have matching groups `(tag, text)` skip_phrase: skip file if string is found in final two lines. Default is `SKIP_PHRASE` Returns: List[_CodeTag]: list of all code tags found in lines \"\"\" if skip_phrase in ' \\n ' . join ( lines [ - 2 :]): return [] comments = [] for lineno , line in enumerate ( lines ): match = regex_compiled . search ( line ) if match : mg = match . groupdict () comments . append ( _CodeTag ( lineno + 1 , tag = mg [ 'tag' ], text = mg [ 'text' ])) return comments @beartype def _search_files ( paths_source : Sequence [ Path ], regex_compiled : Pattern [ str ]) -> List [ _Tags ]: \"\"\"Collect matches from multiple files. Args: paths_source: list of source files to parse regex_compiled: compiled regular expression. Expected to have matching groups `(tag, text)` Returns: List[_Tags]: list of all code tags found in files \"\"\" matches = [] for path_source in paths_source : lines = [] try : lines = read_lines ( path_source ) except UnicodeDecodeError as err : logger . warning ( f 'Could not parse: { path_source } ' , err = err ) comments = _search_lines ( lines , regex_compiled ) if comments : matches . append ( _Tags ( path_source , comments )) return matches @beartype def _format_report ( base_dir : Path , code_tags : List [ _Tags ]) -> str : # noqa: CCR001 \"\"\"Pretty-format the code tags by file and line number. Args: base_dir: base directory relative to the searched files code_tags: list of all code tags found in files Returns: str: pretty-formatted text \"\"\" output = '' counter : Dict [ str , int ] = defaultdict ( lambda : 0 ) for comments in sorted ( code_tags , key = lambda tc : tc . path_source , reverse = False ): output += f '- { comments . path_source . relative_to ( base_dir ) . as_posix () } \\n ' for comment in comments . code_tags : output += f ' - line { comment . lineno : >3 } { comment . tag : >7 } : { comment . text } \\n ' counter [ comment . tag ] += 1 output += ' \\n ' logger . debug ( 'counter= {counter} ' , counter = counter ) sorted_counter = { tag : counter [ tag ] for tag in DG . ct . tags if tag in counter } logger . debug ( 'sorted_counter= {sorted_counter} ' , sorted_counter = sorted_counter ) formatted_summary = ', ' . join ( f ' { tag } ( { count } )' for tag , count in sorted_counter . items ()) if formatted_summary : output += f 'Found code tags for { formatted_summary } \\n ' return output @log_fun @beartype def _write_code_tag_file ( path_tag_summary : Path ) -> None : \"\"\"Create the code tag summary file. Args: path_tag_summary: Path to the output file \"\"\" header = f '# Task Summary \\n\\n Auto-Generated by ` { DG . meta . pkg_name } `' regex_compiled = DG . ct . compile_issue_regex () matches = _search_files ( DG . meta . paths , regex_compiled ) report = _format_report ( DG . meta . path_project , matches ) . strip () if report : path_tag_summary . write_text ( f ' { header } \\n\\n { report } \\n\\n <!-- { SKIP_PHRASE } --> \\n ' ) elif path_tag_summary . is_file (): path_tag_summary . unlink () @beartype def task_collect_code_tags () -> DoitTask : \"\"\"Create a summary file with all of the found code tags. Returns: DoitTask: doit task \"\"\" return debug_task ([( _write_code_tag_file , ( DG . ct . path_code_tag_summary ,))])","title":"calcipy.doit_tasks.code_tag_collector"},{"location":"docs/modules/calcipy/doit_tasks/code_tag_collector/#variables","text":"SKIP_PHRASE String that indicates the file should be excluded from the tag search.","title":"Variables"},{"location":"docs/modules/calcipy/doit_tasks/code_tag_collector/#functions","text":"","title":"Functions"},{"location":"docs/modules/calcipy/doit_tasks/code_tag_collector/#task_collect_code_tags","text":"def task_collect_code_tags () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Create a summary file with all of the found code tags. Returns: Type Description DoitTask doit task View Source @beartype def task_collect_code_tags () -> DoitTask : \"\"\"Create a summary file with all of the found code tags. Returns: DoitTask: doit task \"\"\" return debug_task ([( _write_code_tag_file , ( DG . ct . path_code_tag_summary ,))])","title":"task_collect_code_tags"},{"location":"docs/modules/calcipy/doit_tasks/doc/","text":"calcipy.doit_tasks.doc \u2693\ufe0e doit Documentation Utilities. View Source \"\"\"doit Documentation Utilities.\"\"\" import json import re import webbrowser from pathlib import Path from typing import Any , Callable , Dict , List , Optional , Pattern from beartype import beartype from doit.tools import Interactive from loguru import logger from transitions import Machine from ..file_helpers import _MKDOCS_CONFIG_NAME , _read_yaml_file , read_lines from .base import debug_task , open_in_browser from .doit_globals import DG , DoitTask # ---------------------------------------------------------------------------------------------------------------------- # Manage Changelog @beartype def _move_cl () -> None : \"\"\"Move the `CHANGELOG.md` file to the document directory. Raises: FileNotFoundError: if the changelog was not found \"\"\" path_cl = DG . meta . path_project / 'CHANGELOG.md' if not path_cl . is_file (): raise FileNotFoundError ( f 'Could not locate the changelog at: { path_cl } ' ) path_cl . replace ( DG . doc . doc_dir / path_cl . name ) @beartype def task_cl_write () -> DoitTask : \"\"\"Write a Changelog file with the raw Git history. Resources: - https://keepachangelog.com/en/1.0.0/ - https://www.conventionalcommits.org/en/v1.0.0/ - https://writingfordevelopers.substack.com/p/how-to-write-a-commit-message - https://chris.beams.io/posts/git-commit/ - https://semver.org/ - https://calver.org/ Returns: DoitTask: doit task \"\"\" return debug_task ([ 'poetry run cz changelog' , ( _move_cl , ()), ]) @beartype def task_cl_bump () -> DoitTask : \"\"\"Bumps project version based on commits & settings in pyproject.toml. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run cz bump --changelog --annotated-tag' ), ( _move_cl , ()), 'git push origin --tags --no-verify' , ]) @beartype def task_cl_bump_pre () -> DoitTask : \"\"\"Bump with specified pre-release tag. Example: `doit run cl_bump_pre -p alpha` or `doit run cl_bump_pre -p rc` Returns: DoitTask: doit task \"\"\" task = debug_task ([ Interactive ( 'poetry run cz bump --changelog --prerelease %(prerelease)s ' ), ( _move_cl , ()), 'git push origin --tags --no-verify' , ]) task [ 'params' ] = [{ 'name' : 'prerelease' , 'short' : 'p' , 'long' : 'prerelease' , 'default' : '' , 'help' : 'Specify prerelease version for bump (alpha, beta, rc)' , }] return task # ---------------------------------------------------------------------------------------------------------------------- # Manage README Updates class _ReplacementMachine ( Machine ): # type: ignore[misc] # noqa: H601 \"\"\"State machine to replace content with user-specified handlers. Uses `{cts}` and `{cte}` to demarcate sections (short for calcipy_template start|end) \"\"\" def __init__ ( self ) -> None : \"\"\"Initialize the state machine.\"\"\" self . state_user = 'user' self . state_auto = 'autoformatted' transitions = [ { 'trigger' : 'start_auto' , 'source' : self . state_user , 'dest' : self . state_auto , }, { 'trigger' : 'end' , 'source' : self . state_auto , 'dest' : self . state_user , }, ] super () . __init__ ( states = [ self . state_user , self . state_auto ], initial = self . state_user , transitions = transitions , ) def _parse_line ( self , line : str , handler_lookup : Dict [ str , Callable [[ str , Path ], str ]], path_file : Optional [ Path ] = None , ) -> List [ str ]: \"\"\"Parse lines and insert new_text based on provided handler_lookup. Args: line: single line handler_lookup: Lookup dictionary for autoformatted sections path_file: optional path to the file. Only useful for debugging Returns: List[str]: modified list of strings \"\"\" lines : List [ str ] = [] if ' {cte} ' in line and self . state == self . state_auto : # end self . end () elif ' {cts} ' in line : # start self . start_auto () matches = [ text_match for text_match in handler_lookup if text_match in line ] if len ( matches ) == 1 : lines . extend ( handler_lookup [ matches [ 0 ]]( line , path_file )) else : logger . error ( 'Could not parse: {line} ' , line = line ) lines . append ( line ) self . end () elif self . state == self . state_user : lines . append ( line ) # else: discard the lines in the auto-section return lines def parse ( self , lines : List [ str ], handler_lookup : Dict [ str , Callable [[ str , Path ], str ]], path_file : Optional [ Path ] = None , ) -> List [ str ]: \"\"\"Parse lines and insert new_text based on provided handler_lookup. Args: lines: list of string from source file handler_lookup: Lookup dictionary for autoformatted sections path_file: optional path to the file. Only useful for debugging Returns: List[str]: modified list of strings \"\"\" updated_lines = [] for line in lines : updated_lines . extend ( self . _parse_line ( line , handler_lookup , path_file )) return updated_lines _RE_VAR_COMMENT_HTML = re . compile ( r '<!-- {cts} (?P<key>[^=]+)=(?P<value>[^;]+);' ) \"\"\"Regex for extracting the vairable from an HTML code comment.\"\"\" @beartype def _parse_var_comment ( line : str , matcher : Pattern = _RE_VAR_COMMENT_HTML ) -> Dict [ str , str ]: \"\"\"Parse the variable from a matching comment. Args: line: string from source file matcher: regex pattern to match. Default is `_RE_VAR_COMMENT_HTML` Returns: Dict[str, str]: single key and value pair based on the parsed comment \"\"\" match = matcher . match ( line . strip ()) if match : matches = match . groupdict () return { matches [ 'key' ]: matches [ 'value' ]} return {} @beartype def _handle_source_file ( line : str , path_file : Path ) -> List [ str ]: \"\"\"Replace commented sections in README with linked file contents. Args: line: first line of the section path_file: path to the file that contained the string Returns: List[str]: list of auto-formatted text \"\"\" key , path_rel = [ * _parse_var_comment ( line ) . items ()][ 0 ] path_base = DG . meta . path_project if path_rel . startswith ( '/' ) else path_file . resolve () . parent path_source = path_base / path_rel . lstrip ( '/' ) language = path_source . suffix . lstrip ( '.' ) lines_source = [ f '``` { language } ' , * read_lines ( path_source ), '```' ] if not path_source . is_file (): logger . warning ( f 'Could not locate: { path_source } ' ) line_start = f '<!-- {{ cts }} { key } = { path_rel } ; -->' line_end = '<!-- {cte} -->' return [ line_start ] + lines_source + [ line_end ] @beartype def _format_cov_table ( coverage_data : Dict [ str , Any ]) -> List [ str ]: \"\"\"Format code coverage data table as markdown. Args: coverage_data: dictionary created by `python -m coverage json` Returns: List[str]: list of string lines to insert \"\"\" legend = [ 'File' , 'Statements' , 'Missing' , 'Excluded' , 'Coverage' ] int_keys = [ 'num_statements' , 'missing_lines' , 'excluded_lines' ] rows = [ legend , [ '--:' ] * len ( legend )] for path_file , file_obj in coverage_data [ 'files' ] . items (): rel_path = Path ( path_file ) . as_posix () # .resolve().relative_to(DG.meta.path_project) per = round ( file_obj [ 'summary' ][ 'percent_covered' ], 1 ) rows . append ([ f '` { rel_path } `' ] + [ file_obj [ 'summary' ][ key ] for key in int_keys ] + [ f ' { per } %' ]) # Format table for Github Markdown lines_table = [ f \"| { ' | ' . join ([ str ( value ) for value in row ]) } |\" for row in rows ] lines_table . extend ([ '' , f \"Generated on: { coverage_data [ 'meta' ][ 'timestamp' ] } \" ]) # TODO: Convert to Pandas for \".to_markdown\" # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_markdown.html # TODO: Add summary line for total coverage statistics return lines_table @beartype def _handle_coverage ( line : str , path_file : Path ) -> List [ str ]: \"\"\"Read the coverage.json file and write a Markdown table to the README file. Args: line: first line of the section path_file: path to the file that contained the string Returns: List[str]: list of auto-formatted text \"\"\" path_coverage = DG . meta . path_project / 'coverage.json' # Created by \"task_coverage\" lines_cov = [] if path_coverage . is_file (): coverage_data = json . loads ( path_coverage . read_text ()) lines_cov = _format_cov_table ( coverage_data ) else : logger . warning ( f 'Could not locate: { path_coverage } ' ) line_end = '<!-- {cte} -->' return [ line ] + lines_cov + [ line_end ] @beartype def write_autoformatted_md_sections () -> None : \"\"\"Populate the auto-formatted sections of markdown files with user-configured logic. Raises: RuntimeError: if `DG.doc.handler_lookup` hasn't ben configured. See `_ensure_handler_lookup` \"\"\" if DG . doc . handler_lookup is None : raise RuntimeError ( 'The \"DG.doc.handler_lookup\" dictionary has not been created' ) logger . info ( '> {paths_md} ' , paths_md = DG . doc . paths_md ) for path_md in DG . doc . paths_md : md_lines = _ReplacementMachine () . parse ( read_lines ( path_md ), DG . doc . handler_lookup , path_md ) path_md . write_text ( ' \\n ' . join ( md_lines )) # ---------------------------------------------------------------------------------------------------------------------- # Main Documentation Tasks @beartype def _ensure_handler_lookup () -> None : \"\"\"Configure the handler lookup if not already configured.\"\"\" if DG . doc . handler_lookup is None : DG . doc . handler_lookup = { 'COVERAGE ' : _handle_coverage , 'SOURCE_FILE=' : _handle_source_file , } @beartype def task_document () -> DoitTask : \"\"\"Build the HTML documentation. Returns: DoitTask: doit task \"\"\" _ensure_handler_lookup () pdoc_out = f '--output_dir { DG . doc . doc_dir } /modules --overwrite' pdoc_template = f '--template_dir { DG . calcipy_dir } /doit_tasks/templates' return debug_task ([ ( write_autoformatted_md_sections , ()), Interactive ( f 'poetry run pdocs as_markdown { DG . meta . pkg_name } { pdoc_out } { pdoc_template } ' ), Interactive ( f 'poetry run mkdocs build --site-dir { DG . doc . path_out } ' ), ]) def _is_mkdocs_local () -> bool : \"\"\"Check if mkdocs is configured for local output. See notes on local-link configuration here: https://github.com/timothycrosley/portray/issues/65 Additional information on using local search here: https://github.com/wilhelmer/mkdocs-localsearch Returns: bool: True if configured for local file output rather than hosted \"\"\" mkdocs_config = _read_yaml_file ( DG . meta . path_project / _MKDOCS_CONFIG_NAME ) return mkdocs_config . get ( 'use_directory_urls' ) is False @beartype def task_open_docs () -> DoitTask : \"\"\"Open the documentation files in the default browser. Returns: DoitTask: doit task \"\"\" if _is_mkdocs_local (): # pragma: no cover path_doc_index = DG . doc . path_out / DG . meta . pkg_name / 'index.html' return debug_task ([ ( open_in_browser , ( path_doc_index ,)), ]) return debug_task ([ ( webbrowser . open , ( 'http://localhost:8000' ,)), Interactive ( 'poetry run mkdocs serve --dirtyreload' ), ]) @beartype def task_deploy_docs () -> DoitTask : \"\"\"Deploy docs to the Github `gh-pages` branch. Returns: DoitTask: doit task \"\"\" if _is_mkdocs_local (): # pragma: no cover return debug_task ([ ( NotImplementedError , ( 'Deploy cannot be used with mkdocs built with local-links' ,)), ]) return debug_task ([ Interactive ( 'poetry run mkdocs gh-deploy' )]) Functions \u2693\ufe0e task_cl_bump \u2693\ufe0e def task_cl_bump () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Bumps project version based on commits & settings in pyproject.toml. Returns: Type Description DoitTask doit task View Source @beartype def task_cl_bump () -> DoitTask : \"\"\"Bumps project version based on commits & settings in pyproject.toml. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run cz bump --changelog --annotated-tag' ), ( _move_cl , ()), 'git push origin --tags --no-verify' , ]) task_cl_bump_pre \u2693\ufe0e def task_cl_bump_pre () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Bump with specified pre-release tag. Example: doit run cl_bump_pre -p alpha or doit run cl_bump_pre -p rc Returns: Type Description DoitTask doit task View Source @beartype def task_cl_bump_pre () -> DoitTask : \"\"\"Bump with specified pre-release tag. Example: `doit run cl_bump_pre -p alpha` or `doit run cl_bump_pre -p rc` Returns: DoitTask: doit task \"\"\" task = debug_task ([ Interactive ( 'poetry run cz bump --changelog --prerelease %(prerelease)s ' ), ( _move_cl , ()), 'git push origin --tags --no-verify' , ]) task [ 'params' ] = [{ 'name' : 'prerelease' , 'short' : 'p' , 'long' : 'prerelease' , 'default' : '' , 'help' : 'Specify prerelease version for bump (alpha, beta, rc)' , }] return task task_cl_write \u2693\ufe0e def task_cl_write () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Write a Changelog file with the raw Git history. Resources: https://keepachangelog.com/en/1.0.0/ https://www.conventionalcommits.org/en/v1.0.0/ https://writingfordevelopers.substack.com/p/how-to-write-a-commit-message https://chris.beams.io/posts/git-commit/ https://semver.org/ https://calver.org/ Returns: Type Description DoitTask doit task View Source @beartype def task_cl_write () -> DoitTask : \"\"\"Write a Changelog file with the raw Git history. Resources: - https://keepachangelog.com/en/1.0.0/ - https://www.conventionalcommits.org/en/v1.0.0/ - https://writingfordevelopers.substack.com/p/how-to-write-a-commit-message - https://chris.beams.io/posts/git-commit/ - https://semver.org/ - https://calver.org/ Returns: DoitTask: doit task \"\"\" return debug_task ([ 'poetry run cz changelog' , ( _move_cl , ()), ]) task_deploy_docs \u2693\ufe0e def task_deploy_docs () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Deploy docs to the Github gh-pages branch. Returns: Type Description DoitTask doit task View Source @beartype def task_deploy_docs () -> DoitTask : \"\"\"Deploy docs to the Github `gh-pages` branch. Returns: DoitTask: doit task \"\"\" if _is_mkdocs_local (): # pragma: no cover return debug_task ([ ( NotImplementedError , ( 'Deploy cannot be used with mkdocs built with local-links' ,)), ]) return debug_task ([ Interactive ( 'poetry run mkdocs gh-deploy' )]) task_document \u2693\ufe0e def task_document () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Build the HTML documentation. Returns: Type Description DoitTask doit task View Source @beartype def task_document () -> DoitTask : \"\"\"Build the HTML documentation. Returns: DoitTask: doit task \"\"\" _ensure_handler_lookup () pdoc_out = f '--output_dir { DG . doc . doc_dir } /modules --overwrite' pdoc_template = f '--template_dir { DG . calcipy_dir } /doit_tasks/templates' return debug_task ([ ( write_autoformatted_md_sections , ()), Interactive ( f 'poetry run pdocs as_markdown { DG . meta . pkg_name } { pdoc_out } { pdoc_template } ' ), Interactive ( f 'poetry run mkdocs build --site-dir { DG . doc . path_out } ' ), ]) task_open_docs \u2693\ufe0e def task_open_docs () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Open the documentation files in the default browser. Returns: Type Description DoitTask doit task View Source @beartype def task_open_docs () -> DoitTask : \"\"\"Open the documentation files in the default browser. Returns: DoitTask: doit task \"\"\" if _is_mkdocs_local (): # pragma: no cover path_doc_index = DG . doc . path_out / DG . meta . pkg_name / 'index.html' return debug_task ([ ( open_in_browser , ( path_doc_index ,)), ]) return debug_task ([ ( webbrowser . open , ( 'http://localhost:8000' ,)), Interactive ( 'poetry run mkdocs serve --dirtyreload' ), ]) write_autoformatted_md_sections \u2693\ufe0e def write_autoformatted_md_sections () -> None Populate the auto-formatted sections of markdown files with user-configured logic. Raises: Type Description RuntimeError if DG.doc.handler_lookup hasn\u2019t ben configured. See _ensure_handler_lookup View Source @beartype def write_autoformatted_md_sections () -> None : \"\"\"Populate the auto-formatted sections of markdown files with user-configured logic. Raises: RuntimeError: if `DG.doc.handler_lookup` hasn't ben configured. See `_ensure_handler_lookup` \"\"\" if DG . doc . handler_lookup is None : raise RuntimeError ( 'The \"DG.doc.handler_lookup\" dictionary has not been created' ) logger . info ( '> {paths_md} ' , paths_md = DG . doc . paths_md ) for path_md in DG . doc . paths_md : md_lines = _ReplacementMachine () . parse ( read_lines ( path_md ), DG . doc . handler_lookup , path_md ) path_md . write_text ( ' \\n ' . join ( md_lines ))","title":"calcipy.doit_tasks.doc"},{"location":"docs/modules/calcipy/doit_tasks/doc/#calcipydoit_tasksdoc","text":"doit Documentation Utilities. View Source \"\"\"doit Documentation Utilities.\"\"\" import json import re import webbrowser from pathlib import Path from typing import Any , Callable , Dict , List , Optional , Pattern from beartype import beartype from doit.tools import Interactive from loguru import logger from transitions import Machine from ..file_helpers import _MKDOCS_CONFIG_NAME , _read_yaml_file , read_lines from .base import debug_task , open_in_browser from .doit_globals import DG , DoitTask # ---------------------------------------------------------------------------------------------------------------------- # Manage Changelog @beartype def _move_cl () -> None : \"\"\"Move the `CHANGELOG.md` file to the document directory. Raises: FileNotFoundError: if the changelog was not found \"\"\" path_cl = DG . meta . path_project / 'CHANGELOG.md' if not path_cl . is_file (): raise FileNotFoundError ( f 'Could not locate the changelog at: { path_cl } ' ) path_cl . replace ( DG . doc . doc_dir / path_cl . name ) @beartype def task_cl_write () -> DoitTask : \"\"\"Write a Changelog file with the raw Git history. Resources: - https://keepachangelog.com/en/1.0.0/ - https://www.conventionalcommits.org/en/v1.0.0/ - https://writingfordevelopers.substack.com/p/how-to-write-a-commit-message - https://chris.beams.io/posts/git-commit/ - https://semver.org/ - https://calver.org/ Returns: DoitTask: doit task \"\"\" return debug_task ([ 'poetry run cz changelog' , ( _move_cl , ()), ]) @beartype def task_cl_bump () -> DoitTask : \"\"\"Bumps project version based on commits & settings in pyproject.toml. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run cz bump --changelog --annotated-tag' ), ( _move_cl , ()), 'git push origin --tags --no-verify' , ]) @beartype def task_cl_bump_pre () -> DoitTask : \"\"\"Bump with specified pre-release tag. Example: `doit run cl_bump_pre -p alpha` or `doit run cl_bump_pre -p rc` Returns: DoitTask: doit task \"\"\" task = debug_task ([ Interactive ( 'poetry run cz bump --changelog --prerelease %(prerelease)s ' ), ( _move_cl , ()), 'git push origin --tags --no-verify' , ]) task [ 'params' ] = [{ 'name' : 'prerelease' , 'short' : 'p' , 'long' : 'prerelease' , 'default' : '' , 'help' : 'Specify prerelease version for bump (alpha, beta, rc)' , }] return task # ---------------------------------------------------------------------------------------------------------------------- # Manage README Updates class _ReplacementMachine ( Machine ): # type: ignore[misc] # noqa: H601 \"\"\"State machine to replace content with user-specified handlers. Uses `{cts}` and `{cte}` to demarcate sections (short for calcipy_template start|end) \"\"\" def __init__ ( self ) -> None : \"\"\"Initialize the state machine.\"\"\" self . state_user = 'user' self . state_auto = 'autoformatted' transitions = [ { 'trigger' : 'start_auto' , 'source' : self . state_user , 'dest' : self . state_auto , }, { 'trigger' : 'end' , 'source' : self . state_auto , 'dest' : self . state_user , }, ] super () . __init__ ( states = [ self . state_user , self . state_auto ], initial = self . state_user , transitions = transitions , ) def _parse_line ( self , line : str , handler_lookup : Dict [ str , Callable [[ str , Path ], str ]], path_file : Optional [ Path ] = None , ) -> List [ str ]: \"\"\"Parse lines and insert new_text based on provided handler_lookup. Args: line: single line handler_lookup: Lookup dictionary for autoformatted sections path_file: optional path to the file. Only useful for debugging Returns: List[str]: modified list of strings \"\"\" lines : List [ str ] = [] if ' {cte} ' in line and self . state == self . state_auto : # end self . end () elif ' {cts} ' in line : # start self . start_auto () matches = [ text_match for text_match in handler_lookup if text_match in line ] if len ( matches ) == 1 : lines . extend ( handler_lookup [ matches [ 0 ]]( line , path_file )) else : logger . error ( 'Could not parse: {line} ' , line = line ) lines . append ( line ) self . end () elif self . state == self . state_user : lines . append ( line ) # else: discard the lines in the auto-section return lines def parse ( self , lines : List [ str ], handler_lookup : Dict [ str , Callable [[ str , Path ], str ]], path_file : Optional [ Path ] = None , ) -> List [ str ]: \"\"\"Parse lines and insert new_text based on provided handler_lookup. Args: lines: list of string from source file handler_lookup: Lookup dictionary for autoformatted sections path_file: optional path to the file. Only useful for debugging Returns: List[str]: modified list of strings \"\"\" updated_lines = [] for line in lines : updated_lines . extend ( self . _parse_line ( line , handler_lookup , path_file )) return updated_lines _RE_VAR_COMMENT_HTML = re . compile ( r '<!-- {cts} (?P<key>[^=]+)=(?P<value>[^;]+);' ) \"\"\"Regex for extracting the vairable from an HTML code comment.\"\"\" @beartype def _parse_var_comment ( line : str , matcher : Pattern = _RE_VAR_COMMENT_HTML ) -> Dict [ str , str ]: \"\"\"Parse the variable from a matching comment. Args: line: string from source file matcher: regex pattern to match. Default is `_RE_VAR_COMMENT_HTML` Returns: Dict[str, str]: single key and value pair based on the parsed comment \"\"\" match = matcher . match ( line . strip ()) if match : matches = match . groupdict () return { matches [ 'key' ]: matches [ 'value' ]} return {} @beartype def _handle_source_file ( line : str , path_file : Path ) -> List [ str ]: \"\"\"Replace commented sections in README with linked file contents. Args: line: first line of the section path_file: path to the file that contained the string Returns: List[str]: list of auto-formatted text \"\"\" key , path_rel = [ * _parse_var_comment ( line ) . items ()][ 0 ] path_base = DG . meta . path_project if path_rel . startswith ( '/' ) else path_file . resolve () . parent path_source = path_base / path_rel . lstrip ( '/' ) language = path_source . suffix . lstrip ( '.' ) lines_source = [ f '``` { language } ' , * read_lines ( path_source ), '```' ] if not path_source . is_file (): logger . warning ( f 'Could not locate: { path_source } ' ) line_start = f '<!-- {{ cts }} { key } = { path_rel } ; -->' line_end = '<!-- {cte} -->' return [ line_start ] + lines_source + [ line_end ] @beartype def _format_cov_table ( coverage_data : Dict [ str , Any ]) -> List [ str ]: \"\"\"Format code coverage data table as markdown. Args: coverage_data: dictionary created by `python -m coverage json` Returns: List[str]: list of string lines to insert \"\"\" legend = [ 'File' , 'Statements' , 'Missing' , 'Excluded' , 'Coverage' ] int_keys = [ 'num_statements' , 'missing_lines' , 'excluded_lines' ] rows = [ legend , [ '--:' ] * len ( legend )] for path_file , file_obj in coverage_data [ 'files' ] . items (): rel_path = Path ( path_file ) . as_posix () # .resolve().relative_to(DG.meta.path_project) per = round ( file_obj [ 'summary' ][ 'percent_covered' ], 1 ) rows . append ([ f '` { rel_path } `' ] + [ file_obj [ 'summary' ][ key ] for key in int_keys ] + [ f ' { per } %' ]) # Format table for Github Markdown lines_table = [ f \"| { ' | ' . join ([ str ( value ) for value in row ]) } |\" for row in rows ] lines_table . extend ([ '' , f \"Generated on: { coverage_data [ 'meta' ][ 'timestamp' ] } \" ]) # TODO: Convert to Pandas for \".to_markdown\" # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_markdown.html # TODO: Add summary line for total coverage statistics return lines_table @beartype def _handle_coverage ( line : str , path_file : Path ) -> List [ str ]: \"\"\"Read the coverage.json file and write a Markdown table to the README file. Args: line: first line of the section path_file: path to the file that contained the string Returns: List[str]: list of auto-formatted text \"\"\" path_coverage = DG . meta . path_project / 'coverage.json' # Created by \"task_coverage\" lines_cov = [] if path_coverage . is_file (): coverage_data = json . loads ( path_coverage . read_text ()) lines_cov = _format_cov_table ( coverage_data ) else : logger . warning ( f 'Could not locate: { path_coverage } ' ) line_end = '<!-- {cte} -->' return [ line ] + lines_cov + [ line_end ] @beartype def write_autoformatted_md_sections () -> None : \"\"\"Populate the auto-formatted sections of markdown files with user-configured logic. Raises: RuntimeError: if `DG.doc.handler_lookup` hasn't ben configured. See `_ensure_handler_lookup` \"\"\" if DG . doc . handler_lookup is None : raise RuntimeError ( 'The \"DG.doc.handler_lookup\" dictionary has not been created' ) logger . info ( '> {paths_md} ' , paths_md = DG . doc . paths_md ) for path_md in DG . doc . paths_md : md_lines = _ReplacementMachine () . parse ( read_lines ( path_md ), DG . doc . handler_lookup , path_md ) path_md . write_text ( ' \\n ' . join ( md_lines )) # ---------------------------------------------------------------------------------------------------------------------- # Main Documentation Tasks @beartype def _ensure_handler_lookup () -> None : \"\"\"Configure the handler lookup if not already configured.\"\"\" if DG . doc . handler_lookup is None : DG . doc . handler_lookup = { 'COVERAGE ' : _handle_coverage , 'SOURCE_FILE=' : _handle_source_file , } @beartype def task_document () -> DoitTask : \"\"\"Build the HTML documentation. Returns: DoitTask: doit task \"\"\" _ensure_handler_lookup () pdoc_out = f '--output_dir { DG . doc . doc_dir } /modules --overwrite' pdoc_template = f '--template_dir { DG . calcipy_dir } /doit_tasks/templates' return debug_task ([ ( write_autoformatted_md_sections , ()), Interactive ( f 'poetry run pdocs as_markdown { DG . meta . pkg_name } { pdoc_out } { pdoc_template } ' ), Interactive ( f 'poetry run mkdocs build --site-dir { DG . doc . path_out } ' ), ]) def _is_mkdocs_local () -> bool : \"\"\"Check if mkdocs is configured for local output. See notes on local-link configuration here: https://github.com/timothycrosley/portray/issues/65 Additional information on using local search here: https://github.com/wilhelmer/mkdocs-localsearch Returns: bool: True if configured for local file output rather than hosted \"\"\" mkdocs_config = _read_yaml_file ( DG . meta . path_project / _MKDOCS_CONFIG_NAME ) return mkdocs_config . get ( 'use_directory_urls' ) is False @beartype def task_open_docs () -> DoitTask : \"\"\"Open the documentation files in the default browser. Returns: DoitTask: doit task \"\"\" if _is_mkdocs_local (): # pragma: no cover path_doc_index = DG . doc . path_out / DG . meta . pkg_name / 'index.html' return debug_task ([ ( open_in_browser , ( path_doc_index ,)), ]) return debug_task ([ ( webbrowser . open , ( 'http://localhost:8000' ,)), Interactive ( 'poetry run mkdocs serve --dirtyreload' ), ]) @beartype def task_deploy_docs () -> DoitTask : \"\"\"Deploy docs to the Github `gh-pages` branch. Returns: DoitTask: doit task \"\"\" if _is_mkdocs_local (): # pragma: no cover return debug_task ([ ( NotImplementedError , ( 'Deploy cannot be used with mkdocs built with local-links' ,)), ]) return debug_task ([ Interactive ( 'poetry run mkdocs gh-deploy' )])","title":"calcipy.doit_tasks.doc"},{"location":"docs/modules/calcipy/doit_tasks/doc/#functions","text":"","title":"Functions"},{"location":"docs/modules/calcipy/doit_tasks/doc/#task_cl_bump","text":"def task_cl_bump () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Bumps project version based on commits & settings in pyproject.toml. Returns: Type Description DoitTask doit task View Source @beartype def task_cl_bump () -> DoitTask : \"\"\"Bumps project version based on commits & settings in pyproject.toml. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run cz bump --changelog --annotated-tag' ), ( _move_cl , ()), 'git push origin --tags --no-verify' , ])","title":"task_cl_bump"},{"location":"docs/modules/calcipy/doit_tasks/doc/#task_cl_bump_pre","text":"def task_cl_bump_pre () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Bump with specified pre-release tag. Example: doit run cl_bump_pre -p alpha or doit run cl_bump_pre -p rc Returns: Type Description DoitTask doit task View Source @beartype def task_cl_bump_pre () -> DoitTask : \"\"\"Bump with specified pre-release tag. Example: `doit run cl_bump_pre -p alpha` or `doit run cl_bump_pre -p rc` Returns: DoitTask: doit task \"\"\" task = debug_task ([ Interactive ( 'poetry run cz bump --changelog --prerelease %(prerelease)s ' ), ( _move_cl , ()), 'git push origin --tags --no-verify' , ]) task [ 'params' ] = [{ 'name' : 'prerelease' , 'short' : 'p' , 'long' : 'prerelease' , 'default' : '' , 'help' : 'Specify prerelease version for bump (alpha, beta, rc)' , }] return task","title":"task_cl_bump_pre"},{"location":"docs/modules/calcipy/doit_tasks/doc/#task_cl_write","text":"def task_cl_write () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Write a Changelog file with the raw Git history. Resources: https://keepachangelog.com/en/1.0.0/ https://www.conventionalcommits.org/en/v1.0.0/ https://writingfordevelopers.substack.com/p/how-to-write-a-commit-message https://chris.beams.io/posts/git-commit/ https://semver.org/ https://calver.org/ Returns: Type Description DoitTask doit task View Source @beartype def task_cl_write () -> DoitTask : \"\"\"Write a Changelog file with the raw Git history. Resources: - https://keepachangelog.com/en/1.0.0/ - https://www.conventionalcommits.org/en/v1.0.0/ - https://writingfordevelopers.substack.com/p/how-to-write-a-commit-message - https://chris.beams.io/posts/git-commit/ - https://semver.org/ - https://calver.org/ Returns: DoitTask: doit task \"\"\" return debug_task ([ 'poetry run cz changelog' , ( _move_cl , ()), ])","title":"task_cl_write"},{"location":"docs/modules/calcipy/doit_tasks/doc/#task_deploy_docs","text":"def task_deploy_docs () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Deploy docs to the Github gh-pages branch. Returns: Type Description DoitTask doit task View Source @beartype def task_deploy_docs () -> DoitTask : \"\"\"Deploy docs to the Github `gh-pages` branch. Returns: DoitTask: doit task \"\"\" if _is_mkdocs_local (): # pragma: no cover return debug_task ([ ( NotImplementedError , ( 'Deploy cannot be used with mkdocs built with local-links' ,)), ]) return debug_task ([ Interactive ( 'poetry run mkdocs gh-deploy' )])","title":"task_deploy_docs"},{"location":"docs/modules/calcipy/doit_tasks/doc/#task_document","text":"def task_document () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Build the HTML documentation. Returns: Type Description DoitTask doit task View Source @beartype def task_document () -> DoitTask : \"\"\"Build the HTML documentation. Returns: DoitTask: doit task \"\"\" _ensure_handler_lookup () pdoc_out = f '--output_dir { DG . doc . doc_dir } /modules --overwrite' pdoc_template = f '--template_dir { DG . calcipy_dir } /doit_tasks/templates' return debug_task ([ ( write_autoformatted_md_sections , ()), Interactive ( f 'poetry run pdocs as_markdown { DG . meta . pkg_name } { pdoc_out } { pdoc_template } ' ), Interactive ( f 'poetry run mkdocs build --site-dir { DG . doc . path_out } ' ), ])","title":"task_document"},{"location":"docs/modules/calcipy/doit_tasks/doc/#task_open_docs","text":"def task_open_docs () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Open the documentation files in the default browser. Returns: Type Description DoitTask doit task View Source @beartype def task_open_docs () -> DoitTask : \"\"\"Open the documentation files in the default browser. Returns: DoitTask: doit task \"\"\" if _is_mkdocs_local (): # pragma: no cover path_doc_index = DG . doc . path_out / DG . meta . pkg_name / 'index.html' return debug_task ([ ( open_in_browser , ( path_doc_index ,)), ]) return debug_task ([ ( webbrowser . open , ( 'http://localhost:8000' ,)), Interactive ( 'poetry run mkdocs serve --dirtyreload' ), ])","title":"task_open_docs"},{"location":"docs/modules/calcipy/doit_tasks/doc/#write_autoformatted_md_sections","text":"def write_autoformatted_md_sections () -> None Populate the auto-formatted sections of markdown files with user-configured logic. Raises: Type Description RuntimeError if DG.doc.handler_lookup hasn\u2019t ben configured. See _ensure_handler_lookup View Source @beartype def write_autoformatted_md_sections () -> None : \"\"\"Populate the auto-formatted sections of markdown files with user-configured logic. Raises: RuntimeError: if `DG.doc.handler_lookup` hasn't ben configured. See `_ensure_handler_lookup` \"\"\" if DG . doc . handler_lookup is None : raise RuntimeError ( 'The \"DG.doc.handler_lookup\" dictionary has not been created' ) logger . info ( '> {paths_md} ' , paths_md = DG . doc . paths_md ) for path_md in DG . doc . paths_md : md_lines = _ReplacementMachine () . parse ( read_lines ( path_md ), DG . doc . handler_lookup , path_md ) path_md . write_text ( ' \\n ' . join ( md_lines ))","title":"write_autoformatted_md_sections"},{"location":"docs/modules/calcipy/doit_tasks/doit_globals/","text":"calcipy.doit_tasks.doit_globals \u2693\ufe0e Global Variables for doit. View Source \"\"\"Global Variables for doit.\"\"\" import inspect import re import warnings from functools import partial from pathlib import Path from typing import Any , Callable , Dict , Iterable , List , Optional , Pattern , Set , Tuple , Union import attr import doit import toml from beartype import beartype from doit.action import BaseAction from doit.task import Task from loguru import logger from ..file_helpers import _MKDOCS_CONFIG_NAME , _read_yaml_file , get_doc_dir from ..log_helpers import log_fun from .file_search import find_project_files , find_project_files_by_suffix _DOIT_TASK_IMPORT_ERROR = 'User must install the optional calcipy extra \"dev\" to utilize \"doit_tasks\"' \"\"\"Standard error message when an optional import is not available. Raise with RuntimeError.\"\"\" _DoitCallableArgs = Iterable [ Union [ str , float , int , Path , Dict [ str , Any ]]] \"\"\"Type: legal types that can be passed to a Python callable for doit actions.\"\"\" DoitAction = Union [ str , BaseAction , Tuple [ Callable , _DoitCallableArgs ]] # type: ignore[type-arg] \"\"\"Type: individual doit action.\"\"\" DoitTask = Union [ Task , Dict [ str , DoitAction ]] \"\"\"Type: full doit task.\"\"\" @beartype def _make_full_path ( raw : Union [ Path , str ], path_base : Path ) -> Path : \"\"\"Return a full path by determining if the source path is an absolute path. If not combines with base path. Args: raw: (string or Path) relative or absolute path path_base: base directory to use if the raw path is not absolute Returns: Path: absolute path \"\"\" return Path ( raw ) if Path ( raw ) . is_absolute () else path_base / raw @beartype def _member_filter ( member : Any , instance_type : Any ) -> bool : \"\"\"Return True if the member matches the filters. Args: member: class data- or method-member instance_type: optional instance type Returns: bool: True if the member matches the applied filter \"\"\" return ( instance_type is None or isinstance ( member , instance_type )) @attr . s ( auto_attribs = True , kw_only = True ) class _PathAttrBase : # noqa: H601 path_project : Path \"\"\"Path to the package directory.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Initialize full paths with the package base directory if necessary. Raises: RuntimeError: if any paths are None \"\"\" if self . path_project is None : raise RuntimeError ( 'Missing keyword argument \"path_project\"' ) # pragma: no cover self . _resolve_class_paths ( self . path_project ) self . _verify_initialized_paths () def _get_members ( self , prefix : Optional [ str ], ** kwargs : Any ) -> List [ Tuple [ str , Callable [[ Any ], Any ]]]: \"\"\"Return the members that match the parameters. Example to return all methods that start with `do_`: `self._get_members(instance_type=Callable, prefix='do_')` Args: prefix: optional string prefix to check starts with kwargs: keyword arguments passed to `_member_filter` Returns: List[Tuple[str, Callable]]: filtered members from the class \"\"\" members = inspect . getmembers ( self , predicate = partial ( _member_filter , ** kwargs )) if prefix : members = [( name , member ) for ( name , member ) in members if name . startswith ( prefix )] return members # noqa: R504 def _resolve_class_paths ( self , base_path : Path ) -> None : \"\"\"Resolve all partial paths with the specified base path. WARN: will mutate the class attribute Args: base_path: base path to apply to all found relative paths \"\"\" for name , path_raw in self . _get_members ( instance_type = type ( Path ()), prefix = None ): if not path_raw . is_absolute (): # type: ignore[attr-defined] setattr ( self , name , base_path / path_raw ) # type: ignore[operator] logger . debug ( f 'Mutated: self. { name } = { path_raw } (now: { getattr ( self , name ) } )' ) def _verify_initialized_paths ( self ) -> None : \"\"\"Verify that all paths are not None. WARN: will not raise on error the class attribute Raises: RuntimeError: if any paths are None \"\"\" missing = [ name for name , _m in self . _get_members ( instance_type = type ( None ), prefix = 'path_' )] if missing : kwargs = ', ' . join ( missing ) raise RuntimeError ( f 'Missing keyword arguments for: { kwargs } ' ) @attr . s ( auto_attribs = True , kw_only = True ) class PackageMeta ( _PathAttrBase ): # noqa: H601 \"\"\"Package Meta-Information.\"\"\" path_toml : Path = Path ( 'pyproject.toml' ) \"\"\"Relative path to the poetry toml file.\"\"\" ignore_patterns : List [ str ] = [] \"\"\"List of glob patterns to ignore from all analysis.\"\"\" paths : List [ Path ] = attr . ib ( init = False ) \"\"\"Paths to all tracked files that were not ignored with specified patterns `find_project_files`.\"\"\" paths_by_suffix : Dict [ str , List [ Path ]] = attr . ib ( init = False ) \"\"\"Paths to all tracked files that were not ignored with specified patterns `find_project_files_by_suffix`.\"\"\" pkg_name : str = attr . ib ( init = False ) \"\"\"Package string name.\"\"\" pkg_version : str = attr . ib ( init = False ) \"\"\"Package version.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Finish initializing class attributes. Raises: RuntimeError: if the toml package is not available FileNotFoundError: if the toml could not be located \"\"\" super () . __attrs_post_init__ () # Note: toml is an optional dependency required only when using the `doit_tasks` in development if toml is None : # pragma: no cover raise RuntimeError ( _DOIT_TASK_IMPORT_ERROR ) try : poetry_config = toml . load ( self . path_toml )[ 'tool' ][ 'poetry' ] except FileNotFoundError : # pragma: no cover raise FileNotFoundError ( f 'Check that \" { self . path_project } \" is correct. Could not find: { self . path_toml } ' ) self . pkg_name = poetry_config [ 'name' ] self . pkg_version = poetry_config [ 'version' ] if '-' in self . pkg_name : # pragma: no cover warnings . warn ( f 'Replace dashes in name with underscores ( { self . pkg_name } ) in { self . path_toml } ' ) self . paths = find_project_files ( self . path_project , self . ignore_patterns ) self . paths_by_suffix = find_project_files_by_suffix ( self . path_project , self . ignore_patterns ) def __shorted_path_list ( self ) -> Set [ str ]: # pragma: no cover \"\"\"Shorten the list of directories common to the specified paths. > Not currently needed, but could be useful Returns: Set[str]: set of most common top-level directories relative to the project dir \"\"\" return { pth . parent . relative_to ( self . path_project ) . as_posix () for pth in self . paths } # type: ignore[attr-defined] @attr . s ( auto_attribs = True , kw_only = True ) class LintConfig ( _PathAttrBase ): # noqa: H601 \"\"\"Lint Config.\"\"\" path_flake8 : Union [ Path , str ] = Path ( '.flake8' ) \"\"\"Relative path to the flake8 configuration file. Default is \".flake8\" created by calcipy_template.\"\"\" path_isort : Union [ Path , str ] = Path ( 'pyproject.toml' ) \"\"\"Relative path to the isort configuration file. Default is \"pyproject.toml\" created by calcipy_template.\"\"\" ignore_errors : List [ str ] = [ 'AAA01' , # AAA01 / act block in pytest 'C901' , # C901 / complexity from \"max-complexity = 10\" 'D417' , # D417 / missing arg descriptors 'DAR101' , 'DAR201' , 'DAR401' , # https://pypi.org/project/darglint/ (Scroll to error codes) 'DUO106' , # DUO106 / insecure use of os 'E800' , # E800 / Commented out code 'G001' , # G001 / logging format for un-indexed parameters 'H601' , # H601 / class with low cohesion 'P101' , 'P103' , # P101,P103 / format string 'PD013' , 'S101' , # S101 / assert 'S605' , 'S607' , # S605,S607 / os.popen(...) 'T100' , 'T101' , 'T103' , # T100,T101,T103 / fixme and todo comments ] \"\"\"List of additional excluded flake8 rules for the pre-commit check.\"\"\" paths_py : List [ Path ] = attr . ib ( init = False ) \"\"\"Paths to the Python files used when linting. Created with `find_project_files_by_suffix`.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Finish initializing class attributes.\"\"\" super () . __attrs_post_init__ () self . path_flake8 = _make_full_path ( self . path_flake8 , self . path_project ) self . path_isort = _make_full_path ( self . path_isort , self . path_project ) self . paths_py = DG . meta . paths_by_suffix . get ( 'py' , []) @attr . s ( auto_attribs = True , kw_only = True ) class TestingConfig ( _PathAttrBase ): # noqa: H601 \"\"\"Test Config.\"\"\" pythons : List [ str ] = [ '3.8' , '3.9' ] \"\"\"Python versions to test against. Default is `['3.8', '3.9']`.\"\"\" path_out : Union [ Path , str ] = Path ( 'releases/tests' ) \"\"\"Relative path to the report output directory. Default is `releases/tests`.\"\"\" path_tests : Union [ Path , str ] = Path ( 'tests' ) \"\"\"Relative path to the tests directory. Default is `tests`.\"\"\" args_pytest : str = '--exitfirst --showlocals --failed-first --new-first --verbose --doctest-modules' \"\"\"Default arguments to Pytest. In short form, the defaults are `-x -l --ff --nf -vv`.\"\"\" args_diff : str = '--fail-under=65 --compare-branch=origin/main' \"\"\"Default arguments to diff-cover.\"\"\" path_test_report : Path = attr . ib ( init = False ) \"\"\"Path to the self-contained test HTML report.\"\"\" path_diff_test_report : Path = attr . ib ( init = False ) \"\"\"Path to the self-contained diff-test HTML report.\"\"\" path_diff_lint_report : Path = attr . ib ( init = False ) \"\"\"Path to the self-contained diff-lint HTML report.\"\"\" path_coverage_index : Path = attr . ib ( init = False ) \"\"\"Path to the coverage HTML index file within the report directory.\"\"\" path_mypy_index : Path = attr . ib ( init = False ) \"\"\"Path to the mypy HTML index file within the report directory.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Finish initializing class attributes.\"\"\" super () . __attrs_post_init__ () self . path_out = _make_full_path ( self . path_out , self . path_project ) self . path_tests = _make_full_path ( self . path_tests , self . path_project ) self . path_out . mkdir ( exist_ok = True , parents = True ) # Configure the paths to the report HTML and coverage HTML files self . path_test_report = self . path_out / 'test_report.html' self . path_diff_test_report = self . path_out / 'diff_test_report.html' self . path_diff_lint_report = self . path_out / 'diff_lint_report.html' self . path_coverage_index = self . path_out / 'cov_html/index.html' self . path_mypy_index = self . path_out / 'mypy_html/index.html' @attr . s ( auto_attribs = True , kw_only = True ) class CodeTagConfig ( _PathAttrBase ): # noqa: H601 \"\"\"Code Tag Config.\"\"\" doc_dir : Path = Path ( 'docs/docs' ) \"\"\"Relative path to the source documentation directory.\"\"\" code_tag_summary_filename : str = 'CODE_TAG_SUMMARY.md' \"\"\"Name of the code tag summary file.\"\"\" tags : List [ str ] = [ 'FIXME' , 'TODO' , 'PLANNED' , 'HACK' , 'REVIEW' , 'TBD' , 'DEBUG' , 'FYI' , 'NOTE' , # noqa: T100,T101,T103 ] \"\"\"List of ordered tag names to match.\"\"\" re_raw : str = r '((\\s|\\()(?P<tag> {tag} )(:[^\\r\\n]))(?P<text>.+)' \"\"\"string regular expression that contains `{tag}`.\"\"\" path_code_tag_summary : Path = attr . ib ( init = False ) \"\"\"Path to the code tag summary file. Uses `code_tag_summary_filename`.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Finish initializing class attributes.\"\"\" super () . __attrs_post_init__ () # Configure full path to the code tag summary file self . path_code_tag_summary = self . path_project / self . doc_dir / self . code_tag_summary_filename def compile_issue_regex ( self ) -> Pattern [ str ]: \"\"\"Compile the regex for the specified raw regular expression string and tags. Returns: Pattern[str]: compiled regular expression to match all of the specified tags \"\"\" return re . compile ( self . re_raw . format ( tag = '|' . join ( self . tags ))) @attr . s ( auto_attribs = True , kw_only = True ) class DocConfig ( _PathAttrBase ): # noqa: H601 \"\"\"Documentation Config.\"\"\" doc_dir : Path = Path ( 'docs/docs' ) \"\"\"Relative path to the source documentation directory.\"\"\" handler_lookup : Optional [ Dict [ str , Callable [[ str , Path ], str ]]] = None \"\"\"Lookup dictionary for autoformatted sections of the project's markdown files.\"\"\" path_out : Path = attr . ib ( init = False ) \"\"\"The documentation output directory. Specified in `mkdocs.yml`.\"\"\" paths_md : List [ Path ] = attr . ib ( init = False ) \"\"\"Paths to Markdown files used when documenting. Created with `find_project_files_by_suffix`.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Finish initializing class attributes.\"\"\" super () . __attrs_post_init__ () mkdocs_config = _read_yaml_file ( self . path_project / _MKDOCS_CONFIG_NAME ) self . path_out = mkdocs_config . get ( 'site_dir' , 'releases/site' ) self . path_out = _make_full_path ( self . path_out , self . path_project ) self . path_out . mkdir ( exist_ok = True , parents = True ) self . paths_md = DG . meta . paths_by_suffix . get ( 'md' , []) @attr . s ( auto_attribs = True , kw_only = True ) class DoitGlobals : \"\"\"Global Variables for doit.\"\"\" calcipy_dir : Path = attr . ib ( init = False , default = Path ( __file__ ) . resolve () . parents [ 1 ]) \"\"\"The calcipy directory (likely within `.venv`).\"\"\" meta : PackageMeta = attr . ib ( init = False ) \"\"\"Package Meta-Information.\"\"\" lint : LintConfig = attr . ib ( init = False ) \"\"\"Lint Config.\"\"\" test : TestingConfig = attr . ib ( init = False ) \"\"\"Test Config.\"\"\" ct : CodeTagConfig = attr . ib ( init = False ) \"\"\"Documentation Config.\"\"\" doc : DocConfig = attr . ib ( init = False ) \"\"\"Documentation Config.\"\"\" @log_fun def set_paths ( self , * , path_project : Optional [ Path ] = None , ) -> None : \"\"\"Set data members based on working directory. Args: path_project: optional project base directory Path. Defaults to the current working directory Raises: RuntimeError: if problems in formatting of the toml file \"\"\" logger . info ( f 'Setting DG path: { path_project } ' , path_project = path_project , cwd = Path . cwd ()) path_project = path_project or Path . cwd () # Read the optional toml configuration # > Note: could allow LintConfig/.../DocConfig kwargs to be set in toml, but may be difficult to maintain path_toml = path_project / 'pyproject.toml' calcipy_config = toml . load ( path_toml ) . get ( 'tool' , {}) . get ( 'calcipy' , {}) ignore_patterns = calcipy_config . get ( 'ignore_patterns' , []) self . meta = PackageMeta ( path_project = path_project , ignore_patterns = ignore_patterns ) meta_kwargs = { 'path_project' : self . meta . path_project } # Parse the Copier file for configuration information doc_dir = get_doc_dir ( self . meta . path_project ) / 'docs' # Note: subdirectory is important doc_dir . mkdir ( exist_ok = True , parents = True ) # Configure global options section_keys = [ 'lint' , 'test' , 'code_tag' , 'doc' ] supported_keys = section_keys + [ 'ignore_patterns' ] unexpected_keys = [ key for key in calcipy_config if key not in supported_keys ] if unexpected_keys : raise RuntimeError ( f 'Found unexpected key(s) { unexpected_keys } (i.e. not in { supported_keys } )' ) lint_k , test_k , code_k , doc_k = [ calcipy_config . get ( key , {}) for key in section_keys ] self . lint = LintConfig ( ** meta_kwargs , ** lint_k ) # type: ignore[arg-type] self . test = TestingConfig ( ** meta_kwargs , ** test_k ) # type: ignore[arg-type] self . ct = CodeTagConfig ( ** meta_kwargs , doc_dir = doc_dir , ** code_k ) # type: ignore[arg-type] self . doc = DocConfig ( ** meta_kwargs , doc_dir = doc_dir , ** doc_k ) # type: ignore[arg-type] DG = DoitGlobals () \"\"\"Global doit Globals class used to manage global variables.\"\"\" _WORK_DIR = doit . get_initial_workdir () \"\"\"Work directory identified by doit.\"\"\" DG . set_paths ( path_project = ( Path ( _WORK_DIR ) if _WORK_DIR else Path . cwd ()) . resolve ()) Variables \u2693\ufe0e DG Global doit Globals class used to manage global variables. DoitAction Type: individual doit action. DoitTask Type: full doit task. Classes \u2693\ufe0e CodeTagConfig \u2693\ufe0e class CodeTagConfig ( * , path_project : pathlib . Path , doc_dir : pathlib . Path = PosixPath ( 'docs/docs' ), code_tag_summary_filename : str = 'CODE_TAG_SUMMARY.md' , tags : List [ str ] = [ 'FIXME' , 'TODO' , 'PLANNED' , 'HACK' , 'REVIEW' , 'TBD' , 'DEBUG' , 'FYI' , 'NOTE' ], re_raw : str = '(( \\\\ s| \\\\ ()(?P<tag> {tag} )(:[^ \\\\ r \\\\ n]))(?P<text>.+)' ) View Source class CodeTagConfig ( _PathAttrBase ): # noqa: H601 \"\"\"Code Tag Config.\"\"\" doc_dir : Path = Path ( 'docs/docs' ) \"\"\"Relative path to the source documentation directory.\"\"\" code_tag_summary_filename : str = 'CODE_TAG_SUMMARY.md' \"\"\"Name of the code tag summary file.\"\"\" tags : List [ str ] = [ 'FIXME' , 'TODO' , 'PLANNED' , 'HACK' , 'REVIEW' , 'TBD' , 'DEBUG' , 'FYI' , 'NOTE' , # noqa: T100,T101,T103 ] \"\"\"List of ordered tag names to match.\"\"\" re_raw : str = r '((\\s|\\()(?P<tag> {tag} )(:[^\\r\\n]))(?P<text>.+)' \"\"\"string regular expression that contains `{tag}`.\"\"\" path_code_tag_summary : Path = attr . ib ( init = False ) \"\"\"Path to the code tag summary file. Uses `code_tag_summary_filename`.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Finish initializing class attributes.\"\"\" super () . __attrs_post_init__ () # Configure full path to the code tag summary file self . path_code_tag_summary = self . path_project / self . doc_dir / self . code_tag_summary_filename def compile_issue_regex ( self ) -> Pattern [ str ]: \"\"\"Compile the regex for the specified raw regular expression string and tags. Returns: Pattern[str]: compiled regular expression to match all of the specified tags \"\"\" return re . compile ( self . re_raw . format ( tag = '|' . join ( self . tags ))) Ancestors (in MRO) \u2693\ufe0e calcipy.doit_tasks.doit_globals._PathAttrBase Methods \u2693\ufe0e compile_issue_regex \u2693\ufe0e def compile_issue_regex ( self ) -> Pattern [ str ] Compile the regex for the specified raw regular expression string and tags. Returns: Type Description Pattern[str] compiled regular expression to match all of the specified tags View Source def compile_issue_regex ( self ) -> Pattern [ str ]: \"\"\"Compile the regex for the specified raw regular expression string and tags. Returns: Pattern[str]: compiled regular expression to match all of the specified tags \"\"\" return re . compile ( self . re_raw . format ( tag = '|' . join ( self . tags ))) DocConfig \u2693\ufe0e class DocConfig ( * , path_project : pathlib . Path , doc_dir : pathlib . Path = PosixPath ( 'docs/docs' ), handler_lookup : Union [ Dict [ str , Callable [[ str , pathlib . Path ], str ]], NoneType ] = None ) View Source class DocConfig ( _PathAttrBase ): # noqa: H601 \"\"\"Documentation Config.\"\"\" doc_dir : Path = Path ( 'docs/docs' ) \"\"\"Relative path to the source documentation directory.\"\"\" handler_lookup : Optional [ Dict [ str , Callable [[ str , Path ], str ]]] = None \"\"\"Lookup dictionary for autoformatted sections of the project's markdown files.\"\"\" path_out : Path = attr . ib ( init = False ) \"\"\"The documentation output directory. Specified in `mkdocs.yml`.\"\"\" paths_md : List [ Path ] = attr . ib ( init = False ) \"\"\"Paths to Markdown files used when documenting. Created with `find_project_files_by_suffix`.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Finish initializing class attributes.\"\"\" super () . __attrs_post_init__ () mkdocs_config = _read_yaml_file ( self . path_project / _MKDOCS_CONFIG_NAME ) self . path_out = mkdocs_config . get ( 'site_dir' , 'releases/site' ) self . path_out = _make_full_path ( self . path_out , self . path_project ) self . path_out . mkdir ( exist_ok = True , parents = True ) self . paths_md = DG . meta . paths_by_suffix . get ( 'md' , []) Ancestors (in MRO) \u2693\ufe0e calcipy.doit_tasks.doit_globals._PathAttrBase DoitGlobals \u2693\ufe0e class DoitGlobals ( ) View Source class DoitGlobals : \"\"\"Global Variables for doit.\"\"\" calcipy_dir : Path = attr . ib ( init = False , default = Path ( __file__ ) . resolve () . parents [ 1 ]) \"\"\"The calcipy directory (likely within `.venv`).\"\"\" meta : PackageMeta = attr . ib ( init = False ) \"\"\"Package Meta-Information.\"\"\" lint : LintConfig = attr . ib ( init = False ) \"\"\"Lint Config.\"\"\" test : TestingConfig = attr . ib ( init = False ) \"\"\"Test Config.\"\"\" ct : CodeTagConfig = attr . ib ( init = False ) \"\"\"Documentation Config.\"\"\" doc : DocConfig = attr . ib ( init = False ) \"\"\"Documentation Config.\"\"\" @log_fun def set_paths ( self , * , path_project : Optional [ Path ] = None , ) -> None : \"\"\"Set data members based on working directory. Args: path_project: optional project base directory Path. Defaults to the current working directory Raises: RuntimeError: if problems in formatting of the toml file \"\"\" logger . info ( f 'Setting DG path: { path_project } ' , path_project = path_project , cwd = Path . cwd ()) path_project = path_project or Path . cwd () # Read the optional toml configuration # > Note: could allow LintConfig/.../DocConfig kwargs to be set in toml, but may be difficult to maintain path_toml = path_project / 'pyproject.toml' calcipy_config = toml . load ( path_toml ) . get ( 'tool' , {}) . get ( 'calcipy' , {}) ignore_patterns = calcipy_config . get ( 'ignore_patterns' , []) self . meta = PackageMeta ( path_project = path_project , ignore_patterns = ignore_patterns ) meta_kwargs = { 'path_project' : self . meta . path_project } # Parse the Copier file for configuration information doc_dir = get_doc_dir ( self . meta . path_project ) / 'docs' # Note: subdirectory is important doc_dir . mkdir ( exist_ok = True , parents = True ) # Configure global options section_keys = [ 'lint' , 'test' , 'code_tag' , 'doc' ] supported_keys = section_keys + [ 'ignore_patterns' ] unexpected_keys = [ key for key in calcipy_config if key not in supported_keys ] if unexpected_keys : raise RuntimeError ( f 'Found unexpected key(s) { unexpected_keys } (i.e. not in { supported_keys } )' ) lint_k , test_k , code_k , doc_k = [ calcipy_config . get ( key , {}) for key in section_keys ] self . lint = LintConfig ( ** meta_kwargs , ** lint_k ) # type: ignore[arg-type] self . test = TestingConfig ( ** meta_kwargs , ** test_k ) # type: ignore[arg-type] self . ct = CodeTagConfig ( ** meta_kwargs , doc_dir = doc_dir , ** code_k ) # type: ignore[arg-type] self . doc = DocConfig ( ** meta_kwargs , doc_dir = doc_dir , ** doc_k ) # type: ignore[arg-type] Methods \u2693\ufe0e set_paths \u2693\ufe0e def set_paths ( self , * , path_project : Union [ pathlib . Path , NoneType ] = None ) -> None Set data members based on working directory. Parameters: Name Type Description Default path_project None optional project base directory Path. Defaults to the current working directory None Raises: Type Description RuntimeError if problems in formatting of the toml file View Source @log_fun def set_paths ( self , * , path_project : Optional [ Path ] = None , ) -> None : \"\"\"Set data members based on working directory. Args: path_project: optional project base directory Path. Defaults to the current working directory Raises: RuntimeError: if problems in formatting of the toml file \"\"\" logger . info ( f 'Setting DG path: { path_project } ' , path_project = path_project , cwd = Path . cwd ()) path_project = path_project or Path . cwd () # Read the optional toml configuration # > Note: could allow LintConfig/.../DocConfig kwargs to be set in toml, but may be difficult to maintain path_toml = path_project / 'pyproject.toml' calcipy_config = toml . load ( path_toml ) . get ( 'tool' , {}) . get ( 'calcipy' , {}) ignore_patterns = calcipy_config . get ( 'ignore_patterns' , []) self . meta = PackageMeta ( path_project = path_project , ignore_patterns = ignore_patterns ) meta_kwargs = { 'path_project' : self . meta . path_project } # Parse the Copier file for configuration information doc_dir = get_doc_dir ( self . meta . path_project ) / 'docs' # Note: subdirectory is important doc_dir . mkdir ( exist_ok = True , parents = True ) # Configure global options section_keys = [ 'lint' , 'test' , 'code_tag' , 'doc' ] supported_keys = section_keys + [ 'ignore_patterns' ] unexpected_keys = [ key for key in calcipy_config if key not in supported_keys ] if unexpected_keys : raise RuntimeError ( f 'Found unexpected key(s) { unexpected_keys } (i.e. not in { supported_keys } )' ) lint_k , test_k , code_k , doc_k = [ calcipy_config . get ( key , {}) for key in section_keys ] self . lint = LintConfig ( ** meta_kwargs , ** lint_k ) # type: ignore[arg-type] self . test = TestingConfig ( ** meta_kwargs , ** test_k ) # type: ignore[arg-type] self . ct = CodeTagConfig ( ** meta_kwargs , doc_dir = doc_dir , ** code_k ) # type: ignore[arg-type] self . doc = DocConfig ( ** meta_kwargs , doc_dir = doc_dir , ** doc_k ) # type: ignore[arg-type] LintConfig \u2693\ufe0e class LintConfig ( * , path_project : pathlib . Path , path_flake8 : Union [ pathlib . Path , str ] = PosixPath ( '.flake8' ), path_isort : Union [ pathlib . Path , str ] = PosixPath ( 'pyproject.toml' ), ignore_errors : List [ str ] = [ 'AAA01' , 'C901' , 'D417' , 'DAR101' , 'DAR201' , 'DAR401' , 'DUO106' , 'E800' , 'G001' , 'H601' , 'P101' , 'P103' , 'PD013' , 'S101' , 'S605' , 'S607' , 'T100' , 'T101' , 'T103' ] ) View Source class LintConfig ( _PathAttrBase ): # noqa: H601 \"\"\"Lint Config.\"\"\" path_flake8 : Union [ Path , str ] = Path ( '.flake8' ) \"\"\"Relative path to the flake8 configuration file. Default is \".flake8\" created by calcipy_template.\"\"\" path_isort : Union [ Path , str ] = Path ( 'pyproject.toml' ) \"\"\"Relative path to the isort configuration file. Default is \"pyproject.toml\" created by calcipy_template.\"\"\" ignore_errors : List [ str ] = [ 'AAA01' , # AAA01 / act block in pytest 'C901' , # C901 / complexity from \"max-complexity = 10\" 'D417' , # D417 / missing arg descriptors 'DAR101' , 'DAR201' , 'DAR401' , # https://pypi.org/project/darglint/ (Scroll to error codes) 'DUO106' , # DUO106 / insecure use of os 'E800' , # E800 / Commented out code 'G001' , # G001 / logging format for un-indexed parameters 'H601' , # H601 / class with low cohesion 'P101' , 'P103' , # P101,P103 / format string 'PD013' , 'S101' , # S101 / assert 'S605' , 'S607' , # S605,S607 / os.popen(...) 'T100' , 'T101' , 'T103' , # T100,T101,T103 / fixme and todo comments ] \"\"\"List of additional excluded flake8 rules for the pre-commit check.\"\"\" paths_py : List [ Path ] = attr . ib ( init = False ) \"\"\"Paths to the Python files used when linting. Created with `find_project_files_by_suffix`.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Finish initializing class attributes.\"\"\" super () . __attrs_post_init__ () self . path_flake8 = _make_full_path ( self . path_flake8 , self . path_project ) self . path_isort = _make_full_path ( self . path_isort , self . path_project ) self . paths_py = DG . meta . paths_by_suffix . get ( 'py' , []) Ancestors (in MRO) \u2693\ufe0e calcipy.doit_tasks.doit_globals._PathAttrBase PackageMeta \u2693\ufe0e class PackageMeta ( * , path_project : pathlib . Path , path_toml : pathlib . Path = PosixPath ( 'pyproject.toml' ), ignore_patterns : List [ str ] = [] ) View Source class PackageMeta ( _PathAttrBase ): # noqa: H601 \"\"\"Package Meta-Information.\"\"\" path_toml : Path = Path ( 'pyproject.toml' ) \"\"\"Relative path to the poetry toml file.\"\"\" ignore_patterns : List [ str ] = [] \"\"\"List of glob patterns to ignore from all analysis.\"\"\" paths : List [ Path ] = attr . ib ( init = False ) \"\"\"Paths to all tracked files that were not ignored with specified patterns `find_project_files`.\"\"\" paths_by_suffix : Dict [ str , List [ Path ]] = attr . ib ( init = False ) \"\"\"Paths to all tracked files that were not ignored with specified patterns `find_project_files_by_suffix`.\"\"\" pkg_name : str = attr . ib ( init = False ) \"\"\"Package string name.\"\"\" pkg_version : str = attr . ib ( init = False ) \"\"\"Package version.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Finish initializing class attributes. Raises: RuntimeError: if the toml package is not available FileNotFoundError: if the toml could not be located \"\"\" super () . __attrs_post_init__ () # Note: toml is an optional dependency required only when using the `doit_tasks` in development if toml is None : # pragma: no cover raise RuntimeError ( _DOIT_TASK_IMPORT_ERROR ) try : poetry_config = toml . load ( self . path_toml )[ 'tool' ][ 'poetry' ] except FileNotFoundError : # pragma: no cover raise FileNotFoundError ( f 'Check that \" { self . path_project } \" is correct. Could not find: { self . path_toml } ' ) self . pkg_name = poetry_config [ 'name' ] self . pkg_version = poetry_config [ 'version' ] if '-' in self . pkg_name : # pragma: no cover warnings . warn ( f 'Replace dashes in name with underscores ( { self . pkg_name } ) in { self . path_toml } ' ) self . paths = find_project_files ( self . path_project , self . ignore_patterns ) self . paths_by_suffix = find_project_files_by_suffix ( self . path_project , self . ignore_patterns ) def __shorted_path_list ( self ) -> Set [ str ]: # pragma: no cover \"\"\"Shorten the list of directories common to the specified paths. > Not currently needed, but could be useful Returns: Set[str]: set of most common top-level directories relative to the project dir \"\"\" return { pth . parent . relative_to ( self . path_project ) . as_posix () for pth in self . paths } # type: ignore[attr-defined] Ancestors (in MRO) \u2693\ufe0e calcipy.doit_tasks.doit_globals._PathAttrBase TestingConfig \u2693\ufe0e class TestingConfig ( * , path_project : pathlib . Path , pythons : List [ str ] = [ '3.8' , '3.9' ], path_out : Union [ pathlib . Path , str ] = PosixPath ( 'releases/tests' ), path_tests : Union [ pathlib . Path , str ] = PosixPath ( 'tests' ), args_pytest : str = '--exitfirst --showlocals --failed-first --new-first --verbose --doctest-modules' , args_diff : str = '--fail-under=65 --compare-branch=origin/main' ) View Source class TestingConfig ( _PathAttrBase ): # noqa: H601 \"\"\"Test Config.\"\"\" pythons : List [ str ] = [ '3.8' , '3.9' ] \"\"\"Python versions to test against. Default is `['3.8', '3.9']`.\"\"\" path_out : Union [ Path , str ] = Path ( 'releases/tests' ) \"\"\"Relative path to the report output directory. Default is `releases/tests`.\"\"\" path_tests : Union [ Path , str ] = Path ( 'tests' ) \"\"\"Relative path to the tests directory. Default is `tests`.\"\"\" args_pytest : str = '--exitfirst --showlocals --failed-first --new-first --verbose --doctest-modules' \"\"\"Default arguments to Pytest. In short form, the defaults are `-x -l --ff --nf -vv`.\"\"\" args_diff : str = '--fail-under=65 --compare-branch=origin/main' \"\"\"Default arguments to diff-cover.\"\"\" path_test_report : Path = attr . ib ( init = False ) \"\"\"Path to the self-contained test HTML report.\"\"\" path_diff_test_report : Path = attr . ib ( init = False ) \"\"\"Path to the self-contained diff-test HTML report.\"\"\" path_diff_lint_report : Path = attr . ib ( init = False ) \"\"\"Path to the self-contained diff-lint HTML report.\"\"\" path_coverage_index : Path = attr . ib ( init = False ) \"\"\"Path to the coverage HTML index file within the report directory.\"\"\" path_mypy_index : Path = attr . ib ( init = False ) \"\"\"Path to the mypy HTML index file within the report directory.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Finish initializing class attributes.\"\"\" super () . __attrs_post_init__ () self . path_out = _make_full_path ( self . path_out , self . path_project ) self . path_tests = _make_full_path ( self . path_tests , self . path_project ) self . path_out . mkdir ( exist_ok = True , parents = True ) # Configure the paths to the report HTML and coverage HTML files self . path_test_report = self . path_out / 'test_report.html' self . path_diff_test_report = self . path_out / 'diff_test_report.html' self . path_diff_lint_report = self . path_out / 'diff_lint_report.html' self . path_coverage_index = self . path_out / 'cov_html/index.html' self . path_mypy_index = self . path_out / 'mypy_html/index.html' Ancestors (in MRO) \u2693\ufe0e calcipy.doit_tasks.doit_globals._PathAttrBase","title":"calcipy.doit_tasks.doit_globals"},{"location":"docs/modules/calcipy/doit_tasks/doit_globals/#calcipydoit_tasksdoit_globals","text":"Global Variables for doit. View Source \"\"\"Global Variables for doit.\"\"\" import inspect import re import warnings from functools import partial from pathlib import Path from typing import Any , Callable , Dict , Iterable , List , Optional , Pattern , Set , Tuple , Union import attr import doit import toml from beartype import beartype from doit.action import BaseAction from doit.task import Task from loguru import logger from ..file_helpers import _MKDOCS_CONFIG_NAME , _read_yaml_file , get_doc_dir from ..log_helpers import log_fun from .file_search import find_project_files , find_project_files_by_suffix _DOIT_TASK_IMPORT_ERROR = 'User must install the optional calcipy extra \"dev\" to utilize \"doit_tasks\"' \"\"\"Standard error message when an optional import is not available. Raise with RuntimeError.\"\"\" _DoitCallableArgs = Iterable [ Union [ str , float , int , Path , Dict [ str , Any ]]] \"\"\"Type: legal types that can be passed to a Python callable for doit actions.\"\"\" DoitAction = Union [ str , BaseAction , Tuple [ Callable , _DoitCallableArgs ]] # type: ignore[type-arg] \"\"\"Type: individual doit action.\"\"\" DoitTask = Union [ Task , Dict [ str , DoitAction ]] \"\"\"Type: full doit task.\"\"\" @beartype def _make_full_path ( raw : Union [ Path , str ], path_base : Path ) -> Path : \"\"\"Return a full path by determining if the source path is an absolute path. If not combines with base path. Args: raw: (string or Path) relative or absolute path path_base: base directory to use if the raw path is not absolute Returns: Path: absolute path \"\"\" return Path ( raw ) if Path ( raw ) . is_absolute () else path_base / raw @beartype def _member_filter ( member : Any , instance_type : Any ) -> bool : \"\"\"Return True if the member matches the filters. Args: member: class data- or method-member instance_type: optional instance type Returns: bool: True if the member matches the applied filter \"\"\" return ( instance_type is None or isinstance ( member , instance_type )) @attr . s ( auto_attribs = True , kw_only = True ) class _PathAttrBase : # noqa: H601 path_project : Path \"\"\"Path to the package directory.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Initialize full paths with the package base directory if necessary. Raises: RuntimeError: if any paths are None \"\"\" if self . path_project is None : raise RuntimeError ( 'Missing keyword argument \"path_project\"' ) # pragma: no cover self . _resolve_class_paths ( self . path_project ) self . _verify_initialized_paths () def _get_members ( self , prefix : Optional [ str ], ** kwargs : Any ) -> List [ Tuple [ str , Callable [[ Any ], Any ]]]: \"\"\"Return the members that match the parameters. Example to return all methods that start with `do_`: `self._get_members(instance_type=Callable, prefix='do_')` Args: prefix: optional string prefix to check starts with kwargs: keyword arguments passed to `_member_filter` Returns: List[Tuple[str, Callable]]: filtered members from the class \"\"\" members = inspect . getmembers ( self , predicate = partial ( _member_filter , ** kwargs )) if prefix : members = [( name , member ) for ( name , member ) in members if name . startswith ( prefix )] return members # noqa: R504 def _resolve_class_paths ( self , base_path : Path ) -> None : \"\"\"Resolve all partial paths with the specified base path. WARN: will mutate the class attribute Args: base_path: base path to apply to all found relative paths \"\"\" for name , path_raw in self . _get_members ( instance_type = type ( Path ()), prefix = None ): if not path_raw . is_absolute (): # type: ignore[attr-defined] setattr ( self , name , base_path / path_raw ) # type: ignore[operator] logger . debug ( f 'Mutated: self. { name } = { path_raw } (now: { getattr ( self , name ) } )' ) def _verify_initialized_paths ( self ) -> None : \"\"\"Verify that all paths are not None. WARN: will not raise on error the class attribute Raises: RuntimeError: if any paths are None \"\"\" missing = [ name for name , _m in self . _get_members ( instance_type = type ( None ), prefix = 'path_' )] if missing : kwargs = ', ' . join ( missing ) raise RuntimeError ( f 'Missing keyword arguments for: { kwargs } ' ) @attr . s ( auto_attribs = True , kw_only = True ) class PackageMeta ( _PathAttrBase ): # noqa: H601 \"\"\"Package Meta-Information.\"\"\" path_toml : Path = Path ( 'pyproject.toml' ) \"\"\"Relative path to the poetry toml file.\"\"\" ignore_patterns : List [ str ] = [] \"\"\"List of glob patterns to ignore from all analysis.\"\"\" paths : List [ Path ] = attr . ib ( init = False ) \"\"\"Paths to all tracked files that were not ignored with specified patterns `find_project_files`.\"\"\" paths_by_suffix : Dict [ str , List [ Path ]] = attr . ib ( init = False ) \"\"\"Paths to all tracked files that were not ignored with specified patterns `find_project_files_by_suffix`.\"\"\" pkg_name : str = attr . ib ( init = False ) \"\"\"Package string name.\"\"\" pkg_version : str = attr . ib ( init = False ) \"\"\"Package version.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Finish initializing class attributes. Raises: RuntimeError: if the toml package is not available FileNotFoundError: if the toml could not be located \"\"\" super () . __attrs_post_init__ () # Note: toml is an optional dependency required only when using the `doit_tasks` in development if toml is None : # pragma: no cover raise RuntimeError ( _DOIT_TASK_IMPORT_ERROR ) try : poetry_config = toml . load ( self . path_toml )[ 'tool' ][ 'poetry' ] except FileNotFoundError : # pragma: no cover raise FileNotFoundError ( f 'Check that \" { self . path_project } \" is correct. Could not find: { self . path_toml } ' ) self . pkg_name = poetry_config [ 'name' ] self . pkg_version = poetry_config [ 'version' ] if '-' in self . pkg_name : # pragma: no cover warnings . warn ( f 'Replace dashes in name with underscores ( { self . pkg_name } ) in { self . path_toml } ' ) self . paths = find_project_files ( self . path_project , self . ignore_patterns ) self . paths_by_suffix = find_project_files_by_suffix ( self . path_project , self . ignore_patterns ) def __shorted_path_list ( self ) -> Set [ str ]: # pragma: no cover \"\"\"Shorten the list of directories common to the specified paths. > Not currently needed, but could be useful Returns: Set[str]: set of most common top-level directories relative to the project dir \"\"\" return { pth . parent . relative_to ( self . path_project ) . as_posix () for pth in self . paths } # type: ignore[attr-defined] @attr . s ( auto_attribs = True , kw_only = True ) class LintConfig ( _PathAttrBase ): # noqa: H601 \"\"\"Lint Config.\"\"\" path_flake8 : Union [ Path , str ] = Path ( '.flake8' ) \"\"\"Relative path to the flake8 configuration file. Default is \".flake8\" created by calcipy_template.\"\"\" path_isort : Union [ Path , str ] = Path ( 'pyproject.toml' ) \"\"\"Relative path to the isort configuration file. Default is \"pyproject.toml\" created by calcipy_template.\"\"\" ignore_errors : List [ str ] = [ 'AAA01' , # AAA01 / act block in pytest 'C901' , # C901 / complexity from \"max-complexity = 10\" 'D417' , # D417 / missing arg descriptors 'DAR101' , 'DAR201' , 'DAR401' , # https://pypi.org/project/darglint/ (Scroll to error codes) 'DUO106' , # DUO106 / insecure use of os 'E800' , # E800 / Commented out code 'G001' , # G001 / logging format for un-indexed parameters 'H601' , # H601 / class with low cohesion 'P101' , 'P103' , # P101,P103 / format string 'PD013' , 'S101' , # S101 / assert 'S605' , 'S607' , # S605,S607 / os.popen(...) 'T100' , 'T101' , 'T103' , # T100,T101,T103 / fixme and todo comments ] \"\"\"List of additional excluded flake8 rules for the pre-commit check.\"\"\" paths_py : List [ Path ] = attr . ib ( init = False ) \"\"\"Paths to the Python files used when linting. Created with `find_project_files_by_suffix`.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Finish initializing class attributes.\"\"\" super () . __attrs_post_init__ () self . path_flake8 = _make_full_path ( self . path_flake8 , self . path_project ) self . path_isort = _make_full_path ( self . path_isort , self . path_project ) self . paths_py = DG . meta . paths_by_suffix . get ( 'py' , []) @attr . s ( auto_attribs = True , kw_only = True ) class TestingConfig ( _PathAttrBase ): # noqa: H601 \"\"\"Test Config.\"\"\" pythons : List [ str ] = [ '3.8' , '3.9' ] \"\"\"Python versions to test against. Default is `['3.8', '3.9']`.\"\"\" path_out : Union [ Path , str ] = Path ( 'releases/tests' ) \"\"\"Relative path to the report output directory. Default is `releases/tests`.\"\"\" path_tests : Union [ Path , str ] = Path ( 'tests' ) \"\"\"Relative path to the tests directory. Default is `tests`.\"\"\" args_pytest : str = '--exitfirst --showlocals --failed-first --new-first --verbose --doctest-modules' \"\"\"Default arguments to Pytest. In short form, the defaults are `-x -l --ff --nf -vv`.\"\"\" args_diff : str = '--fail-under=65 --compare-branch=origin/main' \"\"\"Default arguments to diff-cover.\"\"\" path_test_report : Path = attr . ib ( init = False ) \"\"\"Path to the self-contained test HTML report.\"\"\" path_diff_test_report : Path = attr . ib ( init = False ) \"\"\"Path to the self-contained diff-test HTML report.\"\"\" path_diff_lint_report : Path = attr . ib ( init = False ) \"\"\"Path to the self-contained diff-lint HTML report.\"\"\" path_coverage_index : Path = attr . ib ( init = False ) \"\"\"Path to the coverage HTML index file within the report directory.\"\"\" path_mypy_index : Path = attr . ib ( init = False ) \"\"\"Path to the mypy HTML index file within the report directory.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Finish initializing class attributes.\"\"\" super () . __attrs_post_init__ () self . path_out = _make_full_path ( self . path_out , self . path_project ) self . path_tests = _make_full_path ( self . path_tests , self . path_project ) self . path_out . mkdir ( exist_ok = True , parents = True ) # Configure the paths to the report HTML and coverage HTML files self . path_test_report = self . path_out / 'test_report.html' self . path_diff_test_report = self . path_out / 'diff_test_report.html' self . path_diff_lint_report = self . path_out / 'diff_lint_report.html' self . path_coverage_index = self . path_out / 'cov_html/index.html' self . path_mypy_index = self . path_out / 'mypy_html/index.html' @attr . s ( auto_attribs = True , kw_only = True ) class CodeTagConfig ( _PathAttrBase ): # noqa: H601 \"\"\"Code Tag Config.\"\"\" doc_dir : Path = Path ( 'docs/docs' ) \"\"\"Relative path to the source documentation directory.\"\"\" code_tag_summary_filename : str = 'CODE_TAG_SUMMARY.md' \"\"\"Name of the code tag summary file.\"\"\" tags : List [ str ] = [ 'FIXME' , 'TODO' , 'PLANNED' , 'HACK' , 'REVIEW' , 'TBD' , 'DEBUG' , 'FYI' , 'NOTE' , # noqa: T100,T101,T103 ] \"\"\"List of ordered tag names to match.\"\"\" re_raw : str = r '((\\s|\\()(?P<tag> {tag} )(:[^\\r\\n]))(?P<text>.+)' \"\"\"string regular expression that contains `{tag}`.\"\"\" path_code_tag_summary : Path = attr . ib ( init = False ) \"\"\"Path to the code tag summary file. Uses `code_tag_summary_filename`.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Finish initializing class attributes.\"\"\" super () . __attrs_post_init__ () # Configure full path to the code tag summary file self . path_code_tag_summary = self . path_project / self . doc_dir / self . code_tag_summary_filename def compile_issue_regex ( self ) -> Pattern [ str ]: \"\"\"Compile the regex for the specified raw regular expression string and tags. Returns: Pattern[str]: compiled regular expression to match all of the specified tags \"\"\" return re . compile ( self . re_raw . format ( tag = '|' . join ( self . tags ))) @attr . s ( auto_attribs = True , kw_only = True ) class DocConfig ( _PathAttrBase ): # noqa: H601 \"\"\"Documentation Config.\"\"\" doc_dir : Path = Path ( 'docs/docs' ) \"\"\"Relative path to the source documentation directory.\"\"\" handler_lookup : Optional [ Dict [ str , Callable [[ str , Path ], str ]]] = None \"\"\"Lookup dictionary for autoformatted sections of the project's markdown files.\"\"\" path_out : Path = attr . ib ( init = False ) \"\"\"The documentation output directory. Specified in `mkdocs.yml`.\"\"\" paths_md : List [ Path ] = attr . ib ( init = False ) \"\"\"Paths to Markdown files used when documenting. Created with `find_project_files_by_suffix`.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Finish initializing class attributes.\"\"\" super () . __attrs_post_init__ () mkdocs_config = _read_yaml_file ( self . path_project / _MKDOCS_CONFIG_NAME ) self . path_out = mkdocs_config . get ( 'site_dir' , 'releases/site' ) self . path_out = _make_full_path ( self . path_out , self . path_project ) self . path_out . mkdir ( exist_ok = True , parents = True ) self . paths_md = DG . meta . paths_by_suffix . get ( 'md' , []) @attr . s ( auto_attribs = True , kw_only = True ) class DoitGlobals : \"\"\"Global Variables for doit.\"\"\" calcipy_dir : Path = attr . ib ( init = False , default = Path ( __file__ ) . resolve () . parents [ 1 ]) \"\"\"The calcipy directory (likely within `.venv`).\"\"\" meta : PackageMeta = attr . ib ( init = False ) \"\"\"Package Meta-Information.\"\"\" lint : LintConfig = attr . ib ( init = False ) \"\"\"Lint Config.\"\"\" test : TestingConfig = attr . ib ( init = False ) \"\"\"Test Config.\"\"\" ct : CodeTagConfig = attr . ib ( init = False ) \"\"\"Documentation Config.\"\"\" doc : DocConfig = attr . ib ( init = False ) \"\"\"Documentation Config.\"\"\" @log_fun def set_paths ( self , * , path_project : Optional [ Path ] = None , ) -> None : \"\"\"Set data members based on working directory. Args: path_project: optional project base directory Path. Defaults to the current working directory Raises: RuntimeError: if problems in formatting of the toml file \"\"\" logger . info ( f 'Setting DG path: { path_project } ' , path_project = path_project , cwd = Path . cwd ()) path_project = path_project or Path . cwd () # Read the optional toml configuration # > Note: could allow LintConfig/.../DocConfig kwargs to be set in toml, but may be difficult to maintain path_toml = path_project / 'pyproject.toml' calcipy_config = toml . load ( path_toml ) . get ( 'tool' , {}) . get ( 'calcipy' , {}) ignore_patterns = calcipy_config . get ( 'ignore_patterns' , []) self . meta = PackageMeta ( path_project = path_project , ignore_patterns = ignore_patterns ) meta_kwargs = { 'path_project' : self . meta . path_project } # Parse the Copier file for configuration information doc_dir = get_doc_dir ( self . meta . path_project ) / 'docs' # Note: subdirectory is important doc_dir . mkdir ( exist_ok = True , parents = True ) # Configure global options section_keys = [ 'lint' , 'test' , 'code_tag' , 'doc' ] supported_keys = section_keys + [ 'ignore_patterns' ] unexpected_keys = [ key for key in calcipy_config if key not in supported_keys ] if unexpected_keys : raise RuntimeError ( f 'Found unexpected key(s) { unexpected_keys } (i.e. not in { supported_keys } )' ) lint_k , test_k , code_k , doc_k = [ calcipy_config . get ( key , {}) for key in section_keys ] self . lint = LintConfig ( ** meta_kwargs , ** lint_k ) # type: ignore[arg-type] self . test = TestingConfig ( ** meta_kwargs , ** test_k ) # type: ignore[arg-type] self . ct = CodeTagConfig ( ** meta_kwargs , doc_dir = doc_dir , ** code_k ) # type: ignore[arg-type] self . doc = DocConfig ( ** meta_kwargs , doc_dir = doc_dir , ** doc_k ) # type: ignore[arg-type] DG = DoitGlobals () \"\"\"Global doit Globals class used to manage global variables.\"\"\" _WORK_DIR = doit . get_initial_workdir () \"\"\"Work directory identified by doit.\"\"\" DG . set_paths ( path_project = ( Path ( _WORK_DIR ) if _WORK_DIR else Path . cwd ()) . resolve ())","title":"calcipy.doit_tasks.doit_globals"},{"location":"docs/modules/calcipy/doit_tasks/doit_globals/#variables","text":"DG Global doit Globals class used to manage global variables. DoitAction Type: individual doit action. DoitTask Type: full doit task.","title":"Variables"},{"location":"docs/modules/calcipy/doit_tasks/doit_globals/#classes","text":"","title":"Classes"},{"location":"docs/modules/calcipy/doit_tasks/doit_globals/#codetagconfig","text":"class CodeTagConfig ( * , path_project : pathlib . Path , doc_dir : pathlib . Path = PosixPath ( 'docs/docs' ), code_tag_summary_filename : str = 'CODE_TAG_SUMMARY.md' , tags : List [ str ] = [ 'FIXME' , 'TODO' , 'PLANNED' , 'HACK' , 'REVIEW' , 'TBD' , 'DEBUG' , 'FYI' , 'NOTE' ], re_raw : str = '(( \\\\ s| \\\\ ()(?P<tag> {tag} )(:[^ \\\\ r \\\\ n]))(?P<text>.+)' ) View Source class CodeTagConfig ( _PathAttrBase ): # noqa: H601 \"\"\"Code Tag Config.\"\"\" doc_dir : Path = Path ( 'docs/docs' ) \"\"\"Relative path to the source documentation directory.\"\"\" code_tag_summary_filename : str = 'CODE_TAG_SUMMARY.md' \"\"\"Name of the code tag summary file.\"\"\" tags : List [ str ] = [ 'FIXME' , 'TODO' , 'PLANNED' , 'HACK' , 'REVIEW' , 'TBD' , 'DEBUG' , 'FYI' , 'NOTE' , # noqa: T100,T101,T103 ] \"\"\"List of ordered tag names to match.\"\"\" re_raw : str = r '((\\s|\\()(?P<tag> {tag} )(:[^\\r\\n]))(?P<text>.+)' \"\"\"string regular expression that contains `{tag}`.\"\"\" path_code_tag_summary : Path = attr . ib ( init = False ) \"\"\"Path to the code tag summary file. Uses `code_tag_summary_filename`.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Finish initializing class attributes.\"\"\" super () . __attrs_post_init__ () # Configure full path to the code tag summary file self . path_code_tag_summary = self . path_project / self . doc_dir / self . code_tag_summary_filename def compile_issue_regex ( self ) -> Pattern [ str ]: \"\"\"Compile the regex for the specified raw regular expression string and tags. Returns: Pattern[str]: compiled regular expression to match all of the specified tags \"\"\" return re . compile ( self . re_raw . format ( tag = '|' . join ( self . tags )))","title":"CodeTagConfig"},{"location":"docs/modules/calcipy/doit_tasks/doit_globals/#ancestors-in-mro","text":"calcipy.doit_tasks.doit_globals._PathAttrBase","title":"Ancestors (in MRO)"},{"location":"docs/modules/calcipy/doit_tasks/doit_globals/#methods","text":"","title":"Methods"},{"location":"docs/modules/calcipy/doit_tasks/doit_globals/#compile_issue_regex","text":"def compile_issue_regex ( self ) -> Pattern [ str ] Compile the regex for the specified raw regular expression string and tags. Returns: Type Description Pattern[str] compiled regular expression to match all of the specified tags View Source def compile_issue_regex ( self ) -> Pattern [ str ]: \"\"\"Compile the regex for the specified raw regular expression string and tags. Returns: Pattern[str]: compiled regular expression to match all of the specified tags \"\"\" return re . compile ( self . re_raw . format ( tag = '|' . join ( self . tags )))","title":"compile_issue_regex"},{"location":"docs/modules/calcipy/doit_tasks/doit_globals/#docconfig","text":"class DocConfig ( * , path_project : pathlib . Path , doc_dir : pathlib . Path = PosixPath ( 'docs/docs' ), handler_lookup : Union [ Dict [ str , Callable [[ str , pathlib . Path ], str ]], NoneType ] = None ) View Source class DocConfig ( _PathAttrBase ): # noqa: H601 \"\"\"Documentation Config.\"\"\" doc_dir : Path = Path ( 'docs/docs' ) \"\"\"Relative path to the source documentation directory.\"\"\" handler_lookup : Optional [ Dict [ str , Callable [[ str , Path ], str ]]] = None \"\"\"Lookup dictionary for autoformatted sections of the project's markdown files.\"\"\" path_out : Path = attr . ib ( init = False ) \"\"\"The documentation output directory. Specified in `mkdocs.yml`.\"\"\" paths_md : List [ Path ] = attr . ib ( init = False ) \"\"\"Paths to Markdown files used when documenting. Created with `find_project_files_by_suffix`.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Finish initializing class attributes.\"\"\" super () . __attrs_post_init__ () mkdocs_config = _read_yaml_file ( self . path_project / _MKDOCS_CONFIG_NAME ) self . path_out = mkdocs_config . get ( 'site_dir' , 'releases/site' ) self . path_out = _make_full_path ( self . path_out , self . path_project ) self . path_out . mkdir ( exist_ok = True , parents = True ) self . paths_md = DG . meta . paths_by_suffix . get ( 'md' , [])","title":"DocConfig"},{"location":"docs/modules/calcipy/doit_tasks/doit_globals/#ancestors-in-mro_1","text":"calcipy.doit_tasks.doit_globals._PathAttrBase","title":"Ancestors (in MRO)"},{"location":"docs/modules/calcipy/doit_tasks/doit_globals/#doitglobals","text":"class DoitGlobals ( ) View Source class DoitGlobals : \"\"\"Global Variables for doit.\"\"\" calcipy_dir : Path = attr . ib ( init = False , default = Path ( __file__ ) . resolve () . parents [ 1 ]) \"\"\"The calcipy directory (likely within `.venv`).\"\"\" meta : PackageMeta = attr . ib ( init = False ) \"\"\"Package Meta-Information.\"\"\" lint : LintConfig = attr . ib ( init = False ) \"\"\"Lint Config.\"\"\" test : TestingConfig = attr . ib ( init = False ) \"\"\"Test Config.\"\"\" ct : CodeTagConfig = attr . ib ( init = False ) \"\"\"Documentation Config.\"\"\" doc : DocConfig = attr . ib ( init = False ) \"\"\"Documentation Config.\"\"\" @log_fun def set_paths ( self , * , path_project : Optional [ Path ] = None , ) -> None : \"\"\"Set data members based on working directory. Args: path_project: optional project base directory Path. Defaults to the current working directory Raises: RuntimeError: if problems in formatting of the toml file \"\"\" logger . info ( f 'Setting DG path: { path_project } ' , path_project = path_project , cwd = Path . cwd ()) path_project = path_project or Path . cwd () # Read the optional toml configuration # > Note: could allow LintConfig/.../DocConfig kwargs to be set in toml, but may be difficult to maintain path_toml = path_project / 'pyproject.toml' calcipy_config = toml . load ( path_toml ) . get ( 'tool' , {}) . get ( 'calcipy' , {}) ignore_patterns = calcipy_config . get ( 'ignore_patterns' , []) self . meta = PackageMeta ( path_project = path_project , ignore_patterns = ignore_patterns ) meta_kwargs = { 'path_project' : self . meta . path_project } # Parse the Copier file for configuration information doc_dir = get_doc_dir ( self . meta . path_project ) / 'docs' # Note: subdirectory is important doc_dir . mkdir ( exist_ok = True , parents = True ) # Configure global options section_keys = [ 'lint' , 'test' , 'code_tag' , 'doc' ] supported_keys = section_keys + [ 'ignore_patterns' ] unexpected_keys = [ key for key in calcipy_config if key not in supported_keys ] if unexpected_keys : raise RuntimeError ( f 'Found unexpected key(s) { unexpected_keys } (i.e. not in { supported_keys } )' ) lint_k , test_k , code_k , doc_k = [ calcipy_config . get ( key , {}) for key in section_keys ] self . lint = LintConfig ( ** meta_kwargs , ** lint_k ) # type: ignore[arg-type] self . test = TestingConfig ( ** meta_kwargs , ** test_k ) # type: ignore[arg-type] self . ct = CodeTagConfig ( ** meta_kwargs , doc_dir = doc_dir , ** code_k ) # type: ignore[arg-type] self . doc = DocConfig ( ** meta_kwargs , doc_dir = doc_dir , ** doc_k ) # type: ignore[arg-type]","title":"DoitGlobals"},{"location":"docs/modules/calcipy/doit_tasks/doit_globals/#methods_1","text":"","title":"Methods"},{"location":"docs/modules/calcipy/doit_tasks/doit_globals/#set_paths","text":"def set_paths ( self , * , path_project : Union [ pathlib . Path , NoneType ] = None ) -> None Set data members based on working directory. Parameters: Name Type Description Default path_project None optional project base directory Path. Defaults to the current working directory None Raises: Type Description RuntimeError if problems in formatting of the toml file View Source @log_fun def set_paths ( self , * , path_project : Optional [ Path ] = None , ) -> None : \"\"\"Set data members based on working directory. Args: path_project: optional project base directory Path. Defaults to the current working directory Raises: RuntimeError: if problems in formatting of the toml file \"\"\" logger . info ( f 'Setting DG path: { path_project } ' , path_project = path_project , cwd = Path . cwd ()) path_project = path_project or Path . cwd () # Read the optional toml configuration # > Note: could allow LintConfig/.../DocConfig kwargs to be set in toml, but may be difficult to maintain path_toml = path_project / 'pyproject.toml' calcipy_config = toml . load ( path_toml ) . get ( 'tool' , {}) . get ( 'calcipy' , {}) ignore_patterns = calcipy_config . get ( 'ignore_patterns' , []) self . meta = PackageMeta ( path_project = path_project , ignore_patterns = ignore_patterns ) meta_kwargs = { 'path_project' : self . meta . path_project } # Parse the Copier file for configuration information doc_dir = get_doc_dir ( self . meta . path_project ) / 'docs' # Note: subdirectory is important doc_dir . mkdir ( exist_ok = True , parents = True ) # Configure global options section_keys = [ 'lint' , 'test' , 'code_tag' , 'doc' ] supported_keys = section_keys + [ 'ignore_patterns' ] unexpected_keys = [ key for key in calcipy_config if key not in supported_keys ] if unexpected_keys : raise RuntimeError ( f 'Found unexpected key(s) { unexpected_keys } (i.e. not in { supported_keys } )' ) lint_k , test_k , code_k , doc_k = [ calcipy_config . get ( key , {}) for key in section_keys ] self . lint = LintConfig ( ** meta_kwargs , ** lint_k ) # type: ignore[arg-type] self . test = TestingConfig ( ** meta_kwargs , ** test_k ) # type: ignore[arg-type] self . ct = CodeTagConfig ( ** meta_kwargs , doc_dir = doc_dir , ** code_k ) # type: ignore[arg-type] self . doc = DocConfig ( ** meta_kwargs , doc_dir = doc_dir , ** doc_k ) # type: ignore[arg-type]","title":"set_paths"},{"location":"docs/modules/calcipy/doit_tasks/doit_globals/#lintconfig","text":"class LintConfig ( * , path_project : pathlib . Path , path_flake8 : Union [ pathlib . Path , str ] = PosixPath ( '.flake8' ), path_isort : Union [ pathlib . Path , str ] = PosixPath ( 'pyproject.toml' ), ignore_errors : List [ str ] = [ 'AAA01' , 'C901' , 'D417' , 'DAR101' , 'DAR201' , 'DAR401' , 'DUO106' , 'E800' , 'G001' , 'H601' , 'P101' , 'P103' , 'PD013' , 'S101' , 'S605' , 'S607' , 'T100' , 'T101' , 'T103' ] ) View Source class LintConfig ( _PathAttrBase ): # noqa: H601 \"\"\"Lint Config.\"\"\" path_flake8 : Union [ Path , str ] = Path ( '.flake8' ) \"\"\"Relative path to the flake8 configuration file. Default is \".flake8\" created by calcipy_template.\"\"\" path_isort : Union [ Path , str ] = Path ( 'pyproject.toml' ) \"\"\"Relative path to the isort configuration file. Default is \"pyproject.toml\" created by calcipy_template.\"\"\" ignore_errors : List [ str ] = [ 'AAA01' , # AAA01 / act block in pytest 'C901' , # C901 / complexity from \"max-complexity = 10\" 'D417' , # D417 / missing arg descriptors 'DAR101' , 'DAR201' , 'DAR401' , # https://pypi.org/project/darglint/ (Scroll to error codes) 'DUO106' , # DUO106 / insecure use of os 'E800' , # E800 / Commented out code 'G001' , # G001 / logging format for un-indexed parameters 'H601' , # H601 / class with low cohesion 'P101' , 'P103' , # P101,P103 / format string 'PD013' , 'S101' , # S101 / assert 'S605' , 'S607' , # S605,S607 / os.popen(...) 'T100' , 'T101' , 'T103' , # T100,T101,T103 / fixme and todo comments ] \"\"\"List of additional excluded flake8 rules for the pre-commit check.\"\"\" paths_py : List [ Path ] = attr . ib ( init = False ) \"\"\"Paths to the Python files used when linting. Created with `find_project_files_by_suffix`.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Finish initializing class attributes.\"\"\" super () . __attrs_post_init__ () self . path_flake8 = _make_full_path ( self . path_flake8 , self . path_project ) self . path_isort = _make_full_path ( self . path_isort , self . path_project ) self . paths_py = DG . meta . paths_by_suffix . get ( 'py' , [])","title":"LintConfig"},{"location":"docs/modules/calcipy/doit_tasks/doit_globals/#ancestors-in-mro_2","text":"calcipy.doit_tasks.doit_globals._PathAttrBase","title":"Ancestors (in MRO)"},{"location":"docs/modules/calcipy/doit_tasks/doit_globals/#packagemeta","text":"class PackageMeta ( * , path_project : pathlib . Path , path_toml : pathlib . Path = PosixPath ( 'pyproject.toml' ), ignore_patterns : List [ str ] = [] ) View Source class PackageMeta ( _PathAttrBase ): # noqa: H601 \"\"\"Package Meta-Information.\"\"\" path_toml : Path = Path ( 'pyproject.toml' ) \"\"\"Relative path to the poetry toml file.\"\"\" ignore_patterns : List [ str ] = [] \"\"\"List of glob patterns to ignore from all analysis.\"\"\" paths : List [ Path ] = attr . ib ( init = False ) \"\"\"Paths to all tracked files that were not ignored with specified patterns `find_project_files`.\"\"\" paths_by_suffix : Dict [ str , List [ Path ]] = attr . ib ( init = False ) \"\"\"Paths to all tracked files that were not ignored with specified patterns `find_project_files_by_suffix`.\"\"\" pkg_name : str = attr . ib ( init = False ) \"\"\"Package string name.\"\"\" pkg_version : str = attr . ib ( init = False ) \"\"\"Package version.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Finish initializing class attributes. Raises: RuntimeError: if the toml package is not available FileNotFoundError: if the toml could not be located \"\"\" super () . __attrs_post_init__ () # Note: toml is an optional dependency required only when using the `doit_tasks` in development if toml is None : # pragma: no cover raise RuntimeError ( _DOIT_TASK_IMPORT_ERROR ) try : poetry_config = toml . load ( self . path_toml )[ 'tool' ][ 'poetry' ] except FileNotFoundError : # pragma: no cover raise FileNotFoundError ( f 'Check that \" { self . path_project } \" is correct. Could not find: { self . path_toml } ' ) self . pkg_name = poetry_config [ 'name' ] self . pkg_version = poetry_config [ 'version' ] if '-' in self . pkg_name : # pragma: no cover warnings . warn ( f 'Replace dashes in name with underscores ( { self . pkg_name } ) in { self . path_toml } ' ) self . paths = find_project_files ( self . path_project , self . ignore_patterns ) self . paths_by_suffix = find_project_files_by_suffix ( self . path_project , self . ignore_patterns ) def __shorted_path_list ( self ) -> Set [ str ]: # pragma: no cover \"\"\"Shorten the list of directories common to the specified paths. > Not currently needed, but could be useful Returns: Set[str]: set of most common top-level directories relative to the project dir \"\"\" return { pth . parent . relative_to ( self . path_project ) . as_posix () for pth in self . paths } # type: ignore[attr-defined]","title":"PackageMeta"},{"location":"docs/modules/calcipy/doit_tasks/doit_globals/#ancestors-in-mro_3","text":"calcipy.doit_tasks.doit_globals._PathAttrBase","title":"Ancestors (in MRO)"},{"location":"docs/modules/calcipy/doit_tasks/doit_globals/#testingconfig","text":"class TestingConfig ( * , path_project : pathlib . Path , pythons : List [ str ] = [ '3.8' , '3.9' ], path_out : Union [ pathlib . Path , str ] = PosixPath ( 'releases/tests' ), path_tests : Union [ pathlib . Path , str ] = PosixPath ( 'tests' ), args_pytest : str = '--exitfirst --showlocals --failed-first --new-first --verbose --doctest-modules' , args_diff : str = '--fail-under=65 --compare-branch=origin/main' ) View Source class TestingConfig ( _PathAttrBase ): # noqa: H601 \"\"\"Test Config.\"\"\" pythons : List [ str ] = [ '3.8' , '3.9' ] \"\"\"Python versions to test against. Default is `['3.8', '3.9']`.\"\"\" path_out : Union [ Path , str ] = Path ( 'releases/tests' ) \"\"\"Relative path to the report output directory. Default is `releases/tests`.\"\"\" path_tests : Union [ Path , str ] = Path ( 'tests' ) \"\"\"Relative path to the tests directory. Default is `tests`.\"\"\" args_pytest : str = '--exitfirst --showlocals --failed-first --new-first --verbose --doctest-modules' \"\"\"Default arguments to Pytest. In short form, the defaults are `-x -l --ff --nf -vv`.\"\"\" args_diff : str = '--fail-under=65 --compare-branch=origin/main' \"\"\"Default arguments to diff-cover.\"\"\" path_test_report : Path = attr . ib ( init = False ) \"\"\"Path to the self-contained test HTML report.\"\"\" path_diff_test_report : Path = attr . ib ( init = False ) \"\"\"Path to the self-contained diff-test HTML report.\"\"\" path_diff_lint_report : Path = attr . ib ( init = False ) \"\"\"Path to the self-contained diff-lint HTML report.\"\"\" path_coverage_index : Path = attr . ib ( init = False ) \"\"\"Path to the coverage HTML index file within the report directory.\"\"\" path_mypy_index : Path = attr . ib ( init = False ) \"\"\"Path to the mypy HTML index file within the report directory.\"\"\" def __attrs_post_init__ ( self ) -> None : \"\"\"Finish initializing class attributes.\"\"\" super () . __attrs_post_init__ () self . path_out = _make_full_path ( self . path_out , self . path_project ) self . path_tests = _make_full_path ( self . path_tests , self . path_project ) self . path_out . mkdir ( exist_ok = True , parents = True ) # Configure the paths to the report HTML and coverage HTML files self . path_test_report = self . path_out / 'test_report.html' self . path_diff_test_report = self . path_out / 'diff_test_report.html' self . path_diff_lint_report = self . path_out / 'diff_lint_report.html' self . path_coverage_index = self . path_out / 'cov_html/index.html' self . path_mypy_index = self . path_out / 'mypy_html/index.html'","title":"TestingConfig"},{"location":"docs/modules/calcipy/doit_tasks/doit_globals/#ancestors-in-mro_4","text":"calcipy.doit_tasks.doit_globals._PathAttrBase","title":"Ancestors (in MRO)"},{"location":"docs/modules/calcipy/doit_tasks/file_search/","text":"calcipy.doit_tasks.file_search \u2693\ufe0e Find Files. View Source \"\"\"Find Files.\"\"\" from collections import defaultdict from pathlib import Path from typing import Dict , List from beartype import beartype from loguru import logger from pre_commit.git import zsplit from pre_commit.util import cmd_output @beartype def _get_all_files ( * , cwd : Path ) -> List [ str ]: \"\"\"Get all files using git. Modified `pre_commit.git.get_all_files` to accept `cwd`. https://github.com/pre-commit/pre-commit/blob/488b1999f36cac62b6b0d9bc8eae99418ae5c226/pre_commit/git.py#L153 Args: cwd: current working directory to pass to `subprocess.Popen` Returns: List[str]: list of all file paths relative to the `cwd` \"\"\" return zsplit ( cmd_output ( 'git' , 'ls-files' , '-z' , cwd = cwd )[ 1 ]) # type: ignore[no-any-return] @beartype def _filter_files ( rel_filepaths : List [ str ], ignore_patterns : List [ str ]) -> List [ str ]: \"\"\"Filter a list of string file paths with specified ignore patterns in glob syntax. Args: rel_filepaths: list of string file paths ignore_patterns: glob ignore patterns Returns: List[str]: list of all non-ignored file path names \"\"\" if ignore_patterns : matches = [] for pth in map ( Path , rel_filepaths ): matches . extend ([ pth . as_posix () for pat in ignore_patterns if pth . match ( pat )][: 1 ]) return [ rel for rel in rel_filepaths if rel not in matches ] return rel_filepaths @beartype def find_project_files ( path_project : Path , ignore_patterns : List [ str ]) -> List [ Path ]: \"\"\"Find project files in git version control. > Note: uses the relative project directory and verifies that each file exists Args: path_project: Path to the project directory. Typically `DG.meta.path_project` ignore_patterns: glob ignore patterns Returns: Dict[str, List[Path]]: where keys are the suffix (without leading dot) and values the list of paths \"\"\" file_paths = [] rel_filepaths = _get_all_files ( cwd = path_project ) filtered_rel_files = _filter_files ( rel_filepaths = rel_filepaths , ignore_patterns = ignore_patterns ) for rel_file in filtered_rel_files : path_file = path_project / rel_file if path_file . is_file (): file_paths . append ( path_file ) else : # pragma: no cover logger . warning ( f 'Could not find { rel_file } in { path_project } ' ) return file_paths @beartype def find_project_files_by_suffix ( path_project : Path , ignore_patterns : List [ str ]) -> Dict [ str , List [ Path ]]: \"\"\"Find project files in git version control. > Note: uses the relative project directory and verifies that each file exists Args: path_project: Path to the project directory. Typically `DG.meta.path_project` ignore_patterns: glob ignore patterns Returns: Dict[str, List[Path]]: where keys are the suffix (without leading dot) and values the list of paths \"\"\" file_lookup = defaultdict ( list ) for path_file in find_project_files ( path_project , ignore_patterns ): file_lookup [ path_file . suffix . lstrip ( '.' )] . append ( path_file ) return file_lookup Functions \u2693\ufe0e find_project_files \u2693\ufe0e def find_project_files ( path_project : pathlib . Path , ignore_patterns : List [ str ] ) -> List [ pathlib . Path ] Find project files in git version control. Note: uses the relative project directory and verifies that each file exists Parameters: Name Type Description Default path_project None Path to the project directory. Typically DG.meta.path_project None ignore_patterns None glob ignore patterns None Returns: Type Description Dict[str, List[Path]] where keys are the suffix (without leading dot) and values the list of paths View Source @beartype def find_project_files ( path_project : Path , ignore_patterns : List [ str ]) -> List [ Path ]: \"\"\"Find project files in git version control. > Note: uses the relative project directory and verifies that each file exists Args: path_project: Path to the project directory. Typically `DG.meta.path_project` ignore_patterns: glob ignore patterns Returns: Dict[str, List[Path]]: where keys are the suffix (without leading dot) and values the list of paths \"\"\" file_paths = [] rel_filepaths = _get_all_files ( cwd = path_project ) filtered_rel_files = _filter_files ( rel_filepaths = rel_filepaths , ignore_patterns = ignore_patterns ) for rel_file in filtered_rel_files : path_file = path_project / rel_file if path_file . is_file (): file_paths . append ( path_file ) else : # pragma: no cover logger . warning ( f 'Could not find { rel_file } in { path_project } ' ) return file_paths find_project_files_by_suffix \u2693\ufe0e def find_project_files_by_suffix ( path_project : pathlib . Path , ignore_patterns : List [ str ] ) -> Dict [ str , List [ pathlib . Path ]] Find project files in git version control. Note: uses the relative project directory and verifies that each file exists Parameters: Name Type Description Default path_project None Path to the project directory. Typically DG.meta.path_project None ignore_patterns None glob ignore patterns None Returns: Type Description Dict[str, List[Path]] where keys are the suffix (without leading dot) and values the list of paths View Source @beartype def find_project_files_by_suffix ( path_project : Path , ignore_patterns : List [ str ]) -> Dict [ str , List [ Path ]]: \"\"\"Find project files in git version control. > Note: uses the relative project directory and verifies that each file exists Args: path_project: Path to the project directory. Typically `DG.meta.path_project` ignore_patterns: glob ignore patterns Returns: Dict[str, List[Path]]: where keys are the suffix (without leading dot) and values the list of paths \"\"\" file_lookup = defaultdict ( list ) for path_file in find_project_files ( path_project , ignore_patterns ): file_lookup [ path_file . suffix . lstrip ( '.' )] . append ( path_file ) return file_lookup","title":"calcipy.doit_tasks.file_search"},{"location":"docs/modules/calcipy/doit_tasks/file_search/#calcipydoit_tasksfile_search","text":"Find Files. View Source \"\"\"Find Files.\"\"\" from collections import defaultdict from pathlib import Path from typing import Dict , List from beartype import beartype from loguru import logger from pre_commit.git import zsplit from pre_commit.util import cmd_output @beartype def _get_all_files ( * , cwd : Path ) -> List [ str ]: \"\"\"Get all files using git. Modified `pre_commit.git.get_all_files` to accept `cwd`. https://github.com/pre-commit/pre-commit/blob/488b1999f36cac62b6b0d9bc8eae99418ae5c226/pre_commit/git.py#L153 Args: cwd: current working directory to pass to `subprocess.Popen` Returns: List[str]: list of all file paths relative to the `cwd` \"\"\" return zsplit ( cmd_output ( 'git' , 'ls-files' , '-z' , cwd = cwd )[ 1 ]) # type: ignore[no-any-return] @beartype def _filter_files ( rel_filepaths : List [ str ], ignore_patterns : List [ str ]) -> List [ str ]: \"\"\"Filter a list of string file paths with specified ignore patterns in glob syntax. Args: rel_filepaths: list of string file paths ignore_patterns: glob ignore patterns Returns: List[str]: list of all non-ignored file path names \"\"\" if ignore_patterns : matches = [] for pth in map ( Path , rel_filepaths ): matches . extend ([ pth . as_posix () for pat in ignore_patterns if pth . match ( pat )][: 1 ]) return [ rel for rel in rel_filepaths if rel not in matches ] return rel_filepaths @beartype def find_project_files ( path_project : Path , ignore_patterns : List [ str ]) -> List [ Path ]: \"\"\"Find project files in git version control. > Note: uses the relative project directory and verifies that each file exists Args: path_project: Path to the project directory. Typically `DG.meta.path_project` ignore_patterns: glob ignore patterns Returns: Dict[str, List[Path]]: where keys are the suffix (without leading dot) and values the list of paths \"\"\" file_paths = [] rel_filepaths = _get_all_files ( cwd = path_project ) filtered_rel_files = _filter_files ( rel_filepaths = rel_filepaths , ignore_patterns = ignore_patterns ) for rel_file in filtered_rel_files : path_file = path_project / rel_file if path_file . is_file (): file_paths . append ( path_file ) else : # pragma: no cover logger . warning ( f 'Could not find { rel_file } in { path_project } ' ) return file_paths @beartype def find_project_files_by_suffix ( path_project : Path , ignore_patterns : List [ str ]) -> Dict [ str , List [ Path ]]: \"\"\"Find project files in git version control. > Note: uses the relative project directory and verifies that each file exists Args: path_project: Path to the project directory. Typically `DG.meta.path_project` ignore_patterns: glob ignore patterns Returns: Dict[str, List[Path]]: where keys are the suffix (without leading dot) and values the list of paths \"\"\" file_lookup = defaultdict ( list ) for path_file in find_project_files ( path_project , ignore_patterns ): file_lookup [ path_file . suffix . lstrip ( '.' )] . append ( path_file ) return file_lookup","title":"calcipy.doit_tasks.file_search"},{"location":"docs/modules/calcipy/doit_tasks/file_search/#functions","text":"","title":"Functions"},{"location":"docs/modules/calcipy/doit_tasks/file_search/#find_project_files","text":"def find_project_files ( path_project : pathlib . Path , ignore_patterns : List [ str ] ) -> List [ pathlib . Path ] Find project files in git version control. Note: uses the relative project directory and verifies that each file exists Parameters: Name Type Description Default path_project None Path to the project directory. Typically DG.meta.path_project None ignore_patterns None glob ignore patterns None Returns: Type Description Dict[str, List[Path]] where keys are the suffix (without leading dot) and values the list of paths View Source @beartype def find_project_files ( path_project : Path , ignore_patterns : List [ str ]) -> List [ Path ]: \"\"\"Find project files in git version control. > Note: uses the relative project directory and verifies that each file exists Args: path_project: Path to the project directory. Typically `DG.meta.path_project` ignore_patterns: glob ignore patterns Returns: Dict[str, List[Path]]: where keys are the suffix (without leading dot) and values the list of paths \"\"\" file_paths = [] rel_filepaths = _get_all_files ( cwd = path_project ) filtered_rel_files = _filter_files ( rel_filepaths = rel_filepaths , ignore_patterns = ignore_patterns ) for rel_file in filtered_rel_files : path_file = path_project / rel_file if path_file . is_file (): file_paths . append ( path_file ) else : # pragma: no cover logger . warning ( f 'Could not find { rel_file } in { path_project } ' ) return file_paths","title":"find_project_files"},{"location":"docs/modules/calcipy/doit_tasks/file_search/#find_project_files_by_suffix","text":"def find_project_files_by_suffix ( path_project : pathlib . Path , ignore_patterns : List [ str ] ) -> Dict [ str , List [ pathlib . Path ]] Find project files in git version control. Note: uses the relative project directory and verifies that each file exists Parameters: Name Type Description Default path_project None Path to the project directory. Typically DG.meta.path_project None ignore_patterns None glob ignore patterns None Returns: Type Description Dict[str, List[Path]] where keys are the suffix (without leading dot) and values the list of paths View Source @beartype def find_project_files_by_suffix ( path_project : Path , ignore_patterns : List [ str ]) -> Dict [ str , List [ Path ]]: \"\"\"Find project files in git version control. > Note: uses the relative project directory and verifies that each file exists Args: path_project: Path to the project directory. Typically `DG.meta.path_project` ignore_patterns: glob ignore patterns Returns: Dict[str, List[Path]]: where keys are the suffix (without leading dot) and values the list of paths \"\"\" file_lookup = defaultdict ( list ) for path_file in find_project_files ( path_project , ignore_patterns ): file_lookup [ path_file . suffix . lstrip ( '.' )] . append ( path_file ) return file_lookup","title":"find_project_files_by_suffix"},{"location":"docs/modules/calcipy/doit_tasks/lint/","text":"calcipy.doit_tasks.lint \u2693\ufe0e doit Linting Utilities. View Source \"\"\"doit Linting Utilities.\"\"\" from pathlib import Path from typing import Iterable , List from beartype import beartype from doit.tools import Interactive from ..file_helpers import if_found_unlink from .base import debug_task , echo from .doit_globals import DG , DoitAction , DoitTask # ---------------------------------------------------------------------------------------------------------------------- # Linting @beartype def _check_linting_errors ( flake8_log_path : Path , ignore_errors : Iterable [ str ] = ()) -> None : # noqa: CCR001 \"\"\"Check for errors reported in flake8 log file. Removes log file if no errors detected. Args: flake8_log_path: path to flake8 log file created with flag: `--output-file=flake8_log_path` ignore_errors: list of error codes to ignore (beyond the flake8 config settings). Default is None Raises: RuntimeError: if flake8 log file contains any text results \"\"\" flake8_full_path = flake8_log_path . parent / f ' { flake8_log_path . stem } -full { flake8_log_path . suffix } ' log_contents = flake8_log_path . read_text () . strip () review_info = f '. Review: { flake8_log_path } ' if ignore_errors : # Backup the full list of errors flake8_full_path . write_text ( log_contents ) # Exclude the errors specificed to be ignored by the user lines = log_contents . split ( ' \\n ' ) lines = [ line for line in lines if all ( f ': { error_code } ' in line for error_code in ignore_errors ) ] log_contents = ' \\n ' . join ( lines ) flake8_log_path . write_text ( log_contents ) review_info = ( f ' even when ignoring { ignore_errors } . \\n Review: { flake8_log_path } ' f ' \\n Note: the full list linting errors are reported in { flake8_full_path } ' ) else : if_found_unlink ( flake8_full_path ) # Raise an exception if any errors were found. Remove the files if not if len ( log_contents ) > 0 : raise RuntimeError ( f 'Found Linting Errors { review_info } ' ) if_found_unlink ( flake8_log_path ) @beartype def _lint_python ( lint_paths : List [ Path ], path_flake8 : Path , ignore_errors : Iterable [ str ] = (), ) -> List [ DoitAction ]: # FIXME: Docstrings should be reporting an error here for mismatch in types \"\"\"Lint specified files creating summary log file of errors. Args: lint_paths: list of file and directory paths to lint path_flake8: path to flake8 configuration file ignore_errors: list of error codes to ignore (beyond the flake8 config settings). Default is None Returns: DoitTask: doit task \"\"\" # Flake8 appends to the log file. Ensure that an existing file is deleted so that Flake8 creates a fresh file flake8_log_path = DG . meta . path_project / 'flake8.log' actions : List [ DoitAction ] = [( if_found_unlink , ( flake8_log_path ,))] run = 'poetry run python -m' flags = f '--config= { path_flake8 } --output-file= { flake8_log_path } --exit-zero' actions . append ( f ' { run } flake8 { flags } ' + ' ' . join ( f '\" { pth } \"' for pth in lint_paths )) actions . append (( _check_linting_errors , ( flake8_log_path , ignore_errors ))) return actions @beartype def _lint_non_python ( strict : bool = False ) -> List [ DoitAction ]: \"\"\"Lint non-Python files such as JSON and YML/YAML. Args: strict: if True, will use the strictest configuration for the linter Returns: List[DoitAction]: doit task \"\"\" strict_flag = '--strict' if strict else '' actions = [] paths_yaml = DG . meta . paths_by_suffix . get ( 'yml' , []) + DG . meta . paths_by_suffix . get ( 'yaml' , []) if paths_yaml : paths = ' ' . join ( f '\" { pth } \"' for pth in paths_yaml ) actions . append ( Interactive ( f 'poetry run yamllint { strict_flag } { paths } ' )) paths_json = DG . meta . paths_by_suffix . get ( 'json' , []) if paths_json : actions . extend ( Interactive ( f 'poetry run jsonlint { strict_flag } \" { pth } \"' ) for pth in paths_json ) return actions @beartype def task_lint_python () -> DoitTask : \"\"\"Lint all Python files and create summary of errors. Returns: DoitTask: doit task \"\"\" actions = _lint_python ( DG . lint . paths_py , path_flake8 = DG . lint . path_flake8 , ignore_errors = []) return debug_task ( actions ) @beartype def task_lint_project () -> DoitTask : \"\"\"Lint all project files that can be checked. Returns: DoitTask: doit task \"\"\" actions = _lint_python ( DG . lint . paths_py , path_flake8 = DG . lint . path_flake8 , ignore_errors = []) actions . extend ( _lint_non_python ( strict = True )) return debug_task ( actions ) @beartype def task_lint_critical_only () -> DoitTask : \"\"\"Suppress non-critical linting errors. Great for gating PRs/commits. Returns: DoitTask: doit task \"\"\" actions = _lint_python ( DG . lint . paths_py , path_flake8 = DG . lint . path_flake8 , ignore_errors = DG . lint . ignore_errors ) actions . extend ( _lint_non_python ()) return debug_task ( actions ) @beartype def task_radon_lint () -> DoitTask : \"\"\"Lint project with Radon. See documentation: https://radon.readthedocs.io/en/latest/intro.html Returns: DoitTask: doit task \"\"\" actions : List [ DoitAction ] = [] for args in [ 'mi' , 'cc --total-average -nb' , 'hal' ]: actions . append (( echo , ( f '# Radon with args: { args } ' ,))) actions . extend ([ f 'poetry run radon { args } \" { lint_path } \"' for lint_path in DG . lint . paths_py ]) return debug_task ( actions ) @beartype def task_security_checks () -> DoitTask : \"\"\"Use linting tools to identify possible security vulnerabilities. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run bandit -r { DG . meta . pkg_name } ' ), Interactive ( 'poetry run nox --session check_safety' ), ]) # ---------------------------------------------------------------------------------------------------------------------- # Formatting @beartype def task_auto_format () -> DoitTask : \"\"\"Format code with isort and autopep8. Other Useful Format Snippets: ```sh poetry run isort --recursive --check --diff calcipy/ tests/ ``` Returns: DoitTask: doit task \"\"\" run = 'poetry run python -m' paths = ' ' . join ( f '\" { pth } \"' for pth in DG . lint . paths_py ) return debug_task ([ f ' { run } autopep8 { paths } --in-place --aggressive' , f ' { run } isort { paths } --settings-path \" { DG . lint . path_isort } \"' , ]) # ---------------------------------------------------------------------------------------------------------------------- # General Static Analysis @beartype def task_pre_commit_hooks () -> DoitTask : \"\"\"Run the [pre-commit hooks](https://pre-commit.com/) on all files. > Note: use `git commit` or `git push` with `--no-verify` if needed Returns: DoitTask: doit task \"\"\" # Only use these two stages for all pre-commit hooks stages = [ 'commit-msg' , 'pre-push' ] return debug_task ([ Interactive ( 'poetry run pre-commit autoupdate' ), Interactive ( 'poetry run pre-commit install --install-hooks' + ' --hook-type ' . join ([ '' ] + stages )), Interactive ( 'poetry run pre-commit run --all-files --hook-stage push' ), ]) Functions \u2693\ufe0e task_auto_format \u2693\ufe0e def task_auto_format () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Format code with isort and autopep8. Other Useful Format Snippets: poetry run isort --recursive --check --diff calcipy/ tests/ Returns: Type Description DoitTask doit task View Source @beartype def task_auto_format () -> DoitTask : \"\"\"Format code with isort and autopep8. Other Useful Format Snippets: ```sh poetry run isort --recursive --check --diff calcipy/ tests/ ``` Returns: DoitTask: doit task \"\"\" run = 'poetry run python -m' paths = ' ' . join ( f '\" { pth } \"' for pth in DG . lint . paths_py ) return debug_task ([ f ' { run } autopep8 { paths } --in-place --aggressive' , f ' { run } isort { paths } --settings-path \" { DG . lint . path_isort } \"' , ]) task_lint_critical_only \u2693\ufe0e def task_lint_critical_only () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Suppress non-critical linting errors. Great for gating PRs/commits. Returns: Type Description DoitTask doit task View Source @beartype def task_lint_critical_only () -> DoitTask : \"\"\"Suppress non-critical linting errors. Great for gating PRs/commits. Returns: DoitTask: doit task \"\"\" actions = _lint_python ( DG . lint . paths_py , path_flake8 = DG . lint . path_flake8 , ignore_errors = DG . lint . ignore_errors ) actions . extend ( _lint_non_python ()) return debug_task ( actions ) task_lint_project \u2693\ufe0e def task_lint_project () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Lint all project files that can be checked. Returns: Type Description DoitTask doit task View Source @beartype def task_lint_project () -> DoitTask : \"\"\"Lint all project files that can be checked. Returns: DoitTask: doit task \"\"\" actions = _lint_python ( DG . lint . paths_py , path_flake8 = DG . lint . path_flake8 , ignore_errors = []) actions . extend ( _lint_non_python ( strict = True )) return debug_task ( actions ) task_lint_python \u2693\ufe0e def task_lint_python () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Lint all Python files and create summary of errors. Returns: Type Description DoitTask doit task View Source @beartype def task_lint_python () -> DoitTask : \"\"\"Lint all Python files and create summary of errors. Returns: DoitTask: doit task \"\"\" actions = _lint_python ( DG . lint . paths_py , path_flake8 = DG . lint . path_flake8 , ignore_errors = []) return debug_task ( actions ) task_pre_commit_hooks \u2693\ufe0e def task_pre_commit_hooks () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run the pre-commit hooks on all files. Note: use git commit or git push with --no-verify if needed Returns: Type Description DoitTask doit task View Source @beartype def task_pre_commit_hooks () -> DoitTask : \"\"\"Run the [pre-commit hooks](https://pre-commit.com/) on all files. > Note: use `git commit` or `git push` with `--no-verify` if needed Returns: DoitTask: doit task \"\"\" # Only use these two stages for all pre-commit hooks stages = [ 'commit-msg' , 'pre-push' ] return debug_task ([ Interactive ( 'poetry run pre-commit autoupdate' ), Interactive ( 'poetry run pre-commit install --install-hooks' + ' --hook-type ' . join ([ '' ] + stages )), Interactive ( 'poetry run pre-commit run --all-files --hook-stage push' ), ]) task_radon_lint \u2693\ufe0e def task_radon_lint () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Lint project with Radon. See documentation: https://radon.readthedocs.io/en/latest/intro.html Returns: Type Description DoitTask doit task View Source @beartype def task_radon_lint () -> DoitTask : \"\"\"Lint project with Radon. See documentation: https://radon.readthedocs.io/en/latest/intro.html Returns: DoitTask: doit task \"\"\" actions : List [ DoitAction ] = [] for args in [ 'mi' , 'cc --total-average -nb' , 'hal' ]: actions . append (( echo , ( f '# Radon with args: { args } ' ,))) actions . extend ([ f 'poetry run radon { args } \" { lint_path } \"' for lint_path in DG . lint . paths_py ]) return debug_task ( actions ) task_security_checks \u2693\ufe0e def task_security_checks () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Use linting tools to identify possible security vulnerabilities. Returns: Type Description DoitTask doit task View Source @beartype def task_security_checks () -> DoitTask : \"\"\"Use linting tools to identify possible security vulnerabilities. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run bandit -r { DG . meta . pkg_name } ' ), Interactive ( 'poetry run nox --session check_safety' ), ])","title":"calcipy.doit_tasks.lint"},{"location":"docs/modules/calcipy/doit_tasks/lint/#calcipydoit_taskslint","text":"doit Linting Utilities. View Source \"\"\"doit Linting Utilities.\"\"\" from pathlib import Path from typing import Iterable , List from beartype import beartype from doit.tools import Interactive from ..file_helpers import if_found_unlink from .base import debug_task , echo from .doit_globals import DG , DoitAction , DoitTask # ---------------------------------------------------------------------------------------------------------------------- # Linting @beartype def _check_linting_errors ( flake8_log_path : Path , ignore_errors : Iterable [ str ] = ()) -> None : # noqa: CCR001 \"\"\"Check for errors reported in flake8 log file. Removes log file if no errors detected. Args: flake8_log_path: path to flake8 log file created with flag: `--output-file=flake8_log_path` ignore_errors: list of error codes to ignore (beyond the flake8 config settings). Default is None Raises: RuntimeError: if flake8 log file contains any text results \"\"\" flake8_full_path = flake8_log_path . parent / f ' { flake8_log_path . stem } -full { flake8_log_path . suffix } ' log_contents = flake8_log_path . read_text () . strip () review_info = f '. Review: { flake8_log_path } ' if ignore_errors : # Backup the full list of errors flake8_full_path . write_text ( log_contents ) # Exclude the errors specificed to be ignored by the user lines = log_contents . split ( ' \\n ' ) lines = [ line for line in lines if all ( f ': { error_code } ' in line for error_code in ignore_errors ) ] log_contents = ' \\n ' . join ( lines ) flake8_log_path . write_text ( log_contents ) review_info = ( f ' even when ignoring { ignore_errors } . \\n Review: { flake8_log_path } ' f ' \\n Note: the full list linting errors are reported in { flake8_full_path } ' ) else : if_found_unlink ( flake8_full_path ) # Raise an exception if any errors were found. Remove the files if not if len ( log_contents ) > 0 : raise RuntimeError ( f 'Found Linting Errors { review_info } ' ) if_found_unlink ( flake8_log_path ) @beartype def _lint_python ( lint_paths : List [ Path ], path_flake8 : Path , ignore_errors : Iterable [ str ] = (), ) -> List [ DoitAction ]: # FIXME: Docstrings should be reporting an error here for mismatch in types \"\"\"Lint specified files creating summary log file of errors. Args: lint_paths: list of file and directory paths to lint path_flake8: path to flake8 configuration file ignore_errors: list of error codes to ignore (beyond the flake8 config settings). Default is None Returns: DoitTask: doit task \"\"\" # Flake8 appends to the log file. Ensure that an existing file is deleted so that Flake8 creates a fresh file flake8_log_path = DG . meta . path_project / 'flake8.log' actions : List [ DoitAction ] = [( if_found_unlink , ( flake8_log_path ,))] run = 'poetry run python -m' flags = f '--config= { path_flake8 } --output-file= { flake8_log_path } --exit-zero' actions . append ( f ' { run } flake8 { flags } ' + ' ' . join ( f '\" { pth } \"' for pth in lint_paths )) actions . append (( _check_linting_errors , ( flake8_log_path , ignore_errors ))) return actions @beartype def _lint_non_python ( strict : bool = False ) -> List [ DoitAction ]: \"\"\"Lint non-Python files such as JSON and YML/YAML. Args: strict: if True, will use the strictest configuration for the linter Returns: List[DoitAction]: doit task \"\"\" strict_flag = '--strict' if strict else '' actions = [] paths_yaml = DG . meta . paths_by_suffix . get ( 'yml' , []) + DG . meta . paths_by_suffix . get ( 'yaml' , []) if paths_yaml : paths = ' ' . join ( f '\" { pth } \"' for pth in paths_yaml ) actions . append ( Interactive ( f 'poetry run yamllint { strict_flag } { paths } ' )) paths_json = DG . meta . paths_by_suffix . get ( 'json' , []) if paths_json : actions . extend ( Interactive ( f 'poetry run jsonlint { strict_flag } \" { pth } \"' ) for pth in paths_json ) return actions @beartype def task_lint_python () -> DoitTask : \"\"\"Lint all Python files and create summary of errors. Returns: DoitTask: doit task \"\"\" actions = _lint_python ( DG . lint . paths_py , path_flake8 = DG . lint . path_flake8 , ignore_errors = []) return debug_task ( actions ) @beartype def task_lint_project () -> DoitTask : \"\"\"Lint all project files that can be checked. Returns: DoitTask: doit task \"\"\" actions = _lint_python ( DG . lint . paths_py , path_flake8 = DG . lint . path_flake8 , ignore_errors = []) actions . extend ( _lint_non_python ( strict = True )) return debug_task ( actions ) @beartype def task_lint_critical_only () -> DoitTask : \"\"\"Suppress non-critical linting errors. Great for gating PRs/commits. Returns: DoitTask: doit task \"\"\" actions = _lint_python ( DG . lint . paths_py , path_flake8 = DG . lint . path_flake8 , ignore_errors = DG . lint . ignore_errors ) actions . extend ( _lint_non_python ()) return debug_task ( actions ) @beartype def task_radon_lint () -> DoitTask : \"\"\"Lint project with Radon. See documentation: https://radon.readthedocs.io/en/latest/intro.html Returns: DoitTask: doit task \"\"\" actions : List [ DoitAction ] = [] for args in [ 'mi' , 'cc --total-average -nb' , 'hal' ]: actions . append (( echo , ( f '# Radon with args: { args } ' ,))) actions . extend ([ f 'poetry run radon { args } \" { lint_path } \"' for lint_path in DG . lint . paths_py ]) return debug_task ( actions ) @beartype def task_security_checks () -> DoitTask : \"\"\"Use linting tools to identify possible security vulnerabilities. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run bandit -r { DG . meta . pkg_name } ' ), Interactive ( 'poetry run nox --session check_safety' ), ]) # ---------------------------------------------------------------------------------------------------------------------- # Formatting @beartype def task_auto_format () -> DoitTask : \"\"\"Format code with isort and autopep8. Other Useful Format Snippets: ```sh poetry run isort --recursive --check --diff calcipy/ tests/ ``` Returns: DoitTask: doit task \"\"\" run = 'poetry run python -m' paths = ' ' . join ( f '\" { pth } \"' for pth in DG . lint . paths_py ) return debug_task ([ f ' { run } autopep8 { paths } --in-place --aggressive' , f ' { run } isort { paths } --settings-path \" { DG . lint . path_isort } \"' , ]) # ---------------------------------------------------------------------------------------------------------------------- # General Static Analysis @beartype def task_pre_commit_hooks () -> DoitTask : \"\"\"Run the [pre-commit hooks](https://pre-commit.com/) on all files. > Note: use `git commit` or `git push` with `--no-verify` if needed Returns: DoitTask: doit task \"\"\" # Only use these two stages for all pre-commit hooks stages = [ 'commit-msg' , 'pre-push' ] return debug_task ([ Interactive ( 'poetry run pre-commit autoupdate' ), Interactive ( 'poetry run pre-commit install --install-hooks' + ' --hook-type ' . join ([ '' ] + stages )), Interactive ( 'poetry run pre-commit run --all-files --hook-stage push' ), ])","title":"calcipy.doit_tasks.lint"},{"location":"docs/modules/calcipy/doit_tasks/lint/#functions","text":"","title":"Functions"},{"location":"docs/modules/calcipy/doit_tasks/lint/#task_auto_format","text":"def task_auto_format () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Format code with isort and autopep8. Other Useful Format Snippets: poetry run isort --recursive --check --diff calcipy/ tests/ Returns: Type Description DoitTask doit task View Source @beartype def task_auto_format () -> DoitTask : \"\"\"Format code with isort and autopep8. Other Useful Format Snippets: ```sh poetry run isort --recursive --check --diff calcipy/ tests/ ``` Returns: DoitTask: doit task \"\"\" run = 'poetry run python -m' paths = ' ' . join ( f '\" { pth } \"' for pth in DG . lint . paths_py ) return debug_task ([ f ' { run } autopep8 { paths } --in-place --aggressive' , f ' { run } isort { paths } --settings-path \" { DG . lint . path_isort } \"' , ])","title":"task_auto_format"},{"location":"docs/modules/calcipy/doit_tasks/lint/#task_lint_critical_only","text":"def task_lint_critical_only () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Suppress non-critical linting errors. Great for gating PRs/commits. Returns: Type Description DoitTask doit task View Source @beartype def task_lint_critical_only () -> DoitTask : \"\"\"Suppress non-critical linting errors. Great for gating PRs/commits. Returns: DoitTask: doit task \"\"\" actions = _lint_python ( DG . lint . paths_py , path_flake8 = DG . lint . path_flake8 , ignore_errors = DG . lint . ignore_errors ) actions . extend ( _lint_non_python ()) return debug_task ( actions )","title":"task_lint_critical_only"},{"location":"docs/modules/calcipy/doit_tasks/lint/#task_lint_project","text":"def task_lint_project () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Lint all project files that can be checked. Returns: Type Description DoitTask doit task View Source @beartype def task_lint_project () -> DoitTask : \"\"\"Lint all project files that can be checked. Returns: DoitTask: doit task \"\"\" actions = _lint_python ( DG . lint . paths_py , path_flake8 = DG . lint . path_flake8 , ignore_errors = []) actions . extend ( _lint_non_python ( strict = True )) return debug_task ( actions )","title":"task_lint_project"},{"location":"docs/modules/calcipy/doit_tasks/lint/#task_lint_python","text":"def task_lint_python () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Lint all Python files and create summary of errors. Returns: Type Description DoitTask doit task View Source @beartype def task_lint_python () -> DoitTask : \"\"\"Lint all Python files and create summary of errors. Returns: DoitTask: doit task \"\"\" actions = _lint_python ( DG . lint . paths_py , path_flake8 = DG . lint . path_flake8 , ignore_errors = []) return debug_task ( actions )","title":"task_lint_python"},{"location":"docs/modules/calcipy/doit_tasks/lint/#task_pre_commit_hooks","text":"def task_pre_commit_hooks () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run the pre-commit hooks on all files. Note: use git commit or git push with --no-verify if needed Returns: Type Description DoitTask doit task View Source @beartype def task_pre_commit_hooks () -> DoitTask : \"\"\"Run the [pre-commit hooks](https://pre-commit.com/) on all files. > Note: use `git commit` or `git push` with `--no-verify` if needed Returns: DoitTask: doit task \"\"\" # Only use these two stages for all pre-commit hooks stages = [ 'commit-msg' , 'pre-push' ] return debug_task ([ Interactive ( 'poetry run pre-commit autoupdate' ), Interactive ( 'poetry run pre-commit install --install-hooks' + ' --hook-type ' . join ([ '' ] + stages )), Interactive ( 'poetry run pre-commit run --all-files --hook-stage push' ), ])","title":"task_pre_commit_hooks"},{"location":"docs/modules/calcipy/doit_tasks/lint/#task_radon_lint","text":"def task_radon_lint () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Lint project with Radon. See documentation: https://radon.readthedocs.io/en/latest/intro.html Returns: Type Description DoitTask doit task View Source @beartype def task_radon_lint () -> DoitTask : \"\"\"Lint project with Radon. See documentation: https://radon.readthedocs.io/en/latest/intro.html Returns: DoitTask: doit task \"\"\" actions : List [ DoitAction ] = [] for args in [ 'mi' , 'cc --total-average -nb' , 'hal' ]: actions . append (( echo , ( f '# Radon with args: { args } ' ,))) actions . extend ([ f 'poetry run radon { args } \" { lint_path } \"' for lint_path in DG . lint . paths_py ]) return debug_task ( actions )","title":"task_radon_lint"},{"location":"docs/modules/calcipy/doit_tasks/lint/#task_security_checks","text":"def task_security_checks () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Use linting tools to identify possible security vulnerabilities. Returns: Type Description DoitTask doit task View Source @beartype def task_security_checks () -> DoitTask : \"\"\"Use linting tools to identify possible security vulnerabilities. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run bandit -r { DG . meta . pkg_name } ' ), Interactive ( 'poetry run nox --session check_safety' ), ])","title":"task_security_checks"},{"location":"docs/modules/calcipy/doit_tasks/packaging/","text":"calcipy.doit_tasks.packaging \u2693\ufe0e doit Packaging Utilities. View Source \"\"\"doit Packaging Utilities.\"\"\" import json from pathlib import Path from typing import Dict , List , Optional import attr import pendulum import requests import toml from beartype import beartype from doit.tools import Interactive from loguru import logger from pendulum import DateTime from pyrate_limiter import Duration , Limiter , RequestRate from .base import debug_task from .doit_globals import DG , DoitTask # ---------------------------------------------------------------------------------------------------------------------- # Publish releases @beartype def task_check_license () -> DoitTask : \"\"\"Check licenses for compatibility. Returns: DoitTask: doit task \"\"\" return debug_task ([ 'poetry run licensecheck --zero' ]) @beartype def task_lock () -> DoitTask : \"\"\"Lock dependencies. Returns: DoitTask: doit task \"\"\" path_req = DG . meta . path_project / 'requirements.txt' # Ensure that extras are exported as well toml_data = toml . loads ( DG . meta . path_toml . read_text ()) extras = [ * toml_data [ 'tool' ][ 'poetry' ] . get ( 'extras' , {}) . keys ()] extras_arg = ' -E ' . join ([ '' ] + extras ) if extras else '' task = debug_task ([ 'poetry lock' , f 'poetry export -f { path_req . name } -o { path_req . name }{ extras_arg } --dev' , ]) task [ 'file_dep' ] . append ( DG . meta . path_toml ) task [ 'targets' ] . extend ([ DG . meta . path_project / 'poetry.lock' , path_req ]) return task @beartype def _publish_task ( publish_args : str = '' ) -> DoitTask : \"\"\"Create the task with specified options for building and publishing. Args: publish_args: optional string arguments to pass to `poetry publish` Returns: DoitTask: doit task \"\"\" # See guide on publishing # https://github.com/KyleKing/calcipy/blob/dev/development/docs/DEVELOPER_GUIDE.md#publishing return debug_task ([ Interactive ( 'poetry run nox --session build_dist build_check' ), f 'poetry publish { publish_args } ' , ]) @beartype def task_publish () -> DoitTask : \"\"\"Build the distributable format(s) and publish. > See the Developer Guide for configuring pypi token > Use in conjunction with `task_cl_bump` Returns: DoitTask: doit task \"\"\" return _publish_task () @beartype def task_publish_test_pypi () -> DoitTask : \"\"\"Build the distributable format(s) and publish to the TestPyPi repository. Returns: DoitTask: doit task \"\"\" return _publish_task ( '--repository testpypi' ) # ---------------------------------------------------------------------------------------------------------------------- # Check for stale packages def _auto_convert ( cls , fields ): # type: ignore # noqa: ANN001, ANN202, CCR001 \"\"\"Auto convert datetime attributes from string. https://www.attrs.org/en/stable/extending.html#automatic-field-transformation-and-modification Args: cls: type? fields: `_HostedPythonPackageAttribtues` Returns: results \"\"\" results = [] for field in fields : if field . converter is not None : # pragma: no cover results . append ( field ) continue converter : Optional [ DateTime ] = None if field . type in { Optional [ DateTime ], DateTime , 'datetime' }: converter = ( lambda d : pendulum . parse ( d ) if isinstance ( d , str ) else d ) results . append ( field . evolve ( converter = converter )) return results @attr . s ( auto_attribs = True , kw_only = True , field_transformer = _auto_convert ) class _HostedPythonPackage (): # noqa: H601 \"\"\"Representative information for a python package hosted on some domain.\"\"\" domain : str = 'https://pypi.org/pypi/ {name} / {version} /json' name : str version : str datetime : Optional [ DateTime ] = None latest_version : str = '' latest_datetime : Optional [ DateTime ] = None _PATH_PACK_LOCK = DG . meta . path_project / '.calcipy_packaging.lock' \"\"\"Path to the packaging lock file.\"\"\" # PLANNED: Check that this prevent excess requests to PyPi and refactor # https://pypi.org/project/pyrate-limiter/ # https://learn.vonage.com/blog/2020/10/22/respect-api-rate-limits-with-a-backoff-dr/ rate = RequestRate ( 3 , 5 * Duration . SECOND ) limiter = Limiter ( rate ) item = 'pypi' @beartype @limiter . ratelimit ( item , delay = True , max_delay = 10 ) def _get_release_date ( package : _HostedPythonPackage ) -> _HostedPythonPackage : \"\"\"Retrieve release date metadata for the specified package. Args: package: `_HostedPythonPackage` Returns: _HostedPythonPackage: updated with release date metadata from API \"\"\" # Retrieve the JSON summary for the specified package json_url = package . domain . format ( name = package . name , version = package . version ) res = requests . get ( json_url ) releases = res . json ()[ 'releases' ] package . datetime = pendulum . parse ( releases [ package . version ][ 0 ][ 'upload_time_iso_8601' ]) # Also retrieve the latest release date of the package looking through all releases release_dates = { pendulum . parse ( release_data [ 0 ][ 'upload_time_iso_8601' ]): version for version , release_data in releases . items () if release_data and release_data [ 0 ] . get ( 'upload_time_iso_8601' ) } package . latest_datetime = max ([ * release_dates . keys ()]) package . latest_version = release_dates [ package . latest_datetime ] return package @beartype def _read_cache ( path_pack_lock : Path = _PATH_PACK_LOCK ) -> Dict [ str , _HostedPythonPackage ]: \"\"\"Read the cached packaging information. Args: path_pack_lock: Path to the lock file. Default is `_PATH_PACK_LOCK` Returns: Dict[str, _HostedPythonPackage]: the cached packages \"\"\" if not path_pack_lock . is_file (): path_pack_lock . write_text ( ' {} ' ) # noqa: P103 old_cache : Dict [ str , Dict [ str , str ]] = json . loads ( path_pack_lock . read_text ()) return { package_name : _HostedPythonPackage ( ** meta_data ) for package_name , meta_data in old_cache . items () } @beartype def _collect_release_dates ( packages : List [ _HostedPythonPackage ], old_cache : Optional [ Dict [ str , _HostedPythonPackage ]] = None , ) -> List [ _HostedPythonPackage ]: \"\"\"Use the cache to retrieve only metadata that needs to be updated. Args: packages: list of `_HostedPythonPackage` old_cache: cache data to compare against to limit network requests Returns: List[_HostedPythonPackage]: packages with updated release dates \"\"\" if old_cache is None : old_cache = {} updated_packages = [] for package in packages : cached_package = old_cache . get ( package . name ) cached_version = '' if cached_package is None else cached_package . version if package . version != cached_version : package = _get_release_date ( package ) else : package = cached_package updated_packages . append ( package ) return updated_packages @beartype def _write_cache ( updated_packages : List [ _HostedPythonPackage ], path_pack_lock : Path = _PATH_PACK_LOCK ) -> None : \"\"\"Read the cached packaging information. Args: updated_packages: updated packages to store path_pack_lock: Path to the lock file. Default is `_PATH_PACK_LOCK` \"\"\" def serialize ( inst , field , value ): # noqa: ANN001, ANN201 if isinstance ( value , DateTime ): return value . to_iso8601_string () return value new_cache = { pack . name : attr . asdict ( pack , value_serializer = serialize ) for pack in updated_packages } pretty_json = json . dumps ( new_cache , indent = 4 , separators = ( ',' , ': ' ), sort_keys = True ) path_pack_lock . write_text ( pretty_json + ' \\n ' ) @beartype def _read_packages ( path_lock : Path ) -> List [ _HostedPythonPackage ]: \"\"\"Read packages from lock file. Currently only support `poetry.lock`, but could support more in the future. Args: path_lock: Path to the lock file to parse Returns: List[_HostedPythonPackage]: packages found in the lock file Raises: NotImplementedError: if a lock file other that the poetry lock file is used \"\"\" if path_lock . name != 'poetry.lock' : raise NotImplementedError ( f ' { path_lock . name } is not a currently supported lock type. Try \"poetry.lock\" instead' ) lock = toml . loads ( path_lock . read_text ()) # TBD: Handle non-pypi domains and format the URL accordingly (i.e. TestPyPi, etc.) # > domain=dependency['source']['url'] + '{name}/{version}/json' return [ _HostedPythonPackage ( name = dependency [ 'name' ], version = dependency [ 'version' ], ) for dependency in lock [ 'package' ] ] @beartype def _check_for_stale_packages ( packages : List [ _HostedPythonPackage ], * , stale_months : int ) -> None : \"\"\"Check for stale packages. Raise error and log all stale versions found. Args: packages: List of packages stale_months: cutoff in months for when a package might be stale enough to be a risk \"\"\" def format_package ( pack : _HostedPythonPackage ) -> str : delta = f ' { now . diff ( pack . datetime ) . in_months () } months ago:' latest = '' if pack . version == pack . latest_version else f ' (*New version available: { pack . latest_version } *)' return f '- { delta } { pack . name } { pack . version }{ latest } ' now = pendulum . now () stale_cutoff = now . subtract ( months = stale_months ) stale_packages = [ pack for pack in packages if pack . datetime < stale_cutoff ] if stale_packages : stale_list = ' \\n ' . join ( map ( format_package , sorted ( stale_packages , key = lambda x : x . datetime ))) logger . warning ( f 'Found stale packages that may be a dependency risk: \\n\\n { stale_list } \\n\\n ' ) @beartype def find_stale_packages ( path_lock : Path , path_pack_lock : Path = _PATH_PACK_LOCK , * , stale_months : int = 48 , ) -> None : \"\"\"Read the cached packaging information. Args: path_lock: Path to the lock file to parse path_pack_lock: Path to the lock file. Default is `_PATH_PACK_LOCK` stale_months: cutoff in months for when a package might be stale enough to be a risk. Default is 48 \"\"\" packages = _read_packages ( path_lock ) old_cache = _read_cache ( path_pack_lock ) updated_packages = _collect_release_dates ( packages , old_cache ) _write_cache ( updated_packages , path_pack_lock ) _check_for_stale_packages ( updated_packages , stale_months = stale_months ) @beartype def task_check_for_stale_packages () -> DoitTask : \"\"\"Check for stale packages. Returns: DoitTask: doit task \"\"\" path_lock = DG . meta . path_project / 'poetry.lock' path_pack_lock = _PATH_PACK_LOCK task = debug_task ([ ( find_stale_packages , ( path_lock , path_pack_lock ), { 'stale_months' : 48 }), Interactive ( 'poetry run pip list --outdated' ), ]) task [ 'file_dep' ] . append ( path_lock ) task [ 'targets' ] . append ( path_pack_lock ) return task Variables \u2693\ufe0e item limiter rate Functions \u2693\ufe0e find_stale_packages \u2693\ufe0e def find_stale_packages ( path_lock : pathlib . Path , path_pack_lock : pathlib . Path = PosixPath ( '/Users/kyleking/Developer/Werk/__LocalProjects/calcipy/.calcipy_packaging.lock' ), * , stale_months : int = 48 ) -> None Read the cached packaging information. Parameters: Name Type Description Default path_lock None Path to the lock file to parse None path_pack_lock None Path to the lock file. Default is _PATH_PACK_LOCK None stale_months None cutoff in months for when a package might be stale enough to be a risk. Default is 48 None View Source @beartype def find_stale_packages ( path_lock : Path , path_pack_lock : Path = _PATH_PACK_LOCK , * , stale_months : int = 48 , ) -> None : \"\"\"Read the cached packaging information. Args: path_lock: Path to the lock file to parse path_pack_lock: Path to the lock file. Default is `_PATH_PACK_LOCK` stale_months: cutoff in months for when a package might be stale enough to be a risk. Default is 48 \"\"\" packages = _read_packages ( path_lock ) old_cache = _read_cache ( path_pack_lock ) updated_packages = _collect_release_dates ( packages , old_cache ) _write_cache ( updated_packages , path_pack_lock ) _check_for_stale_packages ( updated_packages , stale_months = stale_months ) task_check_for_stale_packages \u2693\ufe0e def task_check_for_stale_packages () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Check for stale packages. Returns: Type Description DoitTask doit task View Source @beartype def task_check_for_stale_packages () -> DoitTask : \"\"\"Check for stale packages. Returns: DoitTask: doit task \"\"\" path_lock = DG . meta . path_project / 'poetry.lock' path_pack_lock = _PATH_PACK_LOCK task = debug_task ([ ( find_stale_packages , ( path_lock , path_pack_lock ), { 'stale_months' : 48 }), Interactive ( 'poetry run pip list --outdated' ), ]) task [ 'file_dep' ] . append ( path_lock ) task [ 'targets' ] . append ( path_pack_lock ) return task task_check_license \u2693\ufe0e def task_check_license () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Check licenses for compatibility. Returns: Type Description DoitTask doit task View Source @beartype def task_check_license () -> DoitTask : \"\"\"Check licenses for compatibility. Returns: DoitTask: doit task \"\"\" return debug_task ([ 'poetry run licensecheck --zero' ]) task_lock \u2693\ufe0e def task_lock () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Lock dependencies. Returns: Type Description DoitTask doit task View Source @beartype def task_lock () -> DoitTask : \"\"\"Lock dependencies. Returns: DoitTask: doit task \"\"\" path_req = DG . meta . path_project / 'requirements.txt' # Ensure that extras are exported as well toml_data = toml . loads ( DG . meta . path_toml . read_text ()) extras = [ * toml_data [ 'tool' ][ 'poetry' ] . get ( 'extras' , {}) . keys ()] extras_arg = ' -E ' . join ([ '' ] + extras ) if extras else '' task = debug_task ([ 'poetry lock' , f 'poetry export -f { path_req . name } -o { path_req . name }{ extras_arg } --dev' , ]) task [ 'file_dep' ] . append ( DG . meta . path_toml ) task [ 'targets' ] . extend ([ DG . meta . path_project / 'poetry.lock' , path_req ]) return task task_publish \u2693\ufe0e def task_publish () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Build the distributable format(s) and publish. See the Developer Guide for configuring pypi token Use in conjunction with task_cl_bump Returns: Type Description DoitTask doit task View Source @beartype def task_publish () -> DoitTask : \"\"\"Build the distributable format(s) and publish. > See the Developer Guide for configuring pypi token > Use in conjunction with `task_cl_bump` Returns: DoitTask: doit task \"\"\" return _publish_task () task_publish_test_pypi \u2693\ufe0e def task_publish_test_pypi () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Build the distributable format(s) and publish to the TestPyPi repository. Returns: Type Description DoitTask doit task View Source @beartype def task_publish_test_pypi () -> DoitTask : \"\"\"Build the distributable format(s) and publish to the TestPyPi repository. Returns: DoitTask: doit task \"\"\" return _publish_task ( '--repository testpypi' )","title":"calcipy.doit_tasks.packaging"},{"location":"docs/modules/calcipy/doit_tasks/packaging/#calcipydoit_taskspackaging","text":"doit Packaging Utilities. View Source \"\"\"doit Packaging Utilities.\"\"\" import json from pathlib import Path from typing import Dict , List , Optional import attr import pendulum import requests import toml from beartype import beartype from doit.tools import Interactive from loguru import logger from pendulum import DateTime from pyrate_limiter import Duration , Limiter , RequestRate from .base import debug_task from .doit_globals import DG , DoitTask # ---------------------------------------------------------------------------------------------------------------------- # Publish releases @beartype def task_check_license () -> DoitTask : \"\"\"Check licenses for compatibility. Returns: DoitTask: doit task \"\"\" return debug_task ([ 'poetry run licensecheck --zero' ]) @beartype def task_lock () -> DoitTask : \"\"\"Lock dependencies. Returns: DoitTask: doit task \"\"\" path_req = DG . meta . path_project / 'requirements.txt' # Ensure that extras are exported as well toml_data = toml . loads ( DG . meta . path_toml . read_text ()) extras = [ * toml_data [ 'tool' ][ 'poetry' ] . get ( 'extras' , {}) . keys ()] extras_arg = ' -E ' . join ([ '' ] + extras ) if extras else '' task = debug_task ([ 'poetry lock' , f 'poetry export -f { path_req . name } -o { path_req . name }{ extras_arg } --dev' , ]) task [ 'file_dep' ] . append ( DG . meta . path_toml ) task [ 'targets' ] . extend ([ DG . meta . path_project / 'poetry.lock' , path_req ]) return task @beartype def _publish_task ( publish_args : str = '' ) -> DoitTask : \"\"\"Create the task with specified options for building and publishing. Args: publish_args: optional string arguments to pass to `poetry publish` Returns: DoitTask: doit task \"\"\" # See guide on publishing # https://github.com/KyleKing/calcipy/blob/dev/development/docs/DEVELOPER_GUIDE.md#publishing return debug_task ([ Interactive ( 'poetry run nox --session build_dist build_check' ), f 'poetry publish { publish_args } ' , ]) @beartype def task_publish () -> DoitTask : \"\"\"Build the distributable format(s) and publish. > See the Developer Guide for configuring pypi token > Use in conjunction with `task_cl_bump` Returns: DoitTask: doit task \"\"\" return _publish_task () @beartype def task_publish_test_pypi () -> DoitTask : \"\"\"Build the distributable format(s) and publish to the TestPyPi repository. Returns: DoitTask: doit task \"\"\" return _publish_task ( '--repository testpypi' ) # ---------------------------------------------------------------------------------------------------------------------- # Check for stale packages def _auto_convert ( cls , fields ): # type: ignore # noqa: ANN001, ANN202, CCR001 \"\"\"Auto convert datetime attributes from string. https://www.attrs.org/en/stable/extending.html#automatic-field-transformation-and-modification Args: cls: type? fields: `_HostedPythonPackageAttribtues` Returns: results \"\"\" results = [] for field in fields : if field . converter is not None : # pragma: no cover results . append ( field ) continue converter : Optional [ DateTime ] = None if field . type in { Optional [ DateTime ], DateTime , 'datetime' }: converter = ( lambda d : pendulum . parse ( d ) if isinstance ( d , str ) else d ) results . append ( field . evolve ( converter = converter )) return results @attr . s ( auto_attribs = True , kw_only = True , field_transformer = _auto_convert ) class _HostedPythonPackage (): # noqa: H601 \"\"\"Representative information for a python package hosted on some domain.\"\"\" domain : str = 'https://pypi.org/pypi/ {name} / {version} /json' name : str version : str datetime : Optional [ DateTime ] = None latest_version : str = '' latest_datetime : Optional [ DateTime ] = None _PATH_PACK_LOCK = DG . meta . path_project / '.calcipy_packaging.lock' \"\"\"Path to the packaging lock file.\"\"\" # PLANNED: Check that this prevent excess requests to PyPi and refactor # https://pypi.org/project/pyrate-limiter/ # https://learn.vonage.com/blog/2020/10/22/respect-api-rate-limits-with-a-backoff-dr/ rate = RequestRate ( 3 , 5 * Duration . SECOND ) limiter = Limiter ( rate ) item = 'pypi' @beartype @limiter . ratelimit ( item , delay = True , max_delay = 10 ) def _get_release_date ( package : _HostedPythonPackage ) -> _HostedPythonPackage : \"\"\"Retrieve release date metadata for the specified package. Args: package: `_HostedPythonPackage` Returns: _HostedPythonPackage: updated with release date metadata from API \"\"\" # Retrieve the JSON summary for the specified package json_url = package . domain . format ( name = package . name , version = package . version ) res = requests . get ( json_url ) releases = res . json ()[ 'releases' ] package . datetime = pendulum . parse ( releases [ package . version ][ 0 ][ 'upload_time_iso_8601' ]) # Also retrieve the latest release date of the package looking through all releases release_dates = { pendulum . parse ( release_data [ 0 ][ 'upload_time_iso_8601' ]): version for version , release_data in releases . items () if release_data and release_data [ 0 ] . get ( 'upload_time_iso_8601' ) } package . latest_datetime = max ([ * release_dates . keys ()]) package . latest_version = release_dates [ package . latest_datetime ] return package @beartype def _read_cache ( path_pack_lock : Path = _PATH_PACK_LOCK ) -> Dict [ str , _HostedPythonPackage ]: \"\"\"Read the cached packaging information. Args: path_pack_lock: Path to the lock file. Default is `_PATH_PACK_LOCK` Returns: Dict[str, _HostedPythonPackage]: the cached packages \"\"\" if not path_pack_lock . is_file (): path_pack_lock . write_text ( ' {} ' ) # noqa: P103 old_cache : Dict [ str , Dict [ str , str ]] = json . loads ( path_pack_lock . read_text ()) return { package_name : _HostedPythonPackage ( ** meta_data ) for package_name , meta_data in old_cache . items () } @beartype def _collect_release_dates ( packages : List [ _HostedPythonPackage ], old_cache : Optional [ Dict [ str , _HostedPythonPackage ]] = None , ) -> List [ _HostedPythonPackage ]: \"\"\"Use the cache to retrieve only metadata that needs to be updated. Args: packages: list of `_HostedPythonPackage` old_cache: cache data to compare against to limit network requests Returns: List[_HostedPythonPackage]: packages with updated release dates \"\"\" if old_cache is None : old_cache = {} updated_packages = [] for package in packages : cached_package = old_cache . get ( package . name ) cached_version = '' if cached_package is None else cached_package . version if package . version != cached_version : package = _get_release_date ( package ) else : package = cached_package updated_packages . append ( package ) return updated_packages @beartype def _write_cache ( updated_packages : List [ _HostedPythonPackage ], path_pack_lock : Path = _PATH_PACK_LOCK ) -> None : \"\"\"Read the cached packaging information. Args: updated_packages: updated packages to store path_pack_lock: Path to the lock file. Default is `_PATH_PACK_LOCK` \"\"\" def serialize ( inst , field , value ): # noqa: ANN001, ANN201 if isinstance ( value , DateTime ): return value . to_iso8601_string () return value new_cache = { pack . name : attr . asdict ( pack , value_serializer = serialize ) for pack in updated_packages } pretty_json = json . dumps ( new_cache , indent = 4 , separators = ( ',' , ': ' ), sort_keys = True ) path_pack_lock . write_text ( pretty_json + ' \\n ' ) @beartype def _read_packages ( path_lock : Path ) -> List [ _HostedPythonPackage ]: \"\"\"Read packages from lock file. Currently only support `poetry.lock`, but could support more in the future. Args: path_lock: Path to the lock file to parse Returns: List[_HostedPythonPackage]: packages found in the lock file Raises: NotImplementedError: if a lock file other that the poetry lock file is used \"\"\" if path_lock . name != 'poetry.lock' : raise NotImplementedError ( f ' { path_lock . name } is not a currently supported lock type. Try \"poetry.lock\" instead' ) lock = toml . loads ( path_lock . read_text ()) # TBD: Handle non-pypi domains and format the URL accordingly (i.e. TestPyPi, etc.) # > domain=dependency['source']['url'] + '{name}/{version}/json' return [ _HostedPythonPackage ( name = dependency [ 'name' ], version = dependency [ 'version' ], ) for dependency in lock [ 'package' ] ] @beartype def _check_for_stale_packages ( packages : List [ _HostedPythonPackage ], * , stale_months : int ) -> None : \"\"\"Check for stale packages. Raise error and log all stale versions found. Args: packages: List of packages stale_months: cutoff in months for when a package might be stale enough to be a risk \"\"\" def format_package ( pack : _HostedPythonPackage ) -> str : delta = f ' { now . diff ( pack . datetime ) . in_months () } months ago:' latest = '' if pack . version == pack . latest_version else f ' (*New version available: { pack . latest_version } *)' return f '- { delta } { pack . name } { pack . version }{ latest } ' now = pendulum . now () stale_cutoff = now . subtract ( months = stale_months ) stale_packages = [ pack for pack in packages if pack . datetime < stale_cutoff ] if stale_packages : stale_list = ' \\n ' . join ( map ( format_package , sorted ( stale_packages , key = lambda x : x . datetime ))) logger . warning ( f 'Found stale packages that may be a dependency risk: \\n\\n { stale_list } \\n\\n ' ) @beartype def find_stale_packages ( path_lock : Path , path_pack_lock : Path = _PATH_PACK_LOCK , * , stale_months : int = 48 , ) -> None : \"\"\"Read the cached packaging information. Args: path_lock: Path to the lock file to parse path_pack_lock: Path to the lock file. Default is `_PATH_PACK_LOCK` stale_months: cutoff in months for when a package might be stale enough to be a risk. Default is 48 \"\"\" packages = _read_packages ( path_lock ) old_cache = _read_cache ( path_pack_lock ) updated_packages = _collect_release_dates ( packages , old_cache ) _write_cache ( updated_packages , path_pack_lock ) _check_for_stale_packages ( updated_packages , stale_months = stale_months ) @beartype def task_check_for_stale_packages () -> DoitTask : \"\"\"Check for stale packages. Returns: DoitTask: doit task \"\"\" path_lock = DG . meta . path_project / 'poetry.lock' path_pack_lock = _PATH_PACK_LOCK task = debug_task ([ ( find_stale_packages , ( path_lock , path_pack_lock ), { 'stale_months' : 48 }), Interactive ( 'poetry run pip list --outdated' ), ]) task [ 'file_dep' ] . append ( path_lock ) task [ 'targets' ] . append ( path_pack_lock ) return task","title":"calcipy.doit_tasks.packaging"},{"location":"docs/modules/calcipy/doit_tasks/packaging/#variables","text":"item limiter rate","title":"Variables"},{"location":"docs/modules/calcipy/doit_tasks/packaging/#functions","text":"","title":"Functions"},{"location":"docs/modules/calcipy/doit_tasks/packaging/#find_stale_packages","text":"def find_stale_packages ( path_lock : pathlib . Path , path_pack_lock : pathlib . Path = PosixPath ( '/Users/kyleking/Developer/Werk/__LocalProjects/calcipy/.calcipy_packaging.lock' ), * , stale_months : int = 48 ) -> None Read the cached packaging information. Parameters: Name Type Description Default path_lock None Path to the lock file to parse None path_pack_lock None Path to the lock file. Default is _PATH_PACK_LOCK None stale_months None cutoff in months for when a package might be stale enough to be a risk. Default is 48 None View Source @beartype def find_stale_packages ( path_lock : Path , path_pack_lock : Path = _PATH_PACK_LOCK , * , stale_months : int = 48 , ) -> None : \"\"\"Read the cached packaging information. Args: path_lock: Path to the lock file to parse path_pack_lock: Path to the lock file. Default is `_PATH_PACK_LOCK` stale_months: cutoff in months for when a package might be stale enough to be a risk. Default is 48 \"\"\" packages = _read_packages ( path_lock ) old_cache = _read_cache ( path_pack_lock ) updated_packages = _collect_release_dates ( packages , old_cache ) _write_cache ( updated_packages , path_pack_lock ) _check_for_stale_packages ( updated_packages , stale_months = stale_months )","title":"find_stale_packages"},{"location":"docs/modules/calcipy/doit_tasks/packaging/#task_check_for_stale_packages","text":"def task_check_for_stale_packages () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Check for stale packages. Returns: Type Description DoitTask doit task View Source @beartype def task_check_for_stale_packages () -> DoitTask : \"\"\"Check for stale packages. Returns: DoitTask: doit task \"\"\" path_lock = DG . meta . path_project / 'poetry.lock' path_pack_lock = _PATH_PACK_LOCK task = debug_task ([ ( find_stale_packages , ( path_lock , path_pack_lock ), { 'stale_months' : 48 }), Interactive ( 'poetry run pip list --outdated' ), ]) task [ 'file_dep' ] . append ( path_lock ) task [ 'targets' ] . append ( path_pack_lock ) return task","title":"task_check_for_stale_packages"},{"location":"docs/modules/calcipy/doit_tasks/packaging/#task_check_license","text":"def task_check_license () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Check licenses for compatibility. Returns: Type Description DoitTask doit task View Source @beartype def task_check_license () -> DoitTask : \"\"\"Check licenses for compatibility. Returns: DoitTask: doit task \"\"\" return debug_task ([ 'poetry run licensecheck --zero' ])","title":"task_check_license"},{"location":"docs/modules/calcipy/doit_tasks/packaging/#task_lock","text":"def task_lock () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Lock dependencies. Returns: Type Description DoitTask doit task View Source @beartype def task_lock () -> DoitTask : \"\"\"Lock dependencies. Returns: DoitTask: doit task \"\"\" path_req = DG . meta . path_project / 'requirements.txt' # Ensure that extras are exported as well toml_data = toml . loads ( DG . meta . path_toml . read_text ()) extras = [ * toml_data [ 'tool' ][ 'poetry' ] . get ( 'extras' , {}) . keys ()] extras_arg = ' -E ' . join ([ '' ] + extras ) if extras else '' task = debug_task ([ 'poetry lock' , f 'poetry export -f { path_req . name } -o { path_req . name }{ extras_arg } --dev' , ]) task [ 'file_dep' ] . append ( DG . meta . path_toml ) task [ 'targets' ] . extend ([ DG . meta . path_project / 'poetry.lock' , path_req ]) return task","title":"task_lock"},{"location":"docs/modules/calcipy/doit_tasks/packaging/#task_publish","text":"def task_publish () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Build the distributable format(s) and publish. See the Developer Guide for configuring pypi token Use in conjunction with task_cl_bump Returns: Type Description DoitTask doit task View Source @beartype def task_publish () -> DoitTask : \"\"\"Build the distributable format(s) and publish. > See the Developer Guide for configuring pypi token > Use in conjunction with `task_cl_bump` Returns: DoitTask: doit task \"\"\" return _publish_task ()","title":"task_publish"},{"location":"docs/modules/calcipy/doit_tasks/packaging/#task_publish_test_pypi","text":"def task_publish_test_pypi () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Build the distributable format(s) and publish to the TestPyPi repository. Returns: Type Description DoitTask doit task View Source @beartype def task_publish_test_pypi () -> DoitTask : \"\"\"Build the distributable format(s) and publish to the TestPyPi repository. Returns: DoitTask: doit task \"\"\" return _publish_task ( '--repository testpypi' )","title":"task_publish_test_pypi"},{"location":"docs/modules/calcipy/doit_tasks/summary_reporter/","text":"calcipy.doit_tasks.summary_reporter \u2693\ufe0e Custom doit reporter. Based on conversation here: https://groups.google.com/g/python-doit/c/SgoiGt_XYDU/m/PQ8JmlKFAgAJ View Source \"\"\"Custom doit reporter. Based on conversation here: https://groups.google.com/g/python-doit/c/SgoiGt_XYDU/m/PQ8JmlKFAgAJ \"\"\" from enum import IntEnum from typing import Any , List , OrderedDict import attr from beartype import beartype from doit.reporter import ConsoleReporter from doit.task import Task from sty import fg class _TaskExitCode ( IntEnum ): # noqa: H601 \"\"\"Enum for identifying the task exit code.\"\"\" PASS = 0 FAIL = 1 NOT_RUN = 2 SKIP_IGNORED = 3 SKIP_UP_TO_DATE = 4 @attr . s ( auto_attribs = True , kw_only = True ) class _TaskSummary : # noqa: H601 \"\"\"Task Summary.\"\"\" name : str exit_code : _TaskExitCode @beartype def _format_task_summary ( task_summary : _TaskSummary ) -> str : \"\"\"Format the string task summary for printing.\"\"\" lookup = { # noqa: DAR101, DAR201 _TaskExitCode . PASS : ( fg . green , 'was successful' ), _TaskExitCode . FAIL : ( fg . red , 'failed' ), _TaskExitCode . NOT_RUN : ( fg . white , 'was not run' ), _TaskExitCode . SKIP_IGNORED : ( fg . yellow , 'was ignored' ), _TaskExitCode . SKIP_UP_TO_DATE : ( fg . yellow , 'was skipped' ), } foreground , exit_summary = lookup . get ( task_summary . exit_code , ( '' , 'is UNKNOWN' )) return f ' { foreground }{ task_summary . name } { exit_summary } ' + fg . rs class SummaryReporter ( ConsoleReporter ): # pragma: no cover # noqa: H601 \"\"\"Summarize results of doit tasks.\"\"\" def initialize ( self , tasks : OrderedDict [ str , Task ], selected_tasks : List [ str ]) -> None : \"\"\"Initialize the data members for tracking task run status.\"\"\" # noqa: DAR101 super () . initialize ( tasks , selected_tasks ) self . _all_tasks = selected_tasks self . _task_summaries = {} def _add_summary ( self , task : Task , exit_code : _TaskExitCode ) -> None : \"\"\"Store summary for later reference.\"\"\" # noqa: DAR101 task_summary = _TaskSummary ( name = task . name , exit_code = exit_code ) self . _task_summaries [ task_summary . name ] = task_summary def add_failure ( self , task : Task , exception : Any ) -> None : \"\"\"Catch tasks that failed.\"\"\" # noqa: DAR101 super () . add_failure ( task , exception ) self . _add_summary ( task , _TaskExitCode . FAIL ) def add_success ( self , task : Task ) -> None : \"\"\"Catch tasks that succeeded.\"\"\" # noqa: DAR101 super () . add_success ( task ) self . _add_summary ( task , _TaskExitCode . PASS ) def skip_uptodate ( self , task : Task ) -> None : \"\"\"Catch tasks skipped.\"\"\" # noqa: DAR101 super () . skip_uptodate ( task ) self . _add_summary ( task , _TaskExitCode . SKIP_IGNORED ) def skip_ignore ( self , task : Task ) -> None : \"\"\"Catch tasks skipped.\"\"\" # noqa: DAR101 super () . skip_ignore ( task ) self . _add_summary ( task , _TaskExitCode . SKIP_UP_TO_DATE ) def complete_run ( self ) -> None : \"\"\"Output a concise summary.\"\"\" super () . complete_run () # Inspired by \"nox\" prefix = 'doit> ' self . write ( f ' { prefix } Summary: \\n ' ) not_run_kwargs = { 'exit_code' : _TaskExitCode . NOT_RUN } for task_name in self . _all_tasks : task_summary = self . _task_summaries . get ( task_name , _TaskSummary ( name = task_name , ** not_run_kwargs )) self . write ( prefix + _format_task_summary ( task_summary ) + ' \\n ' ) Classes \u2693\ufe0e SummaryReporter \u2693\ufe0e class SummaryReporter ( outstream , options ) View Source class SummaryReporter ( ConsoleReporter ): # pragma: no cover # noqa: H601 \"\"\"Summarize results of doit tasks.\"\"\" def initialize ( self , tasks : OrderedDict [ str , Task ], selected_tasks : List [ str ]) -> None : \"\"\"Initialize the data members for tracking task run status.\"\"\" # noqa: DAR101 super () . initialize ( tasks , selected_tasks ) self . _all_tasks = selected_tasks self . _task_summaries = {} def _add_summary ( self , task : Task , exit_code : _TaskExitCode ) -> None : \"\"\"Store summary for later reference.\"\"\" # noqa: DAR101 task_summary = _TaskSummary ( name = task . name , exit_code = exit_code ) self . _task_summaries [ task_summary . name ] = task_summary def add_failure ( self , task : Task , exception : Any ) -> None : \"\"\"Catch tasks that failed.\"\"\" # noqa: DAR101 super () . add_failure ( task , exception ) self . _add_summary ( task , _TaskExitCode . FAIL ) def add_success ( self , task : Task ) -> None : \"\"\"Catch tasks that succeeded.\"\"\" # noqa: DAR101 super () . add_success ( task ) self . _add_summary ( task , _TaskExitCode . PASS ) def skip_uptodate ( self , task : Task ) -> None : \"\"\"Catch tasks skipped.\"\"\" # noqa: DAR101 super () . skip_uptodate ( task ) self . _add_summary ( task , _TaskExitCode . SKIP_IGNORED ) def skip_ignore ( self , task : Task ) -> None : \"\"\"Catch tasks skipped.\"\"\" # noqa: DAR101 super () . skip_ignore ( task ) self . _add_summary ( task , _TaskExitCode . SKIP_UP_TO_DATE ) def complete_run ( self ) -> None : \"\"\"Output a concise summary.\"\"\" super () . complete_run () # Inspired by \"nox\" prefix = 'doit> ' self . write ( f ' { prefix } Summary: \\n ' ) not_run_kwargs = { 'exit_code' : _TaskExitCode . NOT_RUN } for task_name in self . _all_tasks : task_summary = self . _task_summaries . get ( task_name , _TaskSummary ( name = task_name , ** not_run_kwargs )) self . write ( prefix + _format_task_summary ( task_summary ) + ' \\n ' ) Ancestors (in MRO) \u2693\ufe0e doit.reporter.ConsoleReporter Class variables \u2693\ufe0e desc Methods \u2693\ufe0e add_failure \u2693\ufe0e def add_failure ( self , task : doit . task . Task , exception : Any ) -> None Catch tasks that failed. View Source def add_failure ( self , task : Task , exception : Any ) -> None : \"\"\"Catch tasks that failed.\"\"\" # noqa: DAR101 super () . add_failure ( task , exception ) self . _add_summary ( task , _TaskExitCode . FAIL ) add_success \u2693\ufe0e def add_success ( self , task : doit . task . Task ) -> None Catch tasks that succeeded. View Source def add_success ( self , task : Task ) -> None : \"\"\"Catch tasks that succeeded.\"\"\" # noqa: DAR101 super () . add_success ( task ) self . _add_summary ( task , _TaskExitCode . PASS ) cleanup_error \u2693\ufe0e def cleanup_error ( self , exception ) error during cleanup View Source def cleanup_error ( self , exception ): \"\"\"error during cleanup\"\"\" sys . stderr . write ( exception . get_msg ()) complete_run \u2693\ufe0e def complete_run ( self ) -> None Output a concise summary. View Source def complete_run ( self ) -> None : \"\"\"Output a concise summary.\"\"\" super () . complete_run () # Inspired by \"nox\" prefix = 'doit> ' self . write ( f ' { prefix } Summary: \\n ' ) not_run_kwargs = { 'exit_code' : _TaskExitCode . NOT_RUN } for task_name in self . _all_tasks : task_summary = self . _task_summaries . get ( task_name , _TaskSummary ( name = task_name , ** not_run_kwargs )) self . write ( prefix + _format_task_summary ( task_summary ) + ' \\n ' ) execute_task \u2693\ufe0e def execute_task ( self , task ) called when execution starts View Source def execute_task ( self , task ): \"\"\"called when execution starts\"\"\" # ignore tasks that do not define actions # ignore private/hidden tasks (tasks that start with an underscore) if task . actions and ( task . name [ 0 ] != '_' ): self . write ( '. %s \\n ' % task . title ()) get_status \u2693\ufe0e def get_status ( self , task ) called when task is selected (check if up-to-date) View Source def get_status ( self , task ): \"\"\"called when task is selected (check if up-to-date)\"\"\" pass initialize \u2693\ufe0e def initialize ( self , tasks : OrderedDict [ str , doit . task . Task ], selected_tasks : List [ str ] ) -> None Initialize the data members for tracking task run status. View Source def initialize ( self , tasks : OrderedDict [ str , Task ], selected_tasks : List [ str ]) -> None : \"\"\"Initialize the data members for tracking task run status.\"\"\" # noqa: DAR101 super () . initialize ( tasks , selected_tasks ) self . _all_tasks = selected_tasks self . _task_summaries = {} runtime_error \u2693\ufe0e def runtime_error ( self , msg ) error from doit (not from a task execution) View Source def runtime_error ( self , msg ): \"\"\"error from doit (not from a task execution)\"\"\" # saved so they are displayed after task failures messages self . runtime_errors . append ( msg ) skip_ignore \u2693\ufe0e def skip_ignore ( self , task : doit . task . Task ) -> None Catch tasks skipped. View Source def skip_ignore ( self , task : Task ) -> None : \"\"\"Catch tasks skipped.\"\"\" # noqa: DAR101 super () . skip_ignore ( task ) self . _add_summary ( task , _TaskExitCode . SKIP_UP_TO_DATE ) skip_uptodate \u2693\ufe0e def skip_uptodate ( self , task : doit . task . Task ) -> None Catch tasks skipped. View Source def skip_uptodate ( self , task : Task ) -> None : \"\"\"Catch tasks skipped.\"\"\" # noqa: DAR101 super () . skip_uptodate ( task ) self . _add_summary ( task , _TaskExitCode . SKIP_IGNORED ) teardown_task \u2693\ufe0e def teardown_task ( self , task ) called when starts the execution of teardown action View Source def teardown_task ( self , task ): \"\"\"called when starts the execution of teardown action\"\"\" pass write \u2693\ufe0e def write ( self , text ) View Source def write ( self , text ): self . outstream . write ( text )","title":"calcipy.doit_tasks.summary_reporter"},{"location":"docs/modules/calcipy/doit_tasks/summary_reporter/#calcipydoit_taskssummary_reporter","text":"Custom doit reporter. Based on conversation here: https://groups.google.com/g/python-doit/c/SgoiGt_XYDU/m/PQ8JmlKFAgAJ View Source \"\"\"Custom doit reporter. Based on conversation here: https://groups.google.com/g/python-doit/c/SgoiGt_XYDU/m/PQ8JmlKFAgAJ \"\"\" from enum import IntEnum from typing import Any , List , OrderedDict import attr from beartype import beartype from doit.reporter import ConsoleReporter from doit.task import Task from sty import fg class _TaskExitCode ( IntEnum ): # noqa: H601 \"\"\"Enum for identifying the task exit code.\"\"\" PASS = 0 FAIL = 1 NOT_RUN = 2 SKIP_IGNORED = 3 SKIP_UP_TO_DATE = 4 @attr . s ( auto_attribs = True , kw_only = True ) class _TaskSummary : # noqa: H601 \"\"\"Task Summary.\"\"\" name : str exit_code : _TaskExitCode @beartype def _format_task_summary ( task_summary : _TaskSummary ) -> str : \"\"\"Format the string task summary for printing.\"\"\" lookup = { # noqa: DAR101, DAR201 _TaskExitCode . PASS : ( fg . green , 'was successful' ), _TaskExitCode . FAIL : ( fg . red , 'failed' ), _TaskExitCode . NOT_RUN : ( fg . white , 'was not run' ), _TaskExitCode . SKIP_IGNORED : ( fg . yellow , 'was ignored' ), _TaskExitCode . SKIP_UP_TO_DATE : ( fg . yellow , 'was skipped' ), } foreground , exit_summary = lookup . get ( task_summary . exit_code , ( '' , 'is UNKNOWN' )) return f ' { foreground }{ task_summary . name } { exit_summary } ' + fg . rs class SummaryReporter ( ConsoleReporter ): # pragma: no cover # noqa: H601 \"\"\"Summarize results of doit tasks.\"\"\" def initialize ( self , tasks : OrderedDict [ str , Task ], selected_tasks : List [ str ]) -> None : \"\"\"Initialize the data members for tracking task run status.\"\"\" # noqa: DAR101 super () . initialize ( tasks , selected_tasks ) self . _all_tasks = selected_tasks self . _task_summaries = {} def _add_summary ( self , task : Task , exit_code : _TaskExitCode ) -> None : \"\"\"Store summary for later reference.\"\"\" # noqa: DAR101 task_summary = _TaskSummary ( name = task . name , exit_code = exit_code ) self . _task_summaries [ task_summary . name ] = task_summary def add_failure ( self , task : Task , exception : Any ) -> None : \"\"\"Catch tasks that failed.\"\"\" # noqa: DAR101 super () . add_failure ( task , exception ) self . _add_summary ( task , _TaskExitCode . FAIL ) def add_success ( self , task : Task ) -> None : \"\"\"Catch tasks that succeeded.\"\"\" # noqa: DAR101 super () . add_success ( task ) self . _add_summary ( task , _TaskExitCode . PASS ) def skip_uptodate ( self , task : Task ) -> None : \"\"\"Catch tasks skipped.\"\"\" # noqa: DAR101 super () . skip_uptodate ( task ) self . _add_summary ( task , _TaskExitCode . SKIP_IGNORED ) def skip_ignore ( self , task : Task ) -> None : \"\"\"Catch tasks skipped.\"\"\" # noqa: DAR101 super () . skip_ignore ( task ) self . _add_summary ( task , _TaskExitCode . SKIP_UP_TO_DATE ) def complete_run ( self ) -> None : \"\"\"Output a concise summary.\"\"\" super () . complete_run () # Inspired by \"nox\" prefix = 'doit> ' self . write ( f ' { prefix } Summary: \\n ' ) not_run_kwargs = { 'exit_code' : _TaskExitCode . NOT_RUN } for task_name in self . _all_tasks : task_summary = self . _task_summaries . get ( task_name , _TaskSummary ( name = task_name , ** not_run_kwargs )) self . write ( prefix + _format_task_summary ( task_summary ) + ' \\n ' )","title":"calcipy.doit_tasks.summary_reporter"},{"location":"docs/modules/calcipy/doit_tasks/summary_reporter/#classes","text":"","title":"Classes"},{"location":"docs/modules/calcipy/doit_tasks/summary_reporter/#summaryreporter","text":"class SummaryReporter ( outstream , options ) View Source class SummaryReporter ( ConsoleReporter ): # pragma: no cover # noqa: H601 \"\"\"Summarize results of doit tasks.\"\"\" def initialize ( self , tasks : OrderedDict [ str , Task ], selected_tasks : List [ str ]) -> None : \"\"\"Initialize the data members for tracking task run status.\"\"\" # noqa: DAR101 super () . initialize ( tasks , selected_tasks ) self . _all_tasks = selected_tasks self . _task_summaries = {} def _add_summary ( self , task : Task , exit_code : _TaskExitCode ) -> None : \"\"\"Store summary for later reference.\"\"\" # noqa: DAR101 task_summary = _TaskSummary ( name = task . name , exit_code = exit_code ) self . _task_summaries [ task_summary . name ] = task_summary def add_failure ( self , task : Task , exception : Any ) -> None : \"\"\"Catch tasks that failed.\"\"\" # noqa: DAR101 super () . add_failure ( task , exception ) self . _add_summary ( task , _TaskExitCode . FAIL ) def add_success ( self , task : Task ) -> None : \"\"\"Catch tasks that succeeded.\"\"\" # noqa: DAR101 super () . add_success ( task ) self . _add_summary ( task , _TaskExitCode . PASS ) def skip_uptodate ( self , task : Task ) -> None : \"\"\"Catch tasks skipped.\"\"\" # noqa: DAR101 super () . skip_uptodate ( task ) self . _add_summary ( task , _TaskExitCode . SKIP_IGNORED ) def skip_ignore ( self , task : Task ) -> None : \"\"\"Catch tasks skipped.\"\"\" # noqa: DAR101 super () . skip_ignore ( task ) self . _add_summary ( task , _TaskExitCode . SKIP_UP_TO_DATE ) def complete_run ( self ) -> None : \"\"\"Output a concise summary.\"\"\" super () . complete_run () # Inspired by \"nox\" prefix = 'doit> ' self . write ( f ' { prefix } Summary: \\n ' ) not_run_kwargs = { 'exit_code' : _TaskExitCode . NOT_RUN } for task_name in self . _all_tasks : task_summary = self . _task_summaries . get ( task_name , _TaskSummary ( name = task_name , ** not_run_kwargs )) self . write ( prefix + _format_task_summary ( task_summary ) + ' \\n ' )","title":"SummaryReporter"},{"location":"docs/modules/calcipy/doit_tasks/summary_reporter/#ancestors-in-mro","text":"doit.reporter.ConsoleReporter","title":"Ancestors (in MRO)"},{"location":"docs/modules/calcipy/doit_tasks/summary_reporter/#class-variables","text":"desc","title":"Class variables"},{"location":"docs/modules/calcipy/doit_tasks/summary_reporter/#methods","text":"","title":"Methods"},{"location":"docs/modules/calcipy/doit_tasks/summary_reporter/#add_failure","text":"def add_failure ( self , task : doit . task . Task , exception : Any ) -> None Catch tasks that failed. View Source def add_failure ( self , task : Task , exception : Any ) -> None : \"\"\"Catch tasks that failed.\"\"\" # noqa: DAR101 super () . add_failure ( task , exception ) self . _add_summary ( task , _TaskExitCode . FAIL )","title":"add_failure"},{"location":"docs/modules/calcipy/doit_tasks/summary_reporter/#add_success","text":"def add_success ( self , task : doit . task . Task ) -> None Catch tasks that succeeded. View Source def add_success ( self , task : Task ) -> None : \"\"\"Catch tasks that succeeded.\"\"\" # noqa: DAR101 super () . add_success ( task ) self . _add_summary ( task , _TaskExitCode . PASS )","title":"add_success"},{"location":"docs/modules/calcipy/doit_tasks/summary_reporter/#cleanup_error","text":"def cleanup_error ( self , exception ) error during cleanup View Source def cleanup_error ( self , exception ): \"\"\"error during cleanup\"\"\" sys . stderr . write ( exception . get_msg ())","title":"cleanup_error"},{"location":"docs/modules/calcipy/doit_tasks/summary_reporter/#complete_run","text":"def complete_run ( self ) -> None Output a concise summary. View Source def complete_run ( self ) -> None : \"\"\"Output a concise summary.\"\"\" super () . complete_run () # Inspired by \"nox\" prefix = 'doit> ' self . write ( f ' { prefix } Summary: \\n ' ) not_run_kwargs = { 'exit_code' : _TaskExitCode . NOT_RUN } for task_name in self . _all_tasks : task_summary = self . _task_summaries . get ( task_name , _TaskSummary ( name = task_name , ** not_run_kwargs )) self . write ( prefix + _format_task_summary ( task_summary ) + ' \\n ' )","title":"complete_run"},{"location":"docs/modules/calcipy/doit_tasks/summary_reporter/#execute_task","text":"def execute_task ( self , task ) called when execution starts View Source def execute_task ( self , task ): \"\"\"called when execution starts\"\"\" # ignore tasks that do not define actions # ignore private/hidden tasks (tasks that start with an underscore) if task . actions and ( task . name [ 0 ] != '_' ): self . write ( '. %s \\n ' % task . title ())","title":"execute_task"},{"location":"docs/modules/calcipy/doit_tasks/summary_reporter/#get_status","text":"def get_status ( self , task ) called when task is selected (check if up-to-date) View Source def get_status ( self , task ): \"\"\"called when task is selected (check if up-to-date)\"\"\" pass","title":"get_status"},{"location":"docs/modules/calcipy/doit_tasks/summary_reporter/#initialize","text":"def initialize ( self , tasks : OrderedDict [ str , doit . task . Task ], selected_tasks : List [ str ] ) -> None Initialize the data members for tracking task run status. View Source def initialize ( self , tasks : OrderedDict [ str , Task ], selected_tasks : List [ str ]) -> None : \"\"\"Initialize the data members for tracking task run status.\"\"\" # noqa: DAR101 super () . initialize ( tasks , selected_tasks ) self . _all_tasks = selected_tasks self . _task_summaries = {}","title":"initialize"},{"location":"docs/modules/calcipy/doit_tasks/summary_reporter/#runtime_error","text":"def runtime_error ( self , msg ) error from doit (not from a task execution) View Source def runtime_error ( self , msg ): \"\"\"error from doit (not from a task execution)\"\"\" # saved so they are displayed after task failures messages self . runtime_errors . append ( msg )","title":"runtime_error"},{"location":"docs/modules/calcipy/doit_tasks/summary_reporter/#skip_ignore","text":"def skip_ignore ( self , task : doit . task . Task ) -> None Catch tasks skipped. View Source def skip_ignore ( self , task : Task ) -> None : \"\"\"Catch tasks skipped.\"\"\" # noqa: DAR101 super () . skip_ignore ( task ) self . _add_summary ( task , _TaskExitCode . SKIP_UP_TO_DATE )","title":"skip_ignore"},{"location":"docs/modules/calcipy/doit_tasks/summary_reporter/#skip_uptodate","text":"def skip_uptodate ( self , task : doit . task . Task ) -> None Catch tasks skipped. View Source def skip_uptodate ( self , task : Task ) -> None : \"\"\"Catch tasks skipped.\"\"\" # noqa: DAR101 super () . skip_uptodate ( task ) self . _add_summary ( task , _TaskExitCode . SKIP_IGNORED )","title":"skip_uptodate"},{"location":"docs/modules/calcipy/doit_tasks/summary_reporter/#teardown_task","text":"def teardown_task ( self , task ) called when starts the execution of teardown action View Source def teardown_task ( self , task ): \"\"\"called when starts the execution of teardown action\"\"\" pass","title":"teardown_task"},{"location":"docs/modules/calcipy/doit_tasks/summary_reporter/#write","text":"def write ( self , text ) View Source def write ( self , text ): self . outstream . write ( text )","title":"write"},{"location":"docs/modules/calcipy/doit_tasks/test/","text":"calcipy.doit_tasks.test \u2693\ufe0e doit Test Utilities. View Source \"\"\"doit Test Utilities.\"\"\" from beartype import beartype from doit.tools import Interactive from .base import debug_task , open_in_browser from .doit_globals import DG , DoitTask # ---------------------------------------------------------------------------------------------------------------------- # Manage Testing with Nox @beartype def task_nox () -> DoitTask : \"\"\"Run the full nox test suite. > Note: some nox tasks are run in more-specific doit tasks, but this will run everything Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run nox' ), ]) @beartype def task_nox_test () -> DoitTask : \"\"\"Run all nox tests. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run nox --session tests build_check' ), ]) @beartype def task_nox_coverage () -> DoitTask : \"\"\"Run all nox tests. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run nox --session coverage' ), ]) # ---------------------------------------------------------------------------------------------------------------------- # Manage Testing with pytest (Should be run from Nox) @beartype def task_test () -> DoitTask : \"\"\"Run tests with Pytest and stop on the first failure. > Test are randomly ordered by default with pytest-randomly because that can help catch common errors > Tests can be re-run in the last order with `poetry run pytest --randomly-seed=last` > Tip: `--record-mode=rewrite` can be useful if working with `pytest-recording` Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" { DG . test . args_pytest } ' ), ]) @beartype def task_test_all () -> DoitTask : \"\"\"Run all possible tests with Pytest even if one or more failures. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" --ff -vv' ), ]) @beartype def task_test_marker () -> DoitTask : \"\"\"Specify a marker to run a subset of tests. Example: `doit run test_marker -m \"not MARKER\"` or `doit run test_marker -m \"MARKER\"` Returns: DoitTask: doit task \"\"\" task = debug_task ([ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" { DG . test . args_pytest } -m \"%(marker)s\"' )]) task [ 'params' ] = [{ 'name' : 'marker' , 'short' : 'm' , 'long' : 'marker' , 'default' : '' , 'help' : ( 'Runs test with specified marker logic \\n See: ' 'https://docs.pytest.org/en/latest/example/markers.html?highlight=-m' ), }] return task @beartype def task_test_keyword () -> DoitTask : \"\"\"Specify a keyword to run a subset of tests. Example: `doit run test_keyword -k \"KEYWORD\"` Returns: DoitTask: doit task \"\"\" return { 'actions' : [ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" { DG . test . args_pytest } -k \"%(keyword)s\"' ), ], 'params' : [{ 'name' : 'keyword' , 'short' : 'k' , 'long' : 'keyword' , 'default' : '' , 'help' : ( 'Runs only tests that match the string pattern \\n See: ' 'https://docs.pytest.org/en/latest/usage.html#specifying-tests-selecting-tests' ), }], 'verbosity' : 2 , } @beartype def task_coverage () -> DoitTask : \"\"\"Run pytest and create coverage and test reports. Returns: DoitTask: doit task \"\"\" path_tests = DG . test . path_tests cov_dir = DG . test . path_coverage_index . parent cov_html = f '--cov-report=html:\" { cov_dir } \" --html=\" { DG . test . path_test_report } \" --self-contained-html' diff_html = f '--html-report { DG . test . path_diff_test_report } ' return debug_task ([ Interactive ( f 'poetry run pytest \" { path_tests } \" { DG . test . args_pytest } --cov= { DG . meta . pkg_name } { cov_html } ' ), 'poetry run python -m coverage json' , # Create coverage.json file for \"_write_coverage_to_md\" 'poetry run python -m coverage xml' , Interactive ( f 'poetry run diff-cover coverage.xml { DG . test . args_diff } { diff_html } ' ), ]) # ---------------------------------------------------------------------------------------------------------------------- # Other Test Tools (MyPy, etc.) @beartype def task_check_types () -> DoitTask : \"\"\"Run type annotation checks. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run mypy { DG . meta . pkg_name } --show-error-codes' ), ]) # ---------------------------------------------------------------------------------------------------------------------- # Test Output Interaction @beartype def task_open_test_docs () -> DoitTask : \"\"\"Open the test and coverage files in default browser. Returns: DoitTask: doit task \"\"\" actions = [ ( open_in_browser , ( DG . test . path_coverage_index ,)), ( open_in_browser , ( DG . test . path_test_report ,)), ] if DG . test . path_mypy_index . is_file (): actions . append (( open_in_browser , ( DG . test . path_mypy_index ,))) return debug_task ( actions ) # ---------------------------------------------------------------------------------------------------------------------- # Implement long running ptw tasks @beartype def ptw_task ( cli_args : str ) -> DoitTask : \"\"\"Return doit Interactive `ptw` task. Args: cli_args: string CLI args to pass to `ptw` Returns: DoitTask: doit task \"\"\" return { 'actions' : [ Interactive ( f 'poetry run ptw -- \" { DG . test . path_tests } \" { cli_args } ' )], 'verbosity' : 2 , } @beartype def task_ptw_not_chrome () -> DoitTask : \"\"\"Run pytest watch for failed first and skip the CHROME marker. kwargs: `-m 'not CHROME' -vvv` Returns: DoitTask: doit task \"\"\" return ptw_task ( '-m \"not CHROME\" -vvv' ) @beartype def task_ptw_ff () -> DoitTask : \"\"\"Run pytest watch for failed first and skip the CHROME marker. kwargs: `--last-failed --new-first -m 'not CHROME' -vv` Returns: DoitTask: doit task \"\"\" return ptw_task ( '--last-failed --new-first -m \"not CHROME\" -vv' ) @beartype def task_ptw_current () -> DoitTask : \"\"\"Run pytest watch for only tests with the CURRENT marker. kwargs: `-m 'CURRENT' -vv` Returns: DoitTask: doit task \"\"\" return ptw_task ( '-m \"CURRENT\" -vv' ) @beartype def task_ptw_marker () -> DoitTask : \"\"\"Specify a marker to run a subset of tests in Interactive `ptw` task. Example: `doit run ptw_marker -m \"not MARKER\"` or `doit run ptw_marker -m \"MARKER\"` Returns: DoitTask: doit task \"\"\" task = ptw_task ( '-vvv -m \" %(marker)s \"' ) task [ 'params' ] = [{ 'name' : 'marker' , 'short' : 'm' , 'long' : 'marker' , 'default' : '' , 'help' : ( 'Runs test with specified marker logic \\n See: ' 'https://docs.pytest.org/en/latest/example/markers.html?highlight=-m' ), }] return task Functions \u2693\ufe0e ptw_task \u2693\ufe0e def ptw_task ( cli_args : str ) -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Return doit Interactive ptw task. Parameters: Name Type Description Default cli_args None string CLI args to pass to ptw None Returns: Type Description DoitTask doit task View Source @beartype def ptw_task ( cli_args : str ) -> DoitTask : \"\"\"Return doit Interactive `ptw` task. Args: cli_args: string CLI args to pass to `ptw` Returns: DoitTask: doit task \"\"\" return { 'actions' : [ Interactive ( f 'poetry run ptw -- \" { DG . test . path_tests } \" { cli_args } ' )], 'verbosity' : 2 , } task_check_types \u2693\ufe0e def task_check_types () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run type annotation checks. Returns: Type Description DoitTask doit task View Source @beartype def task_check_types () -> DoitTask : \"\"\"Run type annotation checks. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run mypy { DG . meta . pkg_name } --show-error-codes' ), ]) task_coverage \u2693\ufe0e def task_coverage () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run pytest and create coverage and test reports. Returns: Type Description DoitTask doit task View Source @beartype def task_coverage () -> DoitTask : \"\"\"Run pytest and create coverage and test reports. Returns: DoitTask: doit task \"\"\" path_tests = DG . test . path_tests cov_dir = DG . test . path_coverage_index . parent cov_html = f '--cov-report=html:\" { cov_dir } \" --html=\" { DG . test . path_test_report } \" --self-contained-html' diff_html = f '--html-report { DG . test . path_diff_test_report } ' return debug_task ([ Interactive ( f 'poetry run pytest \" { path_tests } \" { DG . test . args_pytest } --cov= { DG . meta . pkg_name } { cov_html } ' ), 'poetry run python -m coverage json' , # Create coverage.json file for \"_write_coverage_to_md\" 'poetry run python -m coverage xml' , Interactive ( f 'poetry run diff-cover coverage.xml { DG . test . args_diff } { diff_html } ' ), ]) task_nox \u2693\ufe0e def task_nox () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run the full nox test suite. Note: some nox tasks are run in more-specific doit tasks, but this will run everything Returns: Type Description DoitTask doit task View Source @beartype def task_nox () -> DoitTask : \"\"\"Run the full nox test suite. > Note: some nox tasks are run in more-specific doit tasks, but this will run everything Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run nox' ), ]) task_nox_coverage \u2693\ufe0e def task_nox_coverage () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run all nox tests. Returns: Type Description DoitTask doit task View Source @beartype def task_nox_coverage () -> DoitTask : \"\"\"Run all nox tests. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run nox --session coverage' ), ]) task_nox_test \u2693\ufe0e def task_nox_test () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run all nox tests. Returns: Type Description DoitTask doit task View Source @beartype def task_nox_test () -> DoitTask : \"\"\"Run all nox tests. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run nox --session tests build_check' ), ]) task_open_test_docs \u2693\ufe0e def task_open_test_docs () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Open the test and coverage files in default browser. Returns: Type Description DoitTask doit task View Source @beartype def task_open_test_docs () -> DoitTask : \"\"\"Open the test and coverage files in default browser. Returns: DoitTask: doit task \"\"\" actions = [ ( open_in_browser , ( DG . test . path_coverage_index ,)), ( open_in_browser , ( DG . test . path_test_report ,)), ] if DG . test . path_mypy_index . is_file (): actions . append (( open_in_browser , ( DG . test . path_mypy_index ,))) return debug_task ( actions ) task_ptw_current \u2693\ufe0e def task_ptw_current () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run pytest watch for only tests with the CURRENT marker. kwargs: -m 'CURRENT' -vv Returns: Type Description DoitTask doit task View Source @beartype def task_ptw_current () -> DoitTask : \"\"\"Run pytest watch for only tests with the CURRENT marker. kwargs: `-m 'CURRENT' -vv` Returns: DoitTask: doit task \"\"\" return ptw_task ( '-m \"CURRENT\" -vv' ) task_ptw_ff \u2693\ufe0e def task_ptw_ff () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run pytest watch for failed first and skip the CHROME marker. kwargs: --last-failed --new-first -m 'not CHROME' -vv Returns: Type Description DoitTask doit task View Source @beartype def task_ptw_ff () -> DoitTask : \"\"\"Run pytest watch for failed first and skip the CHROME marker. kwargs: `--last-failed --new-first -m 'not CHROME' -vv` Returns: DoitTask: doit task \"\"\" return ptw_task ( '--last-failed --new-first -m \"not CHROME\" -vv' ) task_ptw_marker \u2693\ufe0e def task_ptw_marker () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Specify a marker to run a subset of tests in Interactive ptw task. Example: doit run ptw_marker -m \"not MARKER\" or doit run ptw_marker -m \"MARKER\" Returns: Type Description DoitTask doit task View Source @beartype def task_ptw_marker () -> DoitTask : \"\"\"Specify a marker to run a subset of tests in Interactive `ptw` task. Example: `doit run ptw_marker -m \"not MARKER\"` or `doit run ptw_marker -m \"MARKER\"` Returns: DoitTask: doit task \"\"\" task = ptw_task ( '-vvv -m \" %(marker)s \"' ) task [ 'params' ] = [{ 'name' : 'marker' , 'short' : 'm' , 'long' : 'marker' , 'default' : '' , 'help' : ( 'Runs test with specified marker logic \\n See: ' 'https://docs.pytest.org/en/latest/example/markers.html?highlight=-m' ), }] return task task_ptw_not_chrome \u2693\ufe0e def task_ptw_not_chrome () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run pytest watch for failed first and skip the CHROME marker. kwargs: -m 'not CHROME' -vvv Returns: Type Description DoitTask doit task View Source @beartype def task_ptw_not_chrome () -> DoitTask : \"\"\"Run pytest watch for failed first and skip the CHROME marker. kwargs: `-m 'not CHROME' -vvv` Returns: DoitTask: doit task \"\"\" return ptw_task ( '-m \"not CHROME\" -vvv' ) task_test \u2693\ufe0e def task_test () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run tests with Pytest and stop on the first failure. Test are randomly ordered by default with pytest-randomly because that can help catch common errors Tests can be re-run in the last order with poetry run pytest --randomly-seed=last Tip: --record-mode=rewrite can be useful if working with pytest-recording Returns: Type Description DoitTask doit task View Source @beartype def task_test () -> DoitTask : \"\"\"Run tests with Pytest and stop on the first failure. > Test are randomly ordered by default with pytest-randomly because that can help catch common errors > Tests can be re-run in the last order with `poetry run pytest --randomly-seed=last` > Tip: `--record-mode=rewrite` can be useful if working with `pytest-recording` Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" { DG . test . args_pytest } ' ), ]) task_test_all \u2693\ufe0e def task_test_all () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run all possible tests with Pytest even if one or more failures. Returns: Type Description DoitTask doit task View Source @beartype def task_test_all () -> DoitTask : \"\"\"Run all possible tests with Pytest even if one or more failures. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" --ff -vv' ), ]) task_test_keyword \u2693\ufe0e def task_test_keyword () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Specify a keyword to run a subset of tests. Example: doit run test_keyword -k \"KEYWORD\" Returns: Type Description DoitTask doit task View Source @beartype def task_test_keyword () -> DoitTask : \"\"\"Specify a keyword to run a subset of tests. Example: `doit run test_keyword -k \"KEYWORD\"` Returns: DoitTask: doit task \"\"\" return { 'actions' : [ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" { DG . test . args_pytest } -k \"%(keyword)s\"' ), ], 'params' : [{ 'name' : 'keyword' , 'short' : 'k' , 'long' : 'keyword' , 'default' : '' , 'help' : ( 'Runs only tests that match the string pattern \\n See: ' 'https://docs.pytest.org/en/latest/usage.html#specifying-tests-selecting-tests' ), }], 'verbosity' : 2 , } task_test_marker \u2693\ufe0e def task_test_marker () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Specify a marker to run a subset of tests. Example: doit run test_marker -m \"not MARKER\" or doit run test_marker -m \"MARKER\" Returns: Type Description DoitTask doit task View Source @beartype def task_test_marker () -> DoitTask : \"\"\"Specify a marker to run a subset of tests. Example: `doit run test_marker -m \"not MARKER\"` or `doit run test_marker -m \"MARKER\"` Returns: DoitTask: doit task \"\"\" task = debug_task ([ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" { DG . test . args_pytest } -m \"%(marker)s\"' )]) task [ 'params' ] = [{ 'name' : 'marker' , 'short' : 'm' , 'long' : 'marker' , 'default' : '' , 'help' : ( 'Runs test with specified marker logic \\n See: ' 'https://docs.pytest.org/en/latest/example/markers.html?highlight=-m' ), }] return task","title":"calcipy.doit_tasks.test"},{"location":"docs/modules/calcipy/doit_tasks/test/#calcipydoit_taskstest","text":"doit Test Utilities. View Source \"\"\"doit Test Utilities.\"\"\" from beartype import beartype from doit.tools import Interactive from .base import debug_task , open_in_browser from .doit_globals import DG , DoitTask # ---------------------------------------------------------------------------------------------------------------------- # Manage Testing with Nox @beartype def task_nox () -> DoitTask : \"\"\"Run the full nox test suite. > Note: some nox tasks are run in more-specific doit tasks, but this will run everything Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run nox' ), ]) @beartype def task_nox_test () -> DoitTask : \"\"\"Run all nox tests. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run nox --session tests build_check' ), ]) @beartype def task_nox_coverage () -> DoitTask : \"\"\"Run all nox tests. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run nox --session coverage' ), ]) # ---------------------------------------------------------------------------------------------------------------------- # Manage Testing with pytest (Should be run from Nox) @beartype def task_test () -> DoitTask : \"\"\"Run tests with Pytest and stop on the first failure. > Test are randomly ordered by default with pytest-randomly because that can help catch common errors > Tests can be re-run in the last order with `poetry run pytest --randomly-seed=last` > Tip: `--record-mode=rewrite` can be useful if working with `pytest-recording` Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" { DG . test . args_pytest } ' ), ]) @beartype def task_test_all () -> DoitTask : \"\"\"Run all possible tests with Pytest even if one or more failures. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" --ff -vv' ), ]) @beartype def task_test_marker () -> DoitTask : \"\"\"Specify a marker to run a subset of tests. Example: `doit run test_marker -m \"not MARKER\"` or `doit run test_marker -m \"MARKER\"` Returns: DoitTask: doit task \"\"\" task = debug_task ([ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" { DG . test . args_pytest } -m \"%(marker)s\"' )]) task [ 'params' ] = [{ 'name' : 'marker' , 'short' : 'm' , 'long' : 'marker' , 'default' : '' , 'help' : ( 'Runs test with specified marker logic \\n See: ' 'https://docs.pytest.org/en/latest/example/markers.html?highlight=-m' ), }] return task @beartype def task_test_keyword () -> DoitTask : \"\"\"Specify a keyword to run a subset of tests. Example: `doit run test_keyword -k \"KEYWORD\"` Returns: DoitTask: doit task \"\"\" return { 'actions' : [ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" { DG . test . args_pytest } -k \"%(keyword)s\"' ), ], 'params' : [{ 'name' : 'keyword' , 'short' : 'k' , 'long' : 'keyword' , 'default' : '' , 'help' : ( 'Runs only tests that match the string pattern \\n See: ' 'https://docs.pytest.org/en/latest/usage.html#specifying-tests-selecting-tests' ), }], 'verbosity' : 2 , } @beartype def task_coverage () -> DoitTask : \"\"\"Run pytest and create coverage and test reports. Returns: DoitTask: doit task \"\"\" path_tests = DG . test . path_tests cov_dir = DG . test . path_coverage_index . parent cov_html = f '--cov-report=html:\" { cov_dir } \" --html=\" { DG . test . path_test_report } \" --self-contained-html' diff_html = f '--html-report { DG . test . path_diff_test_report } ' return debug_task ([ Interactive ( f 'poetry run pytest \" { path_tests } \" { DG . test . args_pytest } --cov= { DG . meta . pkg_name } { cov_html } ' ), 'poetry run python -m coverage json' , # Create coverage.json file for \"_write_coverage_to_md\" 'poetry run python -m coverage xml' , Interactive ( f 'poetry run diff-cover coverage.xml { DG . test . args_diff } { diff_html } ' ), ]) # ---------------------------------------------------------------------------------------------------------------------- # Other Test Tools (MyPy, etc.) @beartype def task_check_types () -> DoitTask : \"\"\"Run type annotation checks. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run mypy { DG . meta . pkg_name } --show-error-codes' ), ]) # ---------------------------------------------------------------------------------------------------------------------- # Test Output Interaction @beartype def task_open_test_docs () -> DoitTask : \"\"\"Open the test and coverage files in default browser. Returns: DoitTask: doit task \"\"\" actions = [ ( open_in_browser , ( DG . test . path_coverage_index ,)), ( open_in_browser , ( DG . test . path_test_report ,)), ] if DG . test . path_mypy_index . is_file (): actions . append (( open_in_browser , ( DG . test . path_mypy_index ,))) return debug_task ( actions ) # ---------------------------------------------------------------------------------------------------------------------- # Implement long running ptw tasks @beartype def ptw_task ( cli_args : str ) -> DoitTask : \"\"\"Return doit Interactive `ptw` task. Args: cli_args: string CLI args to pass to `ptw` Returns: DoitTask: doit task \"\"\" return { 'actions' : [ Interactive ( f 'poetry run ptw -- \" { DG . test . path_tests } \" { cli_args } ' )], 'verbosity' : 2 , } @beartype def task_ptw_not_chrome () -> DoitTask : \"\"\"Run pytest watch for failed first and skip the CHROME marker. kwargs: `-m 'not CHROME' -vvv` Returns: DoitTask: doit task \"\"\" return ptw_task ( '-m \"not CHROME\" -vvv' ) @beartype def task_ptw_ff () -> DoitTask : \"\"\"Run pytest watch for failed first and skip the CHROME marker. kwargs: `--last-failed --new-first -m 'not CHROME' -vv` Returns: DoitTask: doit task \"\"\" return ptw_task ( '--last-failed --new-first -m \"not CHROME\" -vv' ) @beartype def task_ptw_current () -> DoitTask : \"\"\"Run pytest watch for only tests with the CURRENT marker. kwargs: `-m 'CURRENT' -vv` Returns: DoitTask: doit task \"\"\" return ptw_task ( '-m \"CURRENT\" -vv' ) @beartype def task_ptw_marker () -> DoitTask : \"\"\"Specify a marker to run a subset of tests in Interactive `ptw` task. Example: `doit run ptw_marker -m \"not MARKER\"` or `doit run ptw_marker -m \"MARKER\"` Returns: DoitTask: doit task \"\"\" task = ptw_task ( '-vvv -m \" %(marker)s \"' ) task [ 'params' ] = [{ 'name' : 'marker' , 'short' : 'm' , 'long' : 'marker' , 'default' : '' , 'help' : ( 'Runs test with specified marker logic \\n See: ' 'https://docs.pytest.org/en/latest/example/markers.html?highlight=-m' ), }] return task","title":"calcipy.doit_tasks.test"},{"location":"docs/modules/calcipy/doit_tasks/test/#functions","text":"","title":"Functions"},{"location":"docs/modules/calcipy/doit_tasks/test/#ptw_task","text":"def ptw_task ( cli_args : str ) -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Return doit Interactive ptw task. Parameters: Name Type Description Default cli_args None string CLI args to pass to ptw None Returns: Type Description DoitTask doit task View Source @beartype def ptw_task ( cli_args : str ) -> DoitTask : \"\"\"Return doit Interactive `ptw` task. Args: cli_args: string CLI args to pass to `ptw` Returns: DoitTask: doit task \"\"\" return { 'actions' : [ Interactive ( f 'poetry run ptw -- \" { DG . test . path_tests } \" { cli_args } ' )], 'verbosity' : 2 , }","title":"ptw_task"},{"location":"docs/modules/calcipy/doit_tasks/test/#task_check_types","text":"def task_check_types () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run type annotation checks. Returns: Type Description DoitTask doit task View Source @beartype def task_check_types () -> DoitTask : \"\"\"Run type annotation checks. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run mypy { DG . meta . pkg_name } --show-error-codes' ), ])","title":"task_check_types"},{"location":"docs/modules/calcipy/doit_tasks/test/#task_coverage","text":"def task_coverage () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run pytest and create coverage and test reports. Returns: Type Description DoitTask doit task View Source @beartype def task_coverage () -> DoitTask : \"\"\"Run pytest and create coverage and test reports. Returns: DoitTask: doit task \"\"\" path_tests = DG . test . path_tests cov_dir = DG . test . path_coverage_index . parent cov_html = f '--cov-report=html:\" { cov_dir } \" --html=\" { DG . test . path_test_report } \" --self-contained-html' diff_html = f '--html-report { DG . test . path_diff_test_report } ' return debug_task ([ Interactive ( f 'poetry run pytest \" { path_tests } \" { DG . test . args_pytest } --cov= { DG . meta . pkg_name } { cov_html } ' ), 'poetry run python -m coverage json' , # Create coverage.json file for \"_write_coverage_to_md\" 'poetry run python -m coverage xml' , Interactive ( f 'poetry run diff-cover coverage.xml { DG . test . args_diff } { diff_html } ' ), ])","title":"task_coverage"},{"location":"docs/modules/calcipy/doit_tasks/test/#task_nox","text":"def task_nox () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run the full nox test suite. Note: some nox tasks are run in more-specific doit tasks, but this will run everything Returns: Type Description DoitTask doit task View Source @beartype def task_nox () -> DoitTask : \"\"\"Run the full nox test suite. > Note: some nox tasks are run in more-specific doit tasks, but this will run everything Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run nox' ), ])","title":"task_nox"},{"location":"docs/modules/calcipy/doit_tasks/test/#task_nox_coverage","text":"def task_nox_coverage () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run all nox tests. Returns: Type Description DoitTask doit task View Source @beartype def task_nox_coverage () -> DoitTask : \"\"\"Run all nox tests. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run nox --session coverage' ), ])","title":"task_nox_coverage"},{"location":"docs/modules/calcipy/doit_tasks/test/#task_nox_test","text":"def task_nox_test () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run all nox tests. Returns: Type Description DoitTask doit task View Source @beartype def task_nox_test () -> DoitTask : \"\"\"Run all nox tests. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( 'poetry run nox --session tests build_check' ), ])","title":"task_nox_test"},{"location":"docs/modules/calcipy/doit_tasks/test/#task_open_test_docs","text":"def task_open_test_docs () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Open the test and coverage files in default browser. Returns: Type Description DoitTask doit task View Source @beartype def task_open_test_docs () -> DoitTask : \"\"\"Open the test and coverage files in default browser. Returns: DoitTask: doit task \"\"\" actions = [ ( open_in_browser , ( DG . test . path_coverage_index ,)), ( open_in_browser , ( DG . test . path_test_report ,)), ] if DG . test . path_mypy_index . is_file (): actions . append (( open_in_browser , ( DG . test . path_mypy_index ,))) return debug_task ( actions )","title":"task_open_test_docs"},{"location":"docs/modules/calcipy/doit_tasks/test/#task_ptw_current","text":"def task_ptw_current () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run pytest watch for only tests with the CURRENT marker. kwargs: -m 'CURRENT' -vv Returns: Type Description DoitTask doit task View Source @beartype def task_ptw_current () -> DoitTask : \"\"\"Run pytest watch for only tests with the CURRENT marker. kwargs: `-m 'CURRENT' -vv` Returns: DoitTask: doit task \"\"\" return ptw_task ( '-m \"CURRENT\" -vv' )","title":"task_ptw_current"},{"location":"docs/modules/calcipy/doit_tasks/test/#task_ptw_ff","text":"def task_ptw_ff () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run pytest watch for failed first and skip the CHROME marker. kwargs: --last-failed --new-first -m 'not CHROME' -vv Returns: Type Description DoitTask doit task View Source @beartype def task_ptw_ff () -> DoitTask : \"\"\"Run pytest watch for failed first and skip the CHROME marker. kwargs: `--last-failed --new-first -m 'not CHROME' -vv` Returns: DoitTask: doit task \"\"\" return ptw_task ( '--last-failed --new-first -m \"not CHROME\" -vv' )","title":"task_ptw_ff"},{"location":"docs/modules/calcipy/doit_tasks/test/#task_ptw_marker","text":"def task_ptw_marker () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Specify a marker to run a subset of tests in Interactive ptw task. Example: doit run ptw_marker -m \"not MARKER\" or doit run ptw_marker -m \"MARKER\" Returns: Type Description DoitTask doit task View Source @beartype def task_ptw_marker () -> DoitTask : \"\"\"Specify a marker to run a subset of tests in Interactive `ptw` task. Example: `doit run ptw_marker -m \"not MARKER\"` or `doit run ptw_marker -m \"MARKER\"` Returns: DoitTask: doit task \"\"\" task = ptw_task ( '-vvv -m \" %(marker)s \"' ) task [ 'params' ] = [{ 'name' : 'marker' , 'short' : 'm' , 'long' : 'marker' , 'default' : '' , 'help' : ( 'Runs test with specified marker logic \\n See: ' 'https://docs.pytest.org/en/latest/example/markers.html?highlight=-m' ), }] return task","title":"task_ptw_marker"},{"location":"docs/modules/calcipy/doit_tasks/test/#task_ptw_not_chrome","text":"def task_ptw_not_chrome () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run pytest watch for failed first and skip the CHROME marker. kwargs: -m 'not CHROME' -vvv Returns: Type Description DoitTask doit task View Source @beartype def task_ptw_not_chrome () -> DoitTask : \"\"\"Run pytest watch for failed first and skip the CHROME marker. kwargs: `-m 'not CHROME' -vvv` Returns: DoitTask: doit task \"\"\" return ptw_task ( '-m \"not CHROME\" -vvv' )","title":"task_ptw_not_chrome"},{"location":"docs/modules/calcipy/doit_tasks/test/#task_test","text":"def task_test () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run tests with Pytest and stop on the first failure. Test are randomly ordered by default with pytest-randomly because that can help catch common errors Tests can be re-run in the last order with poetry run pytest --randomly-seed=last Tip: --record-mode=rewrite can be useful if working with pytest-recording Returns: Type Description DoitTask doit task View Source @beartype def task_test () -> DoitTask : \"\"\"Run tests with Pytest and stop on the first failure. > Test are randomly ordered by default with pytest-randomly because that can help catch common errors > Tests can be re-run in the last order with `poetry run pytest --randomly-seed=last` > Tip: `--record-mode=rewrite` can be useful if working with `pytest-recording` Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" { DG . test . args_pytest } ' ), ])","title":"task_test"},{"location":"docs/modules/calcipy/doit_tasks/test/#task_test_all","text":"def task_test_all () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Run all possible tests with Pytest even if one or more failures. Returns: Type Description DoitTask doit task View Source @beartype def task_test_all () -> DoitTask : \"\"\"Run all possible tests with Pytest even if one or more failures. Returns: DoitTask: doit task \"\"\" return debug_task ([ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" --ff -vv' ), ])","title":"task_test_all"},{"location":"docs/modules/calcipy/doit_tasks/test/#task_test_keyword","text":"def task_test_keyword () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Specify a keyword to run a subset of tests. Example: doit run test_keyword -k \"KEYWORD\" Returns: Type Description DoitTask doit task View Source @beartype def task_test_keyword () -> DoitTask : \"\"\"Specify a keyword to run a subset of tests. Example: `doit run test_keyword -k \"KEYWORD\"` Returns: DoitTask: doit task \"\"\" return { 'actions' : [ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" { DG . test . args_pytest } -k \"%(keyword)s\"' ), ], 'params' : [{ 'name' : 'keyword' , 'short' : 'k' , 'long' : 'keyword' , 'default' : '' , 'help' : ( 'Runs only tests that match the string pattern \\n See: ' 'https://docs.pytest.org/en/latest/usage.html#specifying-tests-selecting-tests' ), }], 'verbosity' : 2 , }","title":"task_test_keyword"},{"location":"docs/modules/calcipy/doit_tasks/test/#task_test_marker","text":"def task_test_marker () -> Union [ doit . task . Task , Dict [ str , Union [ str , doit . action . BaseAction , Tuple [ Callable , Iterable [ Union [ str , float , int , pathlib . Path , Dict [ str , Any ]]]]]]] Specify a marker to run a subset of tests. Example: doit run test_marker -m \"not MARKER\" or doit run test_marker -m \"MARKER\" Returns: Type Description DoitTask doit task View Source @beartype def task_test_marker () -> DoitTask : \"\"\"Specify a marker to run a subset of tests. Example: `doit run test_marker -m \"not MARKER\"` or `doit run test_marker -m \"MARKER\"` Returns: DoitTask: doit task \"\"\" task = debug_task ([ Interactive ( f 'poetry run pytest \" { DG . test . path_tests } \" { DG . test . args_pytest } -m \"%(marker)s\"' )]) task [ 'params' ] = [{ 'name' : 'marker' , 'short' : 'm' , 'long' : 'marker' , 'default' : '' , 'help' : ( 'Runs test with specified marker logic \\n See: ' 'https://docs.pytest.org/en/latest/example/markers.html?highlight=-m' ), }] return task","title":"task_test_marker"}]}